{"pages":[{"title":"About","date":"2016-10-24T02:24:00.000Z","path":"about/index.html","text":"关于我自己95后码农军团冲锋兵一枚，不断在与脱发斗争中。 关于编程不应该局限于软件工程师的思维，不应该只写代码，去学习新技术，沟通、管理、理财，你都应该去学习、去了解、去跟上世界成长的脚步。 业余爱好旅行、运动、篮球、爬山、音乐、英语交流 -&gt; 是的，就是正常人干的事情 最后人的这一辈子没法做太多的事情，所以每一件都要做的精彩绝伦"},{"title":"Categories","date":"2021-02-07T01:43:30.625Z","path":"categories/index.html","text":""},{"title":"Tags","date":"2021-02-07T01:43:30.653Z","path":"tags/index.html","text":""}],"posts":[{"title":"Dijkstra最短路径","date":"2021-02-06T09:50:43.000Z","path":"wiki/blog/algorithm/dijkstra/","text":"dijkstra利用松弛操作找到最短的路线距离，假设当前图结构为稀疏图，结构如下: 按照直观来说，0-4的最短路径有如下几种选择 最优路显然是0-2-3-4,权值只有7当属最小 接下来看看如何实现该寻路过程 结构说明1234SparseGraph graph(5,false);bool* visited;int * from;int * distTo; 总共4个额外数组来维护寻路过程的记录 visited,当对某一节点left以及所有对应的边right进行访问时对visited[left] = true进行标记，表明以及访问过当前节点了 from,这个作为辅助数据，在计算到最短路径后，如果需要打印完整的路径，则需要from来记录每次寻路的过程 distTo，distTo[i]记录了原点s到i的最短距离 bfs进行寻路12345678910111213141516171819202122232425262728293031323334void breadth_first_search(int s)&#123; //采用最小索引堆来做,默认初始化n个顶点空间 IndexMinHeap&lt;int&gt; qp(graph.points); //默认插入一个 源起始点 qp.insert(s,0); while(!qp.isEmpty())&#123; //每次获取s原点最短的那个距离 int left = qp.extraMinIndex(); //标记该节点已经被访问过了 visited[left] = true; //接下来访问该节点的所有邻边 for(auto edge : graph.g[left])&#123; //查看对应的邻边有没有被访问过,edge-&gt;a 就是当前id, edge-&gt;b才是领边 edge-&gt;v 代表权值 int right = edge-&gt;b; int length = edge-&gt;v; if(!visited[right])&#123; //判断from 路径有没有记录 || 如果[s -&gt; left + left-&gt;right] &lt; [s -&gt; right] 说明找到了更短的距离 if(from[right] == -1 || distTo[left] + length &lt; distTo[right])&#123; //更新当前被访问的right节点的来源节点left from[right] = left; //更新距离: s-&gt;right = s-&gt;left + left-&gt;right distTo[right] = distTo[left] + length; //判断队列里有没有访问过当前的 right节点 if(qp.contain(right)) qp.change(right,distTo[right]); else qp.insert(right,distTo[right]); &#125; &#125; &#125; &#125;&#125; 从s原点开始,加入到最小索引堆中qp.insert(0,0),因为0-0的距离默认为0，所以第一个节点默认权值为0 接下来就是对0点的各个边进行扫描，如果发现有更短的距离，则直接更新新的距离 123456789如上图所示:0 -&gt; 4 : 距离为9 ，那么 distTo[4] = 9;0-&gt;2-&gt;4 : 因为 0-&gt;2 = 2, 2-&gt;4 = 6 , 存在 0-2-4(8) &lt; 0-4(9)所以找到了更优的路径：o-&gt;4 = 8,依次类推，实现最短路径的查找 不断重复步骤2，直到遍历完可达的顶点后，结束寻路计算 最后的结果应该如下模式 路径展示检查是否通路123456//判断0-4是否有路if(distTo[4])&#123; cout &lt;&lt; \" 1-4 有路:\" &lt;&lt; distTo[4] &lt;&lt; endl;&#125;else&#123; cout &lt;&lt; \" 2-4 有路\" &lt;&lt;endl;&#125; 路径展示1234567int i = 4;cout &lt;&lt; \"4 \" ;while(i != -1 )&#123; cout &lt;&lt; \"-&gt;\"; cout &lt;&lt; from[i]; i = from[i];&#125; 完整的寻路流程图 完整的代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#include \"SparseGraph.h\"#include \"IndexMinHeap.h\"#include &lt;stack&gt;#include &lt;queue&gt;SparseGraph graph(5,false);//代表是否访问过bool* visited;//记录路径，from[i] 表示查找的路径i的上一个节点int * from;//记录权值 这里的权值采用int来表示int * distTo;//bfs 广度优先遍历void breadth_first_search(int s)&#123; //采用最小索引堆来做,默认初始化n个顶点空间 IndexMinHeap&lt;int&gt; qp(graph.points); //默认插入一个 源起始点 qp.insert(s,0); while(!qp.isEmpty())&#123; //每次获取s原点最短的那个距离 int left = qp.extraMinIndex(); //标记该节点已经被访问过了 visited[left] = true; //接下来访问该节点的所有邻边 for(auto edge : graph.g[left])&#123; //查看对应的邻边有没有被访问过,edge-&gt;a 就是当前id, edge-&gt;b才是领边 edge-&gt;v 代表权值 int right = edge-&gt;b; int length = edge-&gt;v; if(!visited[right])&#123; //判断from 路径有没有记录 || 如果[s -&gt; left + left-&gt;right] &lt; [s -&gt; right] if(from[right] == -1 || distTo[left] + length &lt; distTo[right])&#123; //更新当前被访问的right节点的来源节点left from[right] = left; //更新距离: s-&gt;right = s-&gt;left + left-&gt;right distTo[right] = distTo[left] + length; //判断队列里有没有访问过当前的 right节点 if(qp.contain(right))&#123; qp.change(right,distTo[right]); &#125;else&#123; qp.insert(right,distTo[right]); &#125; &#125; &#125; &#125; &#125;&#125;int main()&#123; visited = new bool[5]; from = new int[5]; distTo = new int[5]; for(int i = 0; i &lt; 5; i ++)&#123; from[i] = -1; visited[i] = false; //disTo[i] 记录了原点s到i的最短距离 distTo[i] = 0; &#125; graph.addEdge(0,1,1); graph.addEdge(0,4,2); graph.addEdge(1,4,6); graph.addEdge(1,3,3); graph.addEdge(3,4,4); //标记从1开始到其他任意节点的最短路径 int p = 1; breadth_first_search(p); //判断1-4是否有路 if(distTo[4])&#123; cout &lt;&lt; \" 1-4 有路:\" &lt;&lt; distTo[4] &lt;&lt; endl; &#125;else&#123; cout &lt;&lt; \" 2-4 有路\" &lt;&lt;endl; &#125; // //查看 2-3有没有路径 // if(!visited[3])&#123; // cout &lt;&lt; \"不存在\" &lt;&lt;endl; // &#125; // //查看路径 int i = 4; cout &lt;&lt; \"4 \" ; while(i != -1 )&#123; cout &lt;&lt; \"-&gt;\"; cout &lt;&lt; from[i]; i = from[i]; &#125; &#125;","tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"graph","slug":"graph","permalink":"http://wiki.brewlin.com/tags/graph/"},{"name":"golang","slug":"golang","permalink":"http://wiki.brewlin.com/tags/golang/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"algorithm","slug":"blog/algorithm","permalink":"http://wiki.brewlin.com/categories/blog/algorithm/"}]},{"title":"三色标记清除","date":"2020-11-15T07:23:58.000Z","path":"wiki/blog/gc-learning/算法实现/10.三色标记清除/","text":"github: https://github.com/brewlin/gc-learning 当前实现的三色标记是一种增量式-标记清除算法,解决了标记清除算法中stw过长的问题，增量迭代演进式回收,而不是一次性标记和回收所有对象，优化了stw暂停时间过长的问题 白色: 未搜索过的对象 灰色: 正在搜索的对象，其实就是child引用没有扫描完的对象 黑色: 搜索完成后的对象 当多个阶段全部标记完成后任然是白色的对象就是垃圾对象，应该回收 既然是增量，说明标记阶段每次只执行一部分，清除阶段也只执行一部分 gc_phase: 表示当前所在阶段 max_mark：每阶段需要标记的灰色对象的最大数量 mar_sweep: 每阶段需要清除的白色垃圾对象的最大数量 gc过程主要分为如下流程 标记阶段: 扫描根,进行多阶段标记，每次发现的白色对象转换为灰色对象丢入栈内 清除阶段: 多阶段清除垃圾，只清除白色垃圾(未标记的) 在增量gc多个阶段之间有新的对象产生、更新等，会涉及到安全问题，需要有个写入屏障 @gc 阶段12345678910111213141516//tri-color.cvoid gc(void)&#123; printf(\"执行gc\\n\"); switch(gc_phase)&#123; case GC_ROOT_SCAN: root_scan_phase(); return; case GC_MARK: mark_phase(); return; case GC_SWEEP: sweep_phase(); &#125;&#125; 每次执行gc都会继续执行之前中断的阶段，如 根扫描 标记阶段 清除阶段 完全执行完清除阶段后，下一阶段又回到根扫描上 @stack 存储灰色对象的栈实现了一个简单的栈，用于存储灰色对象，每次扫描到存活对象后直接入栈，转为灰色对象 在标记阶段会递归标记其子对象，完成后出栈，转为黑色对象 1234567891011121314151617//stack.htypedef struct link_list&#123; void* value; struct link_list *next;&#125;Link;typedef struct stack_header&#123; Link* head; Link* tail;&#125;Stack;void push(Stack* stk,void* v);int empty(Stack* stk);void* pop(Stack* stk); push 入栈 pop 出栈 empty 是否为空 @root_scan_phase 根部扫描阶段1234567891011121314151617181920void root_scan_phase()&#123; //垃圾回收前 先从 root 开始 进行递归标记 for(int i = 0;i &lt; root_used;i++) &#123; void* ptr = roots[i].ptr; GC_Heap *gh; Header *hdr; if (!(gh = is_pointer_to_heap(ptr))) continue; if (!(hdr = get_header(gh, ptr))) continue; if (!FL_TEST(hdr, FL_ALLOC)) continue; if (FL_TEST(hdr, FL_MARK)) continue; //标记为灰色 并入栈 FL_SET(hdr, FL_MARK); push(&amp;stack,ptr); &#125; gc_phase = GC_MARK;&#125; 当前是直接将所有存活对象作为灰色对象推入标记栈中,结束了扫描阶段 但是在标记阶段其实还是会进行多次根扫描，因为多个阶段之间可能发生了更新，新增对象等，需要多次进行扫描 第一次gc的时候这里扫描完就可以直接进入下一阶段了 @mark_phase 标记阶段12345678910111213141516171819202122232425262728293031323334//tri-color.cvoid mark_phase()&#123; //1 全部将灰色标记完了在进行下一个清除阶段 //2 未全部标记完则继续进行标记 int scan_root = 0; for (int i = 0; i &lt; max_mark; ++i) &#123; //如果为空就继续去扫描一下root 看看在gc休息期间是否有新的没有进行标记 if(empty(&amp;stack))&#123; //如果扫描过了root，但是依然没有新增灰色对象 则结束标记 if(scan_root &gt;= 1) &#123; gc_phase = GC_SWEEP; break; &#125; root_scan_phase(); scan_root++; continue; &#125; void* obj = pop(&amp;stack); Header* hdr = CURRENT_HEADER(obj); //递归对child 进行标记 for (void* p = obj; p &lt; (void*)NEXT_HEADER(hdr); p++) &#123; //对内存解引用，因为内存里面可能存放了内存的地址 也就是引用，需要进行引用的递归标记 gc_mark(*(void **)p); &#125; &#125; //所有gc扫描完以后 只有空栈的话 说明标记完毕 需要进行清扫 if(empty(&amp;stack))&#123; gc_phase = GC_SWEEP; &#125;&#125; scan_root标志用于在标记栈为空的时候，悄悄再去扫描一下根，看看是否有新的活动对象产生 max_mark标志用于指示每次只标记固定数量的灰色对象(栈里的都是灰色对象) 1234for (void* p = obj; p &lt; (void*)NEXT_HEADER(hdr); p++) &#123; //对内存解引用，因为内存里面可能存放了内存的地址 也就是引用，需要进行引用的递归标记 gc_mark(*(void **)p);&#125; 递归扫描标记子对象(和标记清除章节一致) 最后判断如果灰色对象标记完了，则进入下一阶段GC_SWEEP123if(empty(&amp;stack))&#123; gc_phase = GC_SWEEP;&#125; @sweep_phase 清除阶段也是多阶段清除，每次只清除固定max_sweep个白色垃圾，并记下索引，下次继续清除12345678910111213141516171819202122232425262728293031323334353637//tri-color.cvoid sweep_phase(void)&#123; size_t i; Header *p, *pend, *pnext; //遍历所有的堆内存 //因为所有的内存都从堆里申请，所以需要遍历堆找出待回收的内存 for (i = sweeping; i &lt; gc_heaps_used &amp;&amp; i &lt; max_sweep + sweeping; i++) &#123; //pend 堆内存结束为止 pend = (Header *)(((size_t)gc_heaps[i].slot) + gc_heaps[i].size); //堆的起始为止 因为堆的内存可能被分成了很多份，所以需要遍历该堆的内存 for (p = gc_heaps[i].slot; p &lt; pend; p = NEXT_HEADER(p)) &#123; //查看该堆是否已经被使用 if (FL_TEST(p, FL_ALLOC)) &#123; //查看该堆是否被标记过 if (FL_TEST(p, FL_MARK)) &#123; DEBUG(printf(\"解除标记 : %p\\n\", p)); //取消标记，等待下次来回收，如果在下次回收前 //1. 下次回收前发现该内存又被重新访问了，则不需要清除 //2. 下次回收前发现该内存没有被访问过，所以需要清除 FL_UNSET(p, FL_MARK); &#125;else &#123; DEBUG(printf(\"清除回收 :\\n\")); gc_free(p+1); &#125; &#125; &#125; &#125; //如果堆扫描完则 切换到root扫描 sweeping = i; if(i == gc_heaps_used)&#123; sweeping = 0; gc_phase = GC_ROOT_SCAN; &#125;&#125; 堆扫描完后，又重新回到GC_ROOT_SCAN阶段 关于gc安全的两点写入屏障处在gc执行后的暂停阶段期间，程序对对象又进行了更新会产生不可预料的后果，如下图所示: 首先E没有被Root管理，扫描根的时候无法扫描到，只有扫描C的子对象时才能标记到C A,B对象已经是黑色对象了，不需要在进行扫描了，是觉得的安全对象 此时C到E的引用被切断了，E被黑色对象B引用 如果不做任何操作，E将会在gc结束后备清除 这就是写入屏障的重要性，保证了在gc执行的多阶段暂停之间任然保证逻辑正确 123456789101112131415161718//tri-color.cvoid write_barrier(void *obj_ptr,void *field,void* new_obj_ptr)&#123; Header* obj = CURRENT_HEADER(obj_ptr); Header* new_obj = CURRENT_HEADER(new_obj_ptr); //如果老对象已经被标记了 就要检查新对象是否标记了 if(IS_MARKED(obj))&#123; if(!IS_MARKED(new_obj))&#123; FL_SET(new_obj,FL_MARK); push(&amp;stack,new_obj_ptr); &#125; &#125; //obj-&gt;field = new_obj *(void **)field = new_obj_ptr;&#125; 如上面所说，在更新对象的时候需要判断，如果原对象是一个黑色对象，则需要将当前对象标记为灰色后推入标记栈中 等待下次标记阶段扫描当前对象，解决了更新安全问题 分配安全在gc暂停阶段期间新申请对象需要注意如果新申请的内存在清除内存的后方，只需要默认进行设置为黑色,防止被误回收","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"},{"name":"tri-color-mark","slug":"tri-color-mark","permalink":"http://wiki.brewlin.com/tags/tri-color-mark/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"},{"name":"算法实现","slug":"blog/gc-learning/算法实现","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/算法实现/"}]},{"title":"分代回收算法","date":"2020-11-14T07:22:59.000Z","path":"wiki/blog/gc-learning/算法实现/9.分代回收算法/","text":"github: https://github.com/brewlin/gc-learning 分代垃圾回收也是一种组合算法实现(gc复制 + 标记清除)，在了解之前先来看看几个关键字概念 @分代概念新生代(newg): 作为内存分配区 幸存代(survivorfromg): 作为内存分配区 幸存代(survivorto): 新生代+幸存代执行复制算法,最终复制到幸存to区 老年代(oldg): 老年代单独执行标记清除算法 promote(晋升): 当前规定经历过3次gc后任然幸存的新生代对象会晋升为老年代对象，会拷贝到老年区 remember_set(记录集): 用于存储那些任然引用新生代对象的老年代对象，也是老年代的根ROOT 只从新生代和幸存代from分配内存 多次幸存后晋升为老年代,将对象拷贝到老年区 步骤2中如果晋升过后子对象还在新生代则记录到记录集中作为可达的根 @gc_init 初始化12345678910111213141516171819202122void gc_init(size_t heap_size)&#123; //关闭自动扩充堆 auto_grow = 0; //gc_heaps[3] 用于老年代堆区 gc_heaps_used = 3; for (size_t i = 0; i &lt; 4; i++)&#123; //使用sbrk 向操作系统申请大内存块 void* p = sbrk(heap_size + PTRSIZE); if(p == NULL)exit(-1); gc_heaps[i].slot = (Header *)ALIGN((size_t)p, PTRSIZE); gc_heaps[i].size = heap_size; gc_heaps[i].slot-&gt;size = heap_size; gc_heaps[i].slot-&gt;next_free = NULL; &#125; //初始化新生代空闲链表指针 new_free_p = gc_heaps[newg].slot; //老年代分配需要用到空闲列表 通过gc_free 挂到空闲列表即可 gc_free(gc_heaps[oldg].slot + 1);&#125; 当前主要固定四个内存区,new,from,to,old。并且关闭自动扩充堆 空闲指针free-list是专用于老年代的分配指针，在晋升的时候会从老年代区分配一份内存用于拷贝 空闲指针new_free_p是专用于内存分配指针，新内存都是从新生代区分配 @minor_gc 新生代gc阶段1234567891011121314151617181920212223242526272829303132333435void minor_gc(void)&#123; //每次gc前将 free指向 to的开头 gc_heaps[survivortog].slot-&gt;size = gc_heaps[survivortog].size; //初始化to空间的首地址 to_free_p = gc_heaps[survivortog].slot; //递归进行复制 从 from =&gt; to for(int i = 0;i &lt; root_used;i++)&#123; void* forwarded; if(!(forwarded = gc_copy(roots[i].ptr))) continue; *(Header**)roots[i].optr = forwarded; //将root 所有的执行换到 to上 roots[i].ptr = forwarded; &#125; //更新跨代引用 update_reference(); //清空 新生代 new_free_p = gc_heaps[newg].slot ; memset(new_free_p,0,gc_heaps[newg].size); new_free_p-&gt;size = gc_heaps[newg].size; //清空 幸存代 from memset(gc_heaps[survivorfromg].slot,0,gc_heaps[survivorfromg].size); gc_heaps[survivorfromg].slot-&gt;size = gc_heaps[survivorfromg].size; //交换 swap(幸存代from ,幸存代to); GC_Heap tmp = gc_heaps[survivorfromg]; gc_heaps[survivorfromg] = gc_heaps[survivortog]; gc_heaps[survivortog] = tmp;&#125; 新生代主要执行复制算法，将newg和fromg复制到tog空间，并置换from和to后结束新生代GC 主要流程和GC复制流程一致，可以去看gc复制的实现分析 搜索根执行拷贝到to区 更新引用 清空新生代，清空幸存代 交换from和to @minor_malloc 内存分配所有分配只能走新生代分配，直接从newg区分配一块空闲内存即可123456789101112if (new_free_p-&gt;size &lt; req_size) &#123; //一般是分块用尽会 才会执行gc 清除带回收的内存 if (!do_gc) &#123; do_gc = 1; //内存不够用的时候会触发 复制 释放空间 //释放空间的时候会造成空间的压缩 minor_gc(); goto alloc; &#125; printf(\"内存不够\"); return NULL;&#125; 从new_free_p执行的剩余空间分配一块足够大小的空间 内存不够则执行新生代gcminor_gc释放一定空闲内存 @gc_copy 复制这里和复制算法稍微有点不一样，如果对象属于老年区则不作任何操作,复制只会拷贝新生代区的对象123456if (!(gh = is_pointer_to_heap(ptr))) return NULL;//查看该对象是否存在于 新生代 这里的get_header 只会去查找 新生代和两个幸存代if (!(hdr = get_header(gh,ptr))) &#123; return NULL;&#125; 同时在执行拷贝前需要检查年龄age是否小于3，否则需要晋升为老年代12345678910//没有复制过 0if(!IS_COPIED(hdr))&#123; //判断年龄是否小于阈值 if(hdr-&gt;age &lt; AGE_MAX) &#123; //拷贝 &#125;else&#123; //晋升 &#125;&#125; 复制流程和之前的复制算法流程一样，可以去看之前的分析 @promote 晋升1234567891011121314151617181920212223242526272829303132void promote(void *ptr)&#123; Header* obj = CURRENT_HEADER(ptr); //1 从老年代空间分配出一块 内存 (老年代堆 完全采用 gc标记-清除算法来管理) void* new_obj_ptr = major_malloc(CURRENT_HEADER(ptr)-&gt;size); if(new_obj_ptr == NULL) abort(); Header* new_obj = CURRENT_HEADER(new_obj_ptr); //将obj 拷贝到 new_obj中 memcpy(new_obj,obj,obj-&gt;size); obj-&gt;forwarding = new_obj; //标志已经复制过了 forwarded = true FL_SET(obj,FL_COPIED); //for child: obj 这里是为了检查老年代对象是否有对象依然指向新生代中 for (void *p = ptr; p &lt; (void*)NEXT_HEADER(obj); p++) &#123; //解引用 如果该内存依然是指向的from，且有forwarding 则需要改了 void *ptr = *(void**)p; GC_Heap *gh; Header *hdr; /* mark check */ if (!(gh = is_pointer_to_heap(ptr))) continue; //查看该引用是否存在于 新生代 这里的get_header 只会去查找 新生代和两个幸存代 if (!(hdr = get_header(gh,ptr))) continue; //存在就要将 new_obj 加入集合 rs[rs_index++] = new_obj_ptr; break; &#125;&#125; 从老年代分配一块内存，将当前晋升对象拷贝过去 搜索子对象是否有在新生代和幸存区的，如果存在说明当前老年代对象有跨代引用，需要加入记录集remember_set管理 @update_reference 更新引用这里的更新引用主要是针对跨代引用而言 如果某个对象没有加入ROOT，但是却被老年代引用了，这个时候就需要将它复制到幸存to区,如果不这么做的话，它就会被意外的清除了 如图所示,B对象没有加入根，在复制阶段无法被认定为活动对象，也就无法进行拷贝到幸存区，会被回收 但是他却被老年区的D对象引用，也应该被拷贝到幸存区 所以当前函数主要是处理这种情况，处理跨代引用的拷贝问题 需要注意一点: 当前函数会检查当老年代没有任何引用对象任然在新生代和幸存代时，会从记录集中剔除老年对象,那在老年代gc的时候会被清除，因为没有任何根能够搜索到该老年代对象了 @write_barrier 写屏障为了让老年代对象任然保持活性，那么写入屏障是或不可缺的,想像下如下场景 某老年代对象已经没有任何跨代对象了,且已经被剔除记录集了，如果下一次老年代gc启动，则必定是最先被优化的那一批。 这时候新生代一个对象突然被老年代引用了，如果不做任何操作，我们在update_reference阶段是无法追踪到这个新生代引用对象的 这样导致步骤2中的新生代对象被无辜清除了，正确的做法是:在更新引用的时候需要判断下发出引用的对象是否属于老年代，然后需要记录记录集 1234567891011121314151617181920void write_barrier(void *obj_ptr,void *field,void* new_obj_ptr)&#123; Header* obj = CURRENT_HEADER(obj_ptr); Header* new_obj = CURRENT_HEADER(new_obj_ptr); //obj 在老年代 //new_obj 在新生代 //且 obj 未保存在 记忆集 if(is_pointer_to_space(obj,oldg) &amp;&amp; !is_pointer_to_space(new_obj,oldg) &amp;&amp; !IS_REMEMBERED(obj)) &#123; rs[rs_index++] = obj; //设置该对象已经保存在了记忆集，无需再次保存 FL_SET(obj,FL_REMEMBERED); &#125; //obj-&gt;field = new_obj *(void **)field = new_obj_ptr;&#125; 检查对象是老年代，且被引用对象是新生代的情况 如果满足步骤1，则需要更新记录集 @major_gc 老年代gc老年代gc完全按照标记清除算法执行，只是在搜索根的步骤换成了搜索记录集(remember_set) 12345678910void major_gc(void)&#123; //rs 里的基本都是老年代 for(int i = 0; i &lt; rs_index; i ++) &#123; //只对老年代 对象进行gc gc_mark(rs[i]); &#125; //标记完成后 在进行 清除 对于没有标记过的进行回收 gc_sweep();&#125; 进行记录集搜索并标记 进行清除回收未标记垃圾 @gc_mark 标记阶段判断是否是老年代对象，如果不是则不需要标记 最后进行递归标记 可以看之前的标记清除章节 @gc_sweep 清除阶段搜索老年代堆，对未标记内存进行回收 和之前标记清除章节一致 @major_malloc从老年代堆中分配一份内存返回","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"},{"name":"generational","slug":"generational","permalink":"http://wiki.brewlin.com/tags/generational/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"},{"name":"算法实现","slug":"blog/gc-learning/算法实现","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/算法实现/"}]},{"title":"关于保守式GC","date":"2020-11-13T15:59:59.000Z","path":"wiki/blog/gc-learning/算法实现/8.保守式gc/","text":"github: https://github.com/brewlin/gc-learning 当前所有的gc实现都是基于保守式gc实现的，特点就是实现简单、容易理解，对应用层友好 保守式gc的示例比如一个内存分配如下:123456789#include \"gc.h\"void test()&#123; typedef struct obj&#123; ..... &#125;Obj; Obj* p = gc_malloc(sizeof(Obj); // do something else&#125; 没有任何依赖，只需要调用gc_malloc()分配一块空间即可，不需要应用层去操心如(标记，内嵌指针啥的)，实现简单 保守式gc的缺陷在这简单的背后自然也有保守式gc的一个缺陷,那就是不能识别指针和非指针。接着上上面的函数来说,举个例子1234567void main()&#123; test(); double p = 0x555555; //内存不够了 自动执行gc void* pp = gc_malloc(size);&#125; 调用test函数,加入该函数内p的指针刚好也是 0x555555 test函数返回后继续执行，此时栈上有一个double变量，且值刚好也是0x555555 和上面test函数的指针值相同 假如再次申请空间时，内存不够了，默认启动gc垃圾回收 首先: test作用域已经退出了，在进行root扫描时(可以先去看什么是root?) Obj *p已经是不可达对象，称为垃圾对象 但是: 在main中root扫描，扫到了 double p 且刚好该值是我们实现的堆里的一个合法地址 最终: 导致test的p本来该回收，但是因为 double p导致了回收失败 这就是保守式gc，某些情况下会无法准确识别指针 or 非指针,导致内存得不到释放 当然现代很多语言都是基于保守式gc，也有很多对策来降低这种误差","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"},{"name":"conservative","slug":"conservative","permalink":"http://wiki.brewlin.com/tags/conservative/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"},{"name":"算法实现","slug":"blog/gc-learning/算法实现","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/算法实现/"}]},{"title":"压缩算法-two-finger","date":"2020-11-12T07:21:22.000Z","path":"wiki/blog/gc-learning/算法实现/7.压缩算法-two-finger/","text":"github: https://github.com/brewlin/gc-learning two-finger相比lisp2而言优化了gc效率，只需要执行两次堆的遍历，但同时也多了限制条件,那就是需要保证每个对象的内存块大小一致 通过固定块大小，就可以去除之前set_forwarding_ptr计算移动地址的步骤，因为内存块都是一样的，所以直接移动即可 主要流程如下 gc_mark: 标记阶段，扫描root对活动对象进行标记 move: 第一次遍历堆-双端同时遍历开始移动拷贝 adjust_ptr: 第二次遍历堆-更新引用关系 two-finger和lisp2的区别: two-finger 只需要2次堆遍历，而lisp2需要三次 two-finger 规定每个对象大小必须一致, lisp2无要求 two-finger 不需要移动全部对象(注意这点区别),可以用填空来描述这一行为 @gc_init 初始化123456789101112131415void gc_init(size_t heap_size)&#123; //关闭自动扩充堆 auto_grow = 0; gc_heaps_used = 1; //使用sbrk 向操作系统申请大内存块 void* p = sbrk(heap_size + PTRSIZE); gc_heaps[0].slot = (Header *)ALIGN((size_t)p, PTRSIZE); gc_heaps[0].size = heap_size; gc_heaps[0].slot-&gt;size = heap_size; gc_heaps[0].slot-&gt;next_free = NULL; //将堆初始化到free_list 链表上 gc_free(gc_heaps[0].slot + 1);&#125; 为了聚焦算法实现本身，这里只固定申请一个堆，且关闭自动扩充堆auto_grow = 0 @gc 阶段123456789101112void gc(void)&#123; printf(\"start gc()\\n\"); //gc 递归标记 for(int i = 0;i &lt; root_used;i++) gc_mark(roots[i].ptr); //移动对象 move_obj(); //调整指针 adjust_ptr();&#125; 遍历root,对所有可达对象以及子对象进行标记 直接移动对象即可，因为每个对象大小都一致，直接移动等分距离即可 更新活动对象的子对象指向新的地址 @gc_mark 标记阶段 扫描root根，这里是模拟的root，真实的root可以参考gc-try实现的扫描系统栈12for(int i = 0;i &lt; root_used;i++) gc_mark(roots[i].ptr); 12345678910void* gc_mark(void *ptr)&#123; //检查指针是否合法 /* marking */ FL_SET(hdr, FL_MARK); for (void* p = ptr; p &lt; (void*)NEXT_HEADER(hdr); p++) &#123; gc_mark(*(void **)p); &#125; return ptr;&#125; 常规操作，对当前指针进行检查，然后扫描当前指针执行的内存段，对child进行递归引用标记 @move_obj 移动压缩 注意和lisp的移动的区别，这里采用两个指针空闲指针和live指针 空闲指针从头遍历，总是去寻找空位 live指针从尾遍历, 总是去寻找存活对象 当两个指针相遇的时候结束压缩 两个指针就像是两个手指一样，所以取名two-finger 逻辑实现12345678910111213141516171819202122232425262728293031323334void move_obj()&#123; free_list = gc_heaps[i].slot; total = gc_heaps[i].size; while (true) &#123; //遍历到第一个非标记的地方，也就是空闲区 while (FL_TEST(free_list, FL_ALLOC) &amp;&amp; FL_TEST(free_list, FL_MARK) &amp;&amp; free_list &lt; live) &#123; FL_UNSET(free_list,FL_MARK); total -= free_list-&gt;size; free_list = NEXT_HEADER(free_list); &#125; //遍历到第一个被标记了的地方，这样就会将这个地方拷贝到上面的空闲区 while (!FL_TEST(live, FL_MARK) &amp;&amp; live &gt; gc_heaps[i].slot) //TODO:因为反向遍历的时候 没有域且内存非等分，所以不能通过 -= mem_size 来遍历 live = (Header *) ((void *) live - 1); //进行拷贝 if (free_list &lt; live) &#123; FL_UNSET(live, FL_MARK); memcpy(free_list, live, live-&gt;size); live-&gt;forwarding = free_list; total -= live-&gt;size; &#125; else &#123; break; &#125; &#125; free_list-&gt;size = total; free_list-&gt;next_free = NULL; //方便测试 把空闲空间都清空 memset(free_list + 1,0,total);&#125; 采用2层循环，三个循环来实现压缩 外层循环 在两个指针相遇时结束，压缩也结束了 内层第一个循环，总是去寻找第一个空位 内层第二个循环，总是从尾部反向遍历寻找存活对象 核心就是每个对象大小都是一样的，所以在进行填补的时候直接拷贝即可 @adjust_ptr 更新引用 和lisp2算法一样，更新子对象的引用 初始时block3引用了block4,且block3应该移动到block1处，block4应该移动到block2处 更新后block3不再引用block4而是将要移动后的block2的位置 1234567891011121314151617181920212223242526void adjust_ptr()&#123; //遍历所有对象 for(int i = 0; i &lt; root_used; i ++)&#123; Header* forwarding = CURRENT_HEADER(roots[i].ptr)-&gt;forwarding; roots[i].ptr = forwarding+1; *(Header**)roots[i].optr = forwarding+1; &#125; //堆的起始为止 因为堆的内存可能被分成了很多份，所以需要遍历该堆的内存 for (p = gc_heaps[i].slot; p &lt; pend; p = NEXT_HEADER(p)) &#123; //可能申请的内存 里面又包含了其他内存 for (void* obj = p+1; obj &lt; (void*)NEXT_HEADER(p); obj++) &#123; //正确找到了 child 引用 GC_Heap *gh; Header *hdr; if (!(gh = is_pointer_to_heap(*(void**)obj))) continue; if((hdr = get_header(gh,*(void**)obj))) &#123; *(Header **) obj = hdr-&gt;forwarding + 1; //更新引用 &#125; &#125; &#125;&#125; 先更新root，因为所有活动对象的内存都发生了移动，需要更新栈变量存储的地址，也就是更新root所指向的地址","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"},{"name":"compact","slug":"compact","permalink":"http://wiki.brewlin.com/tags/compact/"},{"name":"compact-two-finger","slug":"compact-two-finger","permalink":"http://wiki.brewlin.com/tags/compact-two-finger/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"},{"name":"算法实现","slug":"blog/gc-learning/算法实现","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/算法实现/"}]},{"title":"压缩算法-lisp2","date":"2020-11-12T07:20:21.000Z","path":"wiki/blog/gc-learning/算法实现/6.压缩算法-lisp2/","text":"github: https://github.com/brewlin/gc-learning 压缩算法,也是一种充分利用空间解决内存碎片的算法。相较于复制称为移动更为恰当,因为压缩算法中不会将对象从from搬到to,仅限于在当前堆内活动，将所有活动对象去全部移动到头部进行压缩 压缩算法相比复制算法解决了内存碎片和无法充分利用堆的问题,但也有新的问题产生，当前压缩算法的实现:lisp2: 在gc过程中需要遍历三次堆，堆内存较大情况下比较耗费时间 不能像gc复制算法那样将具有引用关系的对象就近排列加快访问速度 主要流程如下 gc_mark: 标记阶段，扫描root对活动对象进行标记 set_forwarding_ptr: 第一次遍历堆-计算活动对象移动后的地址 adjust_ptr: 第二次遍历堆-更新引用关系，所有的子类都要执行步骤2中计算出来的新地址 move_obj: 第三次遍历堆-移动对象执行压缩 @gc_init 初始化123456789101112131415void gc_init(size_t heap_size)&#123; //关闭自动扩充堆 auto_grow = 0; gc_heaps_used = 1; //使用sbrk 向操作系统申请大内存块 void* p = sbrk(heap_size + PTRSIZE); gc_heaps[0].slot = (Header *)ALIGN((size_t)p, PTRSIZE); gc_heaps[0].size = heap_size; gc_heaps[0].slot-&gt;size = heap_size; gc_heaps[0].slot-&gt;next_free = NULL; //将堆初始化到free_list 链表上 gc_free(gc_heaps[0].slot + 1);&#125; 为了聚焦算法实现本身，这里只固定申请一个堆，且关闭自动扩充堆auto_grow = 0 @gc 阶段1234567891011121314151617/** * 执行gc */void gc(void)&#123; printf(\"start gc()\\n\"); //gc 递归标记 for(int i = 0;i &lt; root_used;i++) gc_mark(roots[i].ptr); //设置forwarding指针 set_forwarding_ptr(); //调整指针 adjust_ptr(); //移动对象 move_obj();&#125; 遍历root,对所有可达对象以及子对象进行标记 计算活动对象将要移动后的目的地址 更新活动对象的子对象指向新的地址 移动所有活动对象到头部，执行压缩 @gc_mark 标记阶段 扫描root根，这里是模拟的root，真实的root可以参考gc-try实现的扫描系统栈12for(int i = 0;i &lt; root_used;i++) gc_mark(roots[i].ptr); 12345678910void* gc_mark(void *ptr)&#123; //检查指针是否合法 /* marking */ FL_SET(hdr, FL_MARK); for (void* p = ptr; p &lt; (void*)NEXT_HEADER(hdr); p++) &#123; gc_mark(*(void **)p); &#125; return ptr;&#125; 常规操作，对当前指针进行检查，然后扫描当前指针执行的内存段，对child进行递归引用标记 @set_forwarding_ptr 计算移动地址 主要是遍历堆，然后计算活动对象应该被移动到的目的地址 123456789101112131415161718192021222324252627void set_forwarding_ptr(void)&#123; size_t i; Header *p, *pend, *pnext ,*new_obj; //遍历所有的堆内存 //因为所有的内存都从堆里申请，所以需要遍历堆找出待回收的内存 for (i = 0; i &lt; gc_heaps_used; i++) &#123; //pend 堆内存结束为止 pend = (Header *)(((size_t)gc_heaps[i].slot) + gc_heaps[i].size); p = gc_heaps[i].slot; new_obj = gc_heaps[i].slot; //堆的起始为止 因为堆的内存可能被分成了很多份，所以需要遍历该堆的内存 for (; p &lt; pend; p = NEXT_HEADER(p)) &#123; //查看该堆是否已经被使用 if (FL_TEST(p, FL_ALLOC)) &#123; //查看该堆是否被标记过 if (FL_TEST(p, FL_MARK)) &#123; p-&gt;forwarding = new_obj; //new_obj 继续下移 p个空间大小 new_obj = (void*)new_obj + p-&gt;size; &#125; &#125; &#125; &#125;&#125; 主要是设置双指针p,new_obj,同时从头部开始遍历，计算目的地址 p指针去寻找活动对象 找到活动对象后将当前new_obj地址记下，并向后移动n字节 @adjust_ptr 更新引用 初始时block3引用了block4,且block3应该移动到block1处，block4应该移动到block2处 更新后block3不再引用block4而是将要移动后的block2的位置 1234567891011121314151617181920212223242526void adjust_ptr()&#123; //遍历所有对象 for(int i = 0; i &lt; root_used; i ++)&#123; Header* forwarding = CURRENT_HEADER(roots[i].ptr)-&gt;forwarding; roots[i].ptr = forwarding+1; *(Header**)roots[i].optr = forwarding+1; &#125; //堆的起始为止 因为堆的内存可能被分成了很多份，所以需要遍历该堆的内存 for (p = gc_heaps[i].slot; p &lt; pend; p = NEXT_HEADER(p)) &#123; //可能申请的内存 里面又包含了其他内存 for (void* obj = p+1; obj &lt; (void*)NEXT_HEADER(p); obj++) &#123; //正确找到了 child 引用 GC_Heap *gh; Header *hdr; if (!(gh = is_pointer_to_heap(*(void**)obj))) continue; if((hdr = get_header(gh,*(void**)obj))) &#123; *(Header **) obj = hdr-&gt;forwarding + 1; //更新引用 &#125; &#125; &#125;&#125; 先更新root，因为所有活动对象的内存都发生了移动，需要更新栈变量存储的地址，也就是更新root所指向的地址 接下来就是遍历堆，这已经是第二次堆的遍历了，更新所有引用 @move_obj 移动对象最后就简单了，第三次堆遍历直接将所有对象拷贝到目的地址即可123456new_obj = p-&gt;forwarding;memcpy(new_obj, p, p-&gt;size);FL_UNSET(new_obj,FL_MARK);//空闲链表下移free_p = (void*)free_p + new_obj-&gt;size;total -= new_obj-&gt;size; 1234567//这个时候free_p 后面就是空闲列表了free_list = free_p;//total 需要单独计算剩余空间free_list-&gt;size = total;free_list-&gt;next_free = NULL;//方便测试 把空闲空间都清空memset(free_list + 1,0,total); 这里要注意下,当前free_p的后面一定是空闲空间，前面一定是被压缩后的活动对象的空间，直接和free_p即可 顺带同时清除垃圾空间,到此就全部完成了gc","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"},{"name":"compact","slug":"compact","permalink":"http://wiki.brewlin.com/tags/compact/"},{"name":"compact-lisp2","slug":"compact-lisp2","permalink":"http://wiki.brewlin.com/tags/compact-lisp2/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"},{"name":"算法实现","slug":"blog/gc-learning/算法实现","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/算法实现/"}]},{"title":"GC复制-标记清除","date":"2020-11-11T07:18:49.000Z","path":"wiki/blog/gc-learning/算法实现/5.GC复制-标记清除/","text":"github: https://github.com/brewlin/gc-learning copying-or-marking是一种组合算法，结合了复制法和标记清除法来优化复制算法无法完整利用空间(通常来说只能利用1/2堆)的问题 程序默认初始化N个堆，那么有:12345gc次数 from堆索引 to堆索引 标记清除堆范围----------------------------------------------1 heaps[0] heaps[1] heaps[2-(N-1)] 2 heaps[1] heaps[2] heaps[3-(N-1)]..... 这种组合方式既能结合了复制算法的优点，又能优化对应的缺点，目前来说空间利用率可以达到(N-1)/N,最多浪费1/N的空间 同时作为标记清除算法的对应堆也不用担心内存碎片的问题，因为每次gc后，from和to对换后进行自增，慢慢迭代后对所有堆进行了复制 复制算法部分和之前一样，gc标记清除部分也和之前一样，接下来分析如何组合应用 文件结构1234- Makefile 构建文件- copying.c 复制算法实现- mark-sweep.c 标记清除算法实现- test.c 测试用例 test:12&gt; make&gt; ./gc gc复制+标记清除算法主要流程如下: gc_init: 初始化N个堆，0作为to，1作为from gc_mark_or_copy: 搜索根，将所有可达对象进行拷贝或者标记 copy_reference: 复制过后，需要更新之前的引用关系 gc_sweep: 对其他堆执行标记清除算法 交换from,to, 进行递增 gc_init 初始化123456789101112131415void gc_init(size_t heap_size)&#123; //关闭扩充堆 auto_grow = 0; for (size_t i = 0; i &lt; gc_heaps_used; i++)&#123; //使用sbrk 向操作系统申请大内存块 void* p = sbrk(heap_size + PTRSIZE); gc_heaps[i].slot = (Header *)ALIGN((size_t)p, PTRSIZE); gc_heaps[i].size = heap_size; gc_heaps[i].slot-&gt;size = heap_size; gc_heaps[i].slot-&gt;next_free = NULL; //默认情况下0 是给 to堆使用的 不需要挂载到 free_list 空闲链表上 if(i) gc_free(gc_heaps[i].slot + 1); &#125;&#125; auto_grow = 0 关闭自动扩充堆，为了聚焦于算法本身，我们只允许存在固定个数的堆 除了我们规定的0作为to堆外，其他都需要更新到空闲链表上 所有当调用gc_malloc()时，分配的内存既可能来自from，也可能来自mark堆 gc阶段12345678910111213141516171819202122232425262728293031323334353637void gc(void)&#123; printf(\"执行gc复制----\\n\"); //每次gc前将 free指向 to的开头 gc_heaps[to].slot-&gt;size = gc_heaps[to].size; free_p = gc_heaps[to].slot; //递归进行复制 从 from =&gt; to for(int i = 0;i &lt; root_used;i++)&#123; void* forwarded = gc_mark_or_copy(roots[i].ptr); *(Header**)roots[i].optr = forwarded; //将root 所有的执行换到 to上 roots[i].ptr = forwarded; &#125; copy_reference(); //其他部分执行gc清除 gc_sweep(); //首先将free_p 指向的剩余空间 挂载到空闲链表上 //其实就是将原先to剩余的空间继续利用起来 //如果没有剩余空间了则不进行操作 if(free_p &lt; ((void*)gc_heaps[to].slot + gc_heaps[to].size)) gc_free((Header*)free_p+1); //在gc的时候 from已经全部复制到to堆 //这个时候需要清空from堆，但是在此之前我们需要将free_list空闲指针还保留在from堆上的去除 remove_from(); /** * 清空 from 空间前: * 因为空闲链表 还指着from空间的，所以需要更新free_list 指针 * */ memset(gc_heaps[from].slot,0,gc_heaps[from].size+HEADER_SIZE); //开始交换from 和to to = from; from = (from + 1)%10;&#125; 每次执行gc前，都会初始一个free_p指针，指向to堆的首地址，每发生一次拷贝，指针往后移，指向空余空间 扫描Root接着就是进行根的扫描，将所有可达对象执行gc_mark_or_copy,这个函数会进行判断 如果对象来自mark堆则不发生拷贝，直接标记即可 如果对象来自from堆则需要发生拷贝 1234void* forwarded = gc_mark_or_copy(roots[i].ptr);*(Header**)roots[i].optr = forwarded;//将root 所有的执行换到 to上roots[i].ptr = forwarded; 如果只是进行了标记，forwarded就是本身 如果执行了拷贝，forwarded执向的是to空间的新对象地址 执行拷贝和清除对发生了复制的空间进行引用更新 对标记清除区域执行清除123copy_reference();//其他部分执行gc清除gc_sweep(); 递增from-to空间1234567891011remove_from();/** * 清空 from 空间前: * 因为空闲链表 还指着from空间的，所以需要更新free_list 指针 * */memset(gc_heaps[from].slot,0,gc_heaps[from].size+HEADER_SIZE);//开始交换from 和toto = from;from = (from + 1)%10; gc执行完毕后,from区域作为新的to区域，需要清理from的依赖关系 最后resetfrom堆 开始交换from-to @gc_mark_or_copy 标记或拷贝123456789101112/** * 对该对象进行标记 或拷贝 * 并进行子对象标记 或拷贝 * 返回to空间的 body * @param ptr */void* gc_mark_or_copy(void* ptr)&#123; if(is_pointer_to_space(ptr,from)) return gc_copy(ptr); return gc_mark(ptr);&#125; 直接判断对象是否属于from堆来决定是拷贝还是标记 @gc_copy 复制阶段12345678910111213141516171819202122void* gc_copy(void *ptr)&#123; Header *hdr; GC_Heap *gh; if (!(gh = is_pointer_to_space(ptr,from))) return NULL; if (!(hdr = get_header(gh,ptr))) return NULL; assert(FL_TEST(hdr,FL_ALLOC)); //没有复制过 0 if(!IS_COPIED(hdr))&#123; //.....执行拷贝 //从forwarding 指向的空间开始递归 for (void* p = (void*)(forwarding + 1); p &lt; (void*)NEXT_HEADER(forwarding); p++) &#123; //对内存解引用，因为内存里面可能存放了内存的地址 也就是引用，需要进行引用的递归标记 //递归进行 引用的拷贝 gc_mark_or_copy(*(void **)p); &#125; //返回body return forwarding + 1; &#125; //forwarding 是带有header头部的，返回body即可 return hdr-&gt;forwarding+1;&#125; 和之前一样，只有在对child子对象递归判断时需要调用gc_mark_or_copy来决定是复制还是标记 检查是否已拷贝过123456//没有复制过 0if(!IS_COPIED(hdr))&#123;&#125;//forwarding 是带有header头部的，返回body即可return hdr-&gt;forwarding+1; 通过IS_COPIED(hdr)宏来判断标志位是否设置，是否已经拷贝过了 拷贝后，都需要返回拷贝后的指针 拷贝对象到to空间上面步骤如果没有拷贝过，则需要进行拷贝 从to空间分配一个空闲地址 1234//计算复制后的指针Header *forwarding = (Header*)free_p;//在准备分配前的总空间size_t total = forwarding-&gt;size; 进行拷贝,并更新原有对象标志位为COPIED 12345//分配一份内存 将源对象拷贝过来memcpy(forwarding, hdr, hdr-&gt;size);//标记为已拷贝FL_SET(hdr,FL_COPIED);hdr-&gt;flags = 1; 更新to空间的下一个空闲指针 1234//free 指向下一个 bodyfree_p += hdr-&gt;size;//free_p 执行的剩余空间需要时刻维护着((Header*)free_p)-&gt;size = total - hdr-&gt;size; 递归扫描child对象当前对象拷贝过后，还需要对其child子对象引用进行拷贝，直接进行内存扫描即可123456//从forwarding 指向的空间开始递归for (void* p = (void*)(forwarding+1); p &lt; (void*)NEXT_HEADER(forwarding); p++) &#123; //对内存解引用，因为内存里面可能存放了内存的地址 也就是引用，需要进行引用的递归标记 //递归进行 引用的拷贝 gc_copy(*(void **)p);&#125; @copy_reference 更新引用和复制法一样 @gc_sweep 执行清除在root扫描阶段，除了会复制from堆上的内存外，其他堆都需要执行标记对图中除from,to以外的所有未标记的内存进行回收，已标记的置为未标记等待下次gc在进行判断 12345678910111213141516171819202122232425//copying-or-mark/mark-sweep.c/** * 清除 未标记内存 进行回收利用 */void gc_sweep(void)&#123; size_t i; Header *p, *pend, *pnext; //遍历所有的堆内存 //因为所有的内存都从堆里申请，所以需要遍历堆找出待回收的内存 for (i = 0; i &lt; gc_heaps_used; i++) &#123; //to 和 from堆不需要进行清除 if(i == from || i == to) continue; //pend 堆内存结束为止 pend = (Header *)(((size_t)gc_heaps[i].slot) + gc_heaps[i].size); //堆的起始为止 因为堆的内存可能被分成了很多份，所以需要遍历该堆的内存 for (p = gc_heaps[i].slot; p &lt; pend; p = NEXT_HEADER(p)) &#123; //1. 是否已分配 //2. 是否标记 //3. 未标记回收 &#125; &#125;&#125; 在清除阶段过滤掉from,to堆,if(i == from || i == to) continue; 接下来和之前一样,找到未标记且分配过的内存，进行回收 @remove_from 回收from空间这里主要指的是在from已经完全拷贝到to空间之后，空闲链表free_list依然有空闲的节点指向from 这个时候就是找出free_list列表中还存留的from指针，找到后剔除","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"},{"name":"copying-or-marking","slug":"copying-or-marking","permalink":"http://wiki.brewlin.com/tags/copying-or-marking/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"},{"name":"算法实现","slug":"blog/gc-learning/算法实现","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/算法实现/"}]},{"title":"GC复制","date":"2020-11-11T07:17:05.000Z","path":"wiki/blog/gc-learning/算法实现/4.GC复制/","text":"github: https://github.com/brewlin/gc-learning 复制算法，安全解决了标记清除算法中内存碎片的问题，每次执行gc时会将存活的对象全部拷贝到新的堆上,并且紧挨着排列 缺点是需要空出一个堆来作为存放区，带来的结果就是不能充分利用堆，在当前的实现中，总共初始化两个堆from,to堆，各占1/2 文件结构123- Makefile 构建文件- copying.c 主要代码实现- test.c 测试用例 test:12&gt; make&gt; ./gc gc复制算法主要流程如下: gc_init: 这里固定生成2个堆,from，to gc_copy: 搜索根，将所有可达对象全部拷贝到to堆 copy_reference: 复制过后，需要更新之前的引用关系 gc_init 初始化123456789101112131415161718192021void gc_init(size_t req_size)&#123; auto_gc = 1; //关闭自动扩充堆 auto_grow = 0; //使用sbrk 向操作系统申请大内存块 void* from_p = sbrk(req_size + PTRSIZE ); from.slot = (Header *)ALIGN((size_t)from_p, PTRSIZE); from.slot-&gt;next_free = NULL; from.slot-&gt;size = req_size; from.size = req_size; gc_free((void*)(from.slot + 1)); DEBUG(printf(\"扩堆内存:%ld ptr:%p\\n\",req_size,from_p)); //使用sbrk 向操作系统申请大内存块 void* to_p = sbrk(req_size + PTRSIZE + HEADER_SIZE); to.slot = (Header *)ALIGN((size_t)to_p, PTRSIZE); to.slot-&gt;next_free = NULL; to.slot-&gt;size = req_size; to.size = req_size;&#125; auto_grow = 0 关闭自动扩充堆，为了聚焦于算法本身，我们只允许存在两个堆 接下来就是剩下两个堆，分别作为from,to堆使用 from作为内存分配的堆 to 作为每次gc后新的from堆(gc执行完后会swap(from,to)) gc阶段12345678910111213141516171819202122232425void gc(void)&#123; //每次gc前jiang free指向 to的开头 to.slot-&gt;size = to.size; free_p = to.slot; //递归进行复制 从 from =&gt; to for(int i = 0;i &lt; root_used;i++)&#123; void* forwarded = gc_copy(roots[i].ptr); *(Header**)roots[i].optr = forwarded; //将root 所有的执行换到 to上 roots[i].ptr = forwarded; &#125; copy_reference(); //清空 from memset(from.slot,0,from.size+HEADER_SIZE); //开始交换from 和to Header* tmp = from.slot; from.slot = to.slot; to.slot = tmp; //将空闲链表放到 to的最后一个索引 free_list = free_p;&#125; 每次执行gc前，都会初始一个free_p指针，指向to堆的首地址，每发生一次拷贝，指针往后移，指向空余空间 接着就是进行根的扫描，将所有可达对象执行gc_copy拷贝到to堆，也就是当前free_p指向的空间 注意这里*(Header**)roots[i].optr = forwarded就是root篇讲的关于引用地址更新的问题 拷贝完成后,接着就是更新引用 最后就是交换from和to空间，之前的to空间继续作为from来使用 @gc_copy 复制阶段复制阶段分为几个步骤: 校验指针是否合法并获取对象头 检查是否已经拷贝过 从to空间分配新的空间用于存储待复制的对象 递归扫描child引用对象 123456void* gc_copy(void * ptr)&#123; Header *hdr; if (!(hdr = get_header_by_from(ptr))) return NULL;&#125; 检查指针是否合法，并返回对象头 检查是否已拷贝过123456//没有复制过 0if(!IS_COPIED(hdr))&#123;&#125;//forwarding 是带有header头部的，返回body即可return hdr-&gt;forwarding+1; 通过IS_COPIED(hdr)宏来判断标志位是否设置，是否已经拷贝过了 拷贝后，都需要返回拷贝后的指针 拷贝对象到to空间上面步骤如果没有拷贝过，则需要进行拷贝 从to空间分配一个空闲地址 1234//计算复制后的指针Header *forwarding = (Header*)free_p;//在准备分配前的总空间size_t total = forwarding-&gt;size; 进行拷贝,并更新原有对象标志位为COPIED 12345//分配一份内存 将源对象拷贝过来memcpy(forwarding, hdr, hdr-&gt;size);//标记为已拷贝FL_SET(hdr,FL_COPIED);hdr-&gt;flags = 1; 更新to空间的下一个空闲指针 1234//free 指向下一个 bodyfree_p += hdr-&gt;size;//free_p 执行的剩余空间需要时刻维护着((Header*)free_p)-&gt;size = total - hdr-&gt;size; 递归扫描child对象当前对象拷贝过后，还需要对其child子对象引用进行拷贝，直接进行内存扫描即可123456//从forwarding 指向的空间开始递归for (void* p = (void*)(forwarding+1); p &lt; (void*)NEXT_HEADER(forwarding); p++) &#123; //对内存解引用，因为内存里面可能存放了内存的地址 也就是引用，需要进行引用的递归标记 //递归进行 引用的拷贝 gc_copy(*(void **)p);&#125; @copy_reference 更新引用上一步骤执行完拷贝以及递归拷贝子引用后，空间结构应该是这样 可以看到A,B被root直接引用，被拷贝到了to空间，而C被A引用，也同时被拷贝过去了 而且复制过后的空间，引用对象会连续排列在一起，如A,C,这同时也是复制算法的一个优点，加快缓存访问速度 引用更新上面讲了拷贝过后的A任然指向了From的C，需要更正这一点，完全复制依赖关系 1234567891011121314151617181920212223242526void copy_reference()&#123; //遍历所有对象 for(int i = 0; i &lt; root_used; i ++) &#123; void* start = roots[i].ptr; void* end = (void*)NEXT_HEADER(CURRENT_HEADER(start)); //可能申请的内存 里面又包含了其他内存 for (void *p = start; p &lt; end; p++) &#123; Header* hdr; //解引用 如果该内存依然是指向的from，且有forwarding 则需要改了 void *ptr = *(void**)p; if (!(hdr = get_header_by_from(ptr))) &#123; continue; &#125; if(hdr-&gt;forwarding)&#123; printf(\"拷贝引用 hdr:%p forwarding:%p\\n\",hdr,hdr-&gt;forwarding); *(Header**)p = hdr-&gt;forwarding + 1; break; &#125; &#125; &#125;&#125; 遍历所有的Root，判断是对象是否发生过拷贝if(hdr-&gt;forwarding) 将拷贝的引用更新*(Header**)p = hdr-&gt;forwarding + 1","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"},{"name":"copying","slug":"copying","permalink":"http://wiki.brewlin.com/tags/copying/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"},{"name":"算法实现","slug":"blog/gc-learning/算法实现","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/算法实现/"}]},{"title":"引用计数","date":"2020-11-10T07:15:55.000Z","path":"wiki/blog/gc-learning/算法实现/3.引用计数/","text":"github: https://github.com/brewlin/gc-learning 所有gc算法中引用计数最为特别, 相较于其他算法来说最明显的特点有: 没有 stw(stop the world)时间 没有 root的概念，不需要扫描栈 当然相较于其他算法来说弱点也很明显: 增加了应用方的负担(需要时刻注意增减引用计数) 通常需要搭载其他算法才能解决无法回收循环引用的问题 其他gc算法中基本没有对外提供api调用，对于应用层无感知，引用计数则需要开发者自己来维护跟踪分配的对象 gc_inc: 引用计数 + 1 通常在更低级的分配器中默认指向 gc_dec: 引用计数 - 1 为0 则直接回收 gc_update: 许多情况下需要保证计数正确 gc_inc 增加计数123456789101112131415161718void gc_inc(void *ptr)&#123; //该内存属于哪个堆 GC_Heap *gh; //该内存的header Header *hdr; //find header if (!(gh = is_pointer_to_heap(ptr)))&#123;// printf(\"not pointer\\n\"); return; &#125; if (!(hdr = get_header(gh, ptr))) &#123; printf(\"not find header\\n\"); return; &#125; hdr-&gt;ref++;&#125; is_pinter_to_heap：常规操作，进行合法性指针检查 get_header： 获取指针的头部，在确保该指针一定安全的情况下可以直接使用CURRENT_HEADER获取对象头 hdr-&gt;ref++: 直接递增即可 gc_dec 减少计数减少计数的步骤要多一点，除了递减计数外还要执行一次检查，如果小于等于0则直接回收垃圾12345678910111213141516void gc_dec(void *ptr)&#123; GC_Heap *gh; Header *hdr; //find header if (!(gh = is_pointer_to_heap(ptr)))&#123; return; &#125; if (!(hdr = get_header(gh, ptr))) &#123; printf(\"not find header\\n\"); return; &#125; hdr-&gt;ref -- ; //接下来执行计数检查&#125; 和递增计数一样，找到对象头后，直接hdr-&gt;ref--计数即可，接下来看当计数为0时执行回收的情况123456789101112if (hdr-&gt;ref == 0) &#123; //对引用对象进行递归标记 void *p; void *end = (void*)NEXT_HEADER(hdr); //对引用进行递归 减引用 for (p = ptr; p &lt; end; p++) &#123; //对内存解引用，因为内存里面可能存放了内存的地址 也就是引用，需要进行引用的递归标记 gc_dec(*(void **)p); &#125; //回收 gc_free(ptr);&#125; 对[p,end]的内存段进行扫描，递归进行child引用递归更新计数 最后调用gc_free释放当前内存块即可 gc_update 引用更新p-&gt;next指向p2，在进行指针更新过后，没有任何对象在继续引用p2，所以在更新p-&gt;next的时候应该同时要gc_dec(p-&gt;next)来保证p2的计数正确,这就是gc_udpate的作用 123456void gc_update(void *ptr,void *obj)&#123; gc_inc(obj); gc_dec(*(void**)ptr); *(void**)ptr = obj;&#125; 对目标对象obj进行计数 += 1，因为他被当前对象引用了 如上面所说需要将被更新的指针进行计数 -= 1 最后是更新即可 使用上面的例子:1234567891011typedef struct obj&#123; struct obj* next; int value;&#125;Obj;Obj* p = gc_malloc(sizeof(Obj));p-&gt;next = gc_malloc(sizeof(obj));Obj* p2 = gc_malloc(sizeof(Obj));gc_update(&amp;p-&gt;next,p2);//等价于 p-&gt;next = p2;","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"},{"name":"reference-count","slug":"reference-count","permalink":"http://wiki.brewlin.com/tags/reference-count/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"},{"name":"算法实现","slug":"blog/gc-learning/算法实现","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/算法实现/"}]},{"title":"标记清除-多链表法","date":"2020-11-09T13:29:59.000Z","path":"wiki/blog/gc-learning/算法实现/2.标记清除-多链表法/","text":"github: https://github.com/brewlin/gc-learning 多链表法相较于单链表法提升了分配速度,在之前的gc_malloc分配中都是采用的单链表，在分配的时候需要去搜索单链表 多链表的好处就是省去了去查找块的时间，直接就获取了最近的空闲块 默认创建33个空闲链表Header *free_list[33]:123456789101112131415* 请求大小 bytes 对齐后的大小 bytes 空闲链表的索引* ----------------------------------------------------------------* 1-8 8 0* 9-16 16 1* 17-24 24 2* 25-32 32 3* 33-40 40 4* 41-48 48 5* 49-56 56 6* 57-64 64 7* 65-72 72 8* ... ... ...* 241-248 248 30* 249-256 256 31* &gt; 256 32 文件结构12345- gc.c 堆实现- gc.h 头部定义- Makefile 构建文件- mark_sweep.c 主要代码实现- test.c 测试用例 test:12&gt; make&gt; ./gc 关于多链表的结构 接下来分析一下两种标记清除法的区别，标记和清除阶段都是一样的，主要需要分析下关于分配和释放的区别 gc_malloc 内存分配 根据size获取对应空闲链表中的索引 在对应的索引中进行搜索 如果步骤2没有搜索到则需要向操作系统申请一份内存扩充堆 计算索引1234567891011121314151617void* gc_malloc(size_t req_size)&#123; printf(\"gc_malloc :%ld\\n\",req_size); Header *p, *prevp; size_t do_gc = 0; if (req_size &lt;= 0) return NULL; //对齐 字节 req_size = ALIGN(req_size, PTRSIZE); int index = (req_size - 1) &gt;&gt; ALIGNMENT_SHIFT; if(index &gt; MAX_SLICE_HEAP) index = HUGE_BLOCK; printf(\"gc_malloc :%d size:%ld\\n\",index,req_size); //do sth...&#125; 传入的req_size先加上HEADER_SIZE后进行字节对齐 然后通过req_size - 1 &gt;&gt; 3来获得索引，等价于(req_size - 1) / 8,因为当前都是根据PTRSIZE(sizeof(void*))8字节对齐的 得到索引后再判断一下，如果大于MAX_SLICE_HEAP == 31,说明字节数过大。大内存块统一走索引为32的空闲链表 分配空间12345678910alloc://从空闲链表上去搜寻 空余空间prevp = free_list[index];//死循环 遍历for (p = prevp; p; prevp = p, p = p-&gt;next_free) &#123; //堆的内存足够 if (p-&gt;size &gt;= req_size) &#123; //... &#125;&#125; free_ist[index]处开始遍历该空闲链表，如果找到满足的情况进行分配后返回 扩充空间12345678910if (!do_gc &amp;&amp; auto_gc) &#123; gc(); do_gc = 1; goto alloc;&#125; //上面说明 执行了gc之后 内存依然不够用 那么需要扩充堆大小else if ((p = grow(req_size)) != NULL)&#123; goto alloc;&#125;return NULL; 当无空闲链表可用时，先进行gc后进行grow新分配一份内存 如果都失败了则返回NULL 释放阶段释放和之前的差不多，区别就是要对应索引 12345678910111213void gc_free(void *ptr)&#123; DEBUG(printf(\"start free mem:%p\\n\",ptr)); Header *target, *hit; int index; //通过内存地址向上偏移量找到 header头 target = (Header *)ptr - 1; //回收的数据立马清空 memset(ptr,0,target-&gt;size); index = (target-&gt;size - 1) &gt;&gt; ALIGNMENT_SHIFT;&#125; 根据字节数计算出索引 这里和之前的释放还是有点区别12345678910//如果是小内存 不需要合并直接挂到最新的表头即可if(index &lt;= MAX_SLICE_HEAP)&#123; if(free_list[index])&#123; target-&gt;next_free = free_list[index]-&gt;next_free; free_list[index]-&gt;next_free = target; &#125;else&#123; free_list[index] = target; &#125; return;&#125; 现在不需要遍历空闲链表找到合适的位置进行插入和合并了,只需要插入表头即可,效率要高很多，复杂度为O(1) 只有大内存块继续走之前的合并流程 标记阶段和mark-sweep篇标记阶段一样的 清除阶段和mark-sweep篇清除阶段一样的 清除过后的情况应该是这样","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"},{"name":"mark-sweep","slug":"mark-sweep","permalink":"http://wiki.brewlin.com/tags/mark-sweep/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"},{"name":"算法实现","slug":"blog/gc-learning/算法实现","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/算法实现/"}]},{"title":"标记清除算法","date":"2020-11-09T13:28:59.000Z","path":"wiki/blog/gc-learning/算法实现/1.标记清除算法/","text":"github: https://github.com/brewlin/gc-learning 标记-清除 算法主要分为两个过程:标记O(N)、清除O(N),接下来讲解gc的代码实现 文件结构123- Makefile 构建文件- mark_sweep.c 主要代码实现- test.c 测试用例 test:12&gt; make&gt; ./gc gc阶段12345678void gc(void)&#123; //垃圾回收前 先从 root 开始 进行递归标记 for(int i = 0;i &lt; root_used;i++) gc_mark(roots[i].ptr); //标记完成后 在进行 清除 对于没有标记过的进行回收 gc_sweep();&#125; 对根进行遍历，不清楚根可以去看(什么是Root?),进行可达性标记 进入清除阶段，将所有垃圾进行回收，释放可用空间，更新空闲链表 标记清除的实现主要就是标记(marked)，通过对根的访问，对所有可以追踪到的对象都进行标记mark = 1，标记阶段就完成任务了 清除阶段会遍历整个堆，所以复杂度是O(N)，随着堆的增加而呈线性增长，清除阶段会对每份内存进行判断，如果mark = 0则认定为垃圾对象，进行回收。 整个gc阶段就完成了，如果有释放垃圾，此时新分配的内存就可以重复利用刚才释放的空间了 标记阶段接下来详细了解一下标记阶段，标记阶段主要完成四件事 判断当前指针是否合法 进行标记,如果已经标记过则不需要再次标记 对当前对象进行标记 对child引用进行递归标记 检查指针是否合法12345678910111213141516171819void gc_mark(void * ptr)&#123; GC_Heap *gh; Header *hdr; /* mark check */ if (!(gh = is_pointer_to_heap(ptr)))&#123; return; &#125; if (!(hdr = get_header(gh, ptr))) &#123; return; &#125; if (!FL_TEST(hdr, FL_ALLOC)) &#123; return; &#125; if (FL_TEST(hdr, FL_MARK)) &#123; return; &#125;&#125; is_pointer_to_heap: 判断传入的指针是否是堆里的合法内存，通过地址范围判断 get_header: 获取指针的对象头 FL_*： 这个开头的是一些宏定义，可以进行位操作，这里是判断header-&gt;flags有没有设置 FL_ALLOC内存分配标志 FL_TEST: 这里判断如果已经标记过了，不需要再次标记 标记对象1234//...../* marking */FL_SET(hdr, FL_MARK);//..... 这里展开就是:1((Header*)hdr)-&gt;flags |= 0x2 对对象头进行标记，表明当前对象是可达对象，是合法对象，不能被清除 递归进行child标记关于引用的标记其实就是遍历当前内存的地址空间，对每一个字节逐字扫描，发现了合法指针就进行标记,例如:12345678910void main()&#123; typedef struct obj&#123; int value; struct obj* next; &#125;Obj; Obj* ptr = gc_malloc(sizeof(Obj)); ptr-&gt;next = gc_malloc(sizeof(Obj)); ptr-&gt;next-&gt;next = gc_malloc(sizeof(Obj));&#125; 如果对p进行了标记，那么ptr-&gt;next也应该被标记，因为他们之间有引用关系，怎么做到的呢 对ptr的内存段start到end这个区间进行遍历12345//进行child 节点递归 标记for (void* p = ptr; p &lt; (void*)NEXT_HEADER(hdr); p++) &#123; //对内存解引用，因为内存里面可能存放了内存的地址 也就是引用，需要进行引用的递归标记 gc_mark(*(void **)p);&#125; 正常情况下遍历到(void*)ptr + sizeof(int)处应该就是p-&gt;next的地址，如此递归不放过任何的角落 gc_mark(ptr) gc_mark(ptr-&gt;next) gc_mark(ptr-&gt;next-&gt;next) 标记完应该是这样的 清除阶段清除阶段就简单啦，直接搜索堆，将所有的已使用却没标记的内存释放 遍历gc_heaps数组 12345678910111213void gc_sweep(void)&#123; size_t i; Header *p, *pend, *pnext; //遍历所有的堆内存 //因为所有的内存都从堆里申请，所以需要遍历堆找出待回收的内存 for (i = 0; i &lt; gc_heaps_used; i++) &#123; //pend 堆内存结束为止 pend = (Header *)(((size_t)gc_heaps[i].slot) + gc_heaps[i].size); //do ... &#125;&#125; 搜索heap查看该分块是否已经分配FL_ALLOC,没有该标志说明是空闲块，不需要理会 1234567//堆的起始为止 因为堆的内存可能被分成了很多份，所以需要遍历该堆的内存for (p = gc_heaps[i].slot; p &lt; pend; p = NEXT_HEADER(p)) &#123; //查看该堆是否已经被使用 if (FL_TEST(p, FL_ALLOC)) &#123; //do.. &#125;&#125; 解除标志，如果没有被标记过说明是垃圾: 进行gc_free 1234567891011//查看该堆是否被标记过if (FL_TEST(p, FL_MARK)) &#123; DEBUG(printf(\"解除标记 : %p\\n\", p)); //取消标记，等待下次来回收，如果在下次回收前 //1. 下次回收前发现该内存又被重新访问了，则不需要清除 //2. 下次回收前发现该内存没有被访问过，所以需要清除 FL_UNSET(p, FL_MARK);&#125;else &#123; DEBUG(printf(\"清除回收 :\\n\")); gc_free(p+1);&#125; 清除过后的堆应该是这样的:","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"},{"name":"mark-sweep","slug":"mark-sweep","permalink":"http://wiki.brewlin.com/tags/mark-sweep/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"},{"name":"算法实现","slug":"blog/gc-learning/算法实现","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/算法实现/"}]},{"title":"什么是Heap","date":"2020-11-09T13:28:59.000Z","path":"wiki/blog/gc-learning/前言/2.什么是heaps/","text":"github: https://github.com/brewlin/gc-learning heap也就是堆，本意应该是系统堆的概念的，现代的语言为了加快内存分配速度，基本上都会自己预先分配一块大内存，也可以叫做内存池。这块大内存就是用户态的堆 在gc概念中就是heap,例如在标记类算法中，有一个gc环节叫做清除(sweep)，也就是回收垃圾，那么要实现这个功能，就要对heap进行遍历找出待回收的垃圾,所以这个堆就是我们用户态的一块大内存，非系统的堆 heap有以下api: gc_malloc 内存分配 gc_free 内存回收(搭载了gc的heap，不需要用户显示调用) is_pointer_to_heap 是否是heap中申请的内存 接下来看下当前是如何管理内存的 heap的结构 相关结构体GC_HEAP：维护堆信息1234typedef struct gc_heap &#123; Header *slot; size_t size;&#125; GC_Heap; slot 指向从操作系统申请的内存首地址,默认4k,也就是操作系统的一页大小 size 每个heap的内存大小 Header: 实际上每份分配的内存都是默认会用掉一个头部空间12345678typedef struct header &#123; size_t ref; //引用计数中使用，其他算法忽略 size_t flags; //marked,remembered,copied size_t size; //当前内存块大小 size_t age; //分代回收中使用，表示年龄 struct header *next_free; //回收链表中使用，指向下一个空闲内存 struct header *forwarding;//复制算法中使用, 指向拷贝后的新内存地址&#125; Header; 为了更好的描述gc算法的实现，各种算法的公用标志都统一放到同一个header中，实际中肯定不能这么搞，太耗费空间了，很多都是用位来标记 ref 在引用计数中代表被引用的次数 flags 有多个位标记 size 指示当前内存块的大小 注意:size = sizeof(Header) + sizeof(Obj) 是包含了当前头部信息了的 age 分代回收中表示年龄 next_free 指向下一个空闲的内存,在内存分配的时候直接通过该字段来遍历空闲内存 forwarding 复制类算法中指向了新地址 header头 每个用户申请的内存都有一个隐形的头部,例如: gc_alloc(16) 实际申请了 16 + sizeof(header) 那么返回给用户的地址其实是 ptr + sizeof(header).同样的也可以通过 ptr-sizeof(header) 拿到header头 宏定义和全局变量12345678/* marco */#define TINY_HEAP_SIZE 4 * 1024 //计算指针 所占内存大小#define PTRSIZE ((size_t) sizeof(void *))#define HEADER_SIZE ((size_t) sizeof(Header))//堆的上限#define HEAP_LIMIT 100000 //字节对齐 向上取整#define ALIGN(x,a) (((x) + (a - 1)) &amp; ~(a - 1))#define NEXT_HEADER(x) ((Header *)((size_t)(x+1) + (x-&gt;size- HEADER_SIZE))) //[ [header] x-&gt;size [header] x-&gt;size ....]#define CURRENT_HEADER(x) ((Header *)x - 1) ALIGN 是向上进行地址对齐，ALIGN(6,8) == 8, ALIGN(9,8) == 16 NEXT_HEADER 方便直接获取下一个连续内存地址 CURRENT_HEADER 这个宏需要注意的一点是:需要自己保证传入的指针已经确认是堆里分配的，否则会导致不可预料的错误 一些flags 标志位1234567891011/* flags */#define FL_ALLOC 0x1#define FL_MARK 0x2#define FL_COPIED 0x4#define FL_REMEMBERED 0x8#define FL_SET(x, f) (((Header *)x)-&gt;flags |= f)#define FL_UNSET(x, f) (((Header *)x)-&gt;flags &amp;= ~(f))#define FL_TEST(x, f) (((Header *)x)-&gt;flags &amp; f)#define IS_MARKED(x) (FL_TEST(x, FL_ALLOC) &amp;&amp; FL_TEST(x, FL_MARK))#define IS_COPIED(x) (FL_TEST(x, FL_ALLOC) &amp;&amp; FL_TEST(x, FL_COPIED))#define IS_REMEMBERED(x) (FL_TEST(x, FL_ALLOC) &amp;&amp; FL_TEST(x, FL_REMEMBERED)) 一些全局变量123456/* global variable */extern Header *free_list;extern GC_Heap gc_heaps[HEAP_LIMIT];extern size_t gc_heaps_used;extern int auto_gc; //测试的时候 有时候需要关闭内存不够时执行gcextern int auto_grow; //测试的时候 有时候需要关闭内存不够时扩充堆 free_list 是一个单向链表，将所有heap的空闲空间串联起来,在执行gc_malloc时直接基于first-fit分配法遍历当前链表进行查找符合的大小内存,关于分配法: best-fit 遍历空闲链表，找出刚好符合那块内存，优点是减少了内存碎片，缺点是增加了分配时间 first-fit 找到第一块符合大小的空间，如果大于申请的则进行拆分，缺点显然是内存碎片 worse-fit 每次都去寻找最大的内存块 然后切割分配，增加了内存碎片 时间也不咋地，所以避免使用这种 gc_heaps 用户态堆，管理用户所有内存，默认每个heap 4k大小 auto_gc 为了方便测试增加的开关，表示在内存不够时是否需要去执行gc auto_grow 为了方便测试，表示在内存不够时是否需要立即扩充堆，新增一个4k页大小 gc_malloc分配内存分配流程，从内存池中查找一块空闲内存返回给申请方，主要流程如下: 遍历free_list链表，找到大于等于当前内存的块 刚好满足则直接更新下返回即可，否则需要拆分块大小 步骤1没找到可用的块，则考虑进行gc 步骤3依然无可用块，则考虑扩充堆 字节对齐1234//gc.creq_size += HEADER_SIZE;//对齐 字节req_size = ALIGN(req_size, PTRSIZE); 对申请的内存进行字节对齐,并且除了本身的size外，还要额外加上header的空间 搜索块123456789101112131415//gc.c//从空闲链表上去搜寻 空余空间prevp = free_list;//死循环 遍历for (p = prevp; p; prevp = p, p = p-&gt;next_free) &#123; //堆的内存足够 if (p-&gt;size &gt;= req_size) &#123; if (p-&gt;size == req_size)&#123; //刚好满足 &#125;else&#123; //需要拆分当前块 &#125; &#125; 直接遍历free_list空闲链表，前提是这个free_list已经将所有可用内存串联在一起了，而这些主要是在gc_free中做到的 12345678910111213//gc.c// 从空闲列表上 移除当前的 堆，因为申请的大小刚好把堆消耗完了if (p-&gt;size == req_size)&#123; if(p == prevp) free_list = prevp = p-&gt;next_free; else prevp-&gt;next_free = p-&gt;next_free; &#125;else&#123; prevp = (void*)prevp + req_size; memcpy(prevp,p,HEADER_SIZE); prevp-&gt;size = p-&gt;size - req_size; &#125; 如果空闲块刚刚好，则直接将空闲块移除链表，然后返回即可 如果空闲块比较大，则需要进行拆分,拆分从块起始处开始拆分 12345678910p-&gt;size = req_size;free_list = prevp;//给新分配的p 设置为标志位 fl_alloc 为新分配的空间printf(\"%p\\n\",p);p-&gt;flags = 0;p-&gt;ref = 1;FL_SET(p, FL_ALLOC);//设置年龄为0p-&gt;age = 0;p-&gt;forwarding = NULL; 这里是对新分配的块进行初始化操作，比如标志位置0等 12345678910//gc.cif (!do_gc &amp;&amp; auto_gc) &#123; gc(); do_gc = 1; goto alloc;&#125;else if(auto_grow)&#123; //上面说明 执行了gc之后 内存依然不够用 那么需要扩充堆大小 p = gc_grow(req_size); if(p != NULL) goto alloc;&#125; 扩充堆&amp;gc上面如果没有找到可用的空闲块，则需要考虑进行辅助操作，gc or grow 接下来看看grow扩充一个堆的逻辑:12345678910111213141516171819202122//gc.cHeader* gc_grow(size_t req_size)&#123; Header *cp, *up; if (!(cp = add_heap(req_size)))&#123; return NULL; &#125; up = (Header *) cp; if(free_list == NULL)&#123; memset(up + 1,0,up-&gt;size - HEADER_SIZE); free_list = up; up-&gt;flags = 0; return free_list; &#125;else&#123; gc_free((void *)(up+1)); &#125; return free_list;&#125; 通过add_heap 申请一块最小为4k的空间 如果空闲链表为空则直接替换上去，返回 gc_free不但可以释放小内存块，也可以将新的堆串联到空闲链表上 这里基本就完成了内存块的分配 gc_free释放释放的流程要稍微多一点，主要分为三个步骤: 格式化待释放的内存 找到内存所对应的位置 挂载的链表上后结束 格式化格式化内存12345678910//gc.cvoid gc_free(void *ptr)&#123; Header *target, *hit,*prevp; //调用方需要保证内存是合法的当前堆内存，否则就会发生段错误 target = (Header *)ptr - 1; //回收的数据立马清空 memset(ptr,0,target-&gt;size-HEADER_SIZE); target-&gt;flags = 0; 特殊情况特殊情况一:free_list为空时直接替换free_list返回即可123456//空闲链表为空，直接将当前target挂到上面if(free_list == NULL)&#123; free_list = target; target-&gt;flags = 0; return;&#125; 特殊情况二:当前内存在free_list头部123456if(NEXT_HEADER(target) == free_list)&#123; target-&gt;size += (free_list-&gt;size); target-&gt;next_free = free_list-&gt;next_free; free_list = target; return;&#125; 直接将当前target合并到空闲链表头部 定位内存在堆中的位置定位待回收内存在堆中的位置，这个步骤是为了合并，相邻的两块内存必须要合并，否则会造成即使空闲空间足够但是依然不能够分配的窘迫 123456789101112//搜索target可能在空闲链表上的区间位置prevp = free_list;for(hit = prevp; hit &amp;&amp; hit-&gt;next_free ; prevp = hit,hit = hit-&gt;next_free)&#123; //刚好 target就在 [hit,hit-&gt;next_free] 之间 if(target &gt;= hit &amp;&amp; target &lt;= hit-&gt;next_free)&#123; break; &#125; //跨堆的情况 说明target在两个堆之间 (heap1_end,heap2_start) if(hit &gt;= hit-&gt;next_free &amp;&amp; (target &gt; hit || target &lt; hit-&gt;next_free)) break;&#125; 主要分为4种情况: target 属于右区间 1234567//1. 判断右区间 如果target属于右区间 则合并if (NEXT_HEADER(target) == hit-&gt;next_free) &#123; target-&gt;size += hit-&gt;next_free-&gt;size; target-&gt;next_free = hit-&gt;next_free-&gt;next_free;&#125;else &#123; target-&gt;next_free = hit-&gt;next_free;&#125; 这个时候说明NEXT_HEADER(target) == hit-&gt;next_free成立，需要合并target + hit-&gt;next_free target不属于右区间 如果右区间没有相邻，则直接插入hit-&gt;next_free前就行了 target 属于左区间 12345678//2. 判断左区间 如果target属于左区间 则合并if (NEXT_HEADER(hit) == target) &#123; /* merge */ hit-&gt;size += target-&gt;size; hit-&gt;next_free = target-&gt;next_free;&#125;else &#123; hit-&gt;next_free = target;&#125; 这个时候NEXT_HEADER(hit) == target成立，合并左区间 target 不属于左区间 直接挂在hit后就可以了 如果是新初始化的扩充堆基本上都不会触发上面的条件，直接挂到free_list尾节点即可","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"},{"name":"前言","slug":"blog/gc-learning/前言","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/前言/"}]},{"title":"GC算法分析与实现","date":"2020-11-09T13:28:59.000Z","path":"wiki/blog/gc-learning/GC算法分析与实现/","text":"github: https://github.com/brewlin/gc-learning 本系列文章主要阅读垃圾回收的算法与实现一书进行的实现解说，主要因为之前没有完整的gc算法实现的代码样例，书中各种实现都是基于伪码讲解，虽能理解作者的意思但难免还是有些抽象 遂写这些文章，记录下自己在学习算法理论并实际实现的过程。后续会追加分析其他语言的gc实现，深入理解生产级别是如何应用gc，以及如何极限的优化gc性能 目录前言 什么是root根? 什么是heaps堆? 算法实现 标记清除算法 - 基础实现 标记清除算法 - 多空闲链表法 引用计数算法 GC 复制算法 复制+标记清除 - 组合实现的多空间复制算法 标记压缩算法 - 基础实现 标记压缩算法 - two_finger实现 保守式gc算法 - 当前都是基于保守式gc算法 分代垃圾回收 - 复制算法+标记清除组合实现 增量式垃圾回收 - 三色标记 OS 环境参数123456&gt; gcc -vThread model: posixgcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)&gt; uname -aLinux ubuntu 4.4.0-157-generic #185-Ubuntu SMP Tue Jul 23 09:17:01 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux 关于测试每个算法实现目录都有test.c,都是对当前算法的简单逻辑验证 根目录有一个auto_test.sh 脚本可以一次性跑全部的测试用例123&gt; cd gc-learning&gt; dos2unix auto_test.sh&gt; sh auto_test.sh 代码结构1234567891011121314gc-learning----- gc.c----- gc.h----- mark-sweep ----- mark-sweep-mulit-free-list----- reference-count----- copying----- copying-or-mark----- compact-lisp2----- compact-two-finger----- generational----- tri-color-marking 所有的gc算法都依赖于公用gc.c中的的heaps堆内存池实现，可以先看什么是堆?了解内存管理 gc.c和gc.h是公用内存实现","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"}]},{"title":"什么是Root","date":"2020-11-09T13:28:59.000Z","path":"wiki/blog/gc-learning/前言/1.什么是roots/","text":"github: https://github.com/brewlin/gc-learning 讲root根之前我们要先理解什么是gc 回收，怎么定义垃圾等等,区别垃圾可以简单这么理解: 如果某对象没有被任何地方引用 - 垃圾对象 如果某对象至少还有一次被引用 - 合法对象 那么如何辨别对象没有被任何地方引用呢，这就是root的作用了 当前root的定义root根在不同场景有不同的意思，但有一点不变通过root能够访问到的对象一定是合法对象，则不应该被清除 root通常有以下的形式表示: 全局变量空间 寄存器 函数栈 并非只有上面的空间才能成为根,通常情况下对于动态运行时语言来说，都会在程序层面创建一个集合，然后自己来管理分配的对象，实现了根对象的管理 当前系列的gc实现不会真的去搜索上面的这些区域去实现根的查找,因为这样有些复杂而且不方便测试和演示 为了更加集中于gc算法的实现表示，采用了一个roots数组来作为根，有如下的规则: 只要是存在数组里的对象，都称为可达对象，一定是合法对象，不可以回收 只要不在数组里的对象，都是不可达对象，作为垃圾需要回收(被引用的内存除外) root结构体定义root结构体的定义12345//gc.htypedef struct root_&#123; void *ptr; //从heap中申请的内存地址 void *optr;//用户栈变量的地址&#125;root; ptr 指向了我们从heaps中分配的内存地址,也就是用户使用的对象 opr 指向了用户变量的地址，这里讲一下这个成员的作用: 在有些算法中，例如gc复制算法,在执行gc之后，也许当前对象不是垃圾对象不会被回收,但是:当前对象的内存发生了拷贝，内存位置发生了改变12Obj* p = gc_malloc(sizeof(Obj));gc(); 例如这种情况，optr的作用就体现出来了，在发生gc复制后，p本来应该指向新的空间，但是如果不更新p的值的话那么就会导致异常 因为我们的根保留了引用对象的地址(临时变量基本都是存储在栈上的，其实就是保留了栈的地址rbp - offset),这样只需要在gc执行复制的时候将引用对象一并修改了即可 root全局数组的定义123#define ROOT_RANGES_LIMIT 100000extern size_t root_used;extern root roots[ROOT_RANGES_LIMIT]; 为了方便测试，直接在栈上分配了默认100000大小的根,通过root_used来记录根对象的个数 添加root12Obj* p= gc_malloc(Obj);add_roots(&amp;p); 通过add_roots将对象加入root，成为可达对象，那么只要一直在root中，当前对象永远不会被回收 &amp;p注意这里是引用，在上面部分说了，如果执行的内存被拷贝到新地址了，需要同时更新p的地址 Real Root 尝试上面基本都是讲的模拟的根，那么我们来尝试一下可不可以实现真正意义的根访问呢 这里的测试主要分为寄存器的访问，系统栈的遍历搜索 完整代码可以在gc-try下测试 寄存器的扫描首先来统计一下我们在程序运行期间能够使用到的寄存器 函数参数寄存器: rdi,rsi,rdx,rcx,r8,r9 多的就存放在栈上了不用管 通用寄存器 : rax,rbx,rbp,rsp,%10-%15 不严谨的说上面这些寄存器是我们最常用的通用寄存器，也就是说寄存器里面可能存储着有我们的对象，需要我们gc的时候进行扫描1234567891011121314void scan_register()&#123; void *reg; if(reg = get_sp()) gc_mark(*(void**)reg); if(reg = get_bp()) gc_mark(*(void**)reg); if(reg = get_di()) gc_mark(*(void**)reg); if(reg = get_si()) gc_mark(*(void**)reg); if(reg = get_dx()) gc_mark(*(void**)reg); if(reg = get_cx()) gc_mark(*(void**)reg); if(reg = get_r8()) gc_mark(*(void**)reg); if(reg = get_r9()) gc_mark(*(void**)reg); if(reg = get_ax()) gc_mark(*(void**)reg); if(reg = get_bx()) gc_mark(*(void**)reg);&#125; 上面相关的函数可以在这里找到/gc-try/root.s 系统栈的扫描这里是gc过程的一部分遍历root1234567//现在开始是真正的扫描系统栈空间void * cur_sp = get_sp();//高低往低地址增长assert(sp_start &gt;= cur_sp);for (; cur_sp &lt; sp_start ; cur_sp += 4)&#123; gc_mark(*(void**)cur_sp);&#125; 通过get_sp() 直接获取当前的系统栈顶,也就是rsp寄存器的地址 sp_start 是我们在main开始前记录的栈起始位置 [sp_start,cur_sp] 这个区间就是我们当前的栈范围，直接扫描整个区间就可以访问我们所有的可达变量 (void**)cur_sp 是一个解引用操作，此时获取的值就是我们的代码里的临时变量 要理解我们扫描栈的意义就要先理解什么是栈，一张图说明一下c的函数栈帧结构: 1234567891011121314151617181920212223 +--------------+ -&gt; 这里就是函数A的栈帧范围了 | | + | | | +--------------+ | | | | | arg(N-1) | -&gt; 参数超过6个后，其他参数就放在这里 | | | | +--------------+ | | | | |Return address| -&gt; 这里指向函数A的中断的下一个指令地址Stack grows down | | | | +--------------+ | | | | | %rbp | -&gt; 这里指向函数A的起始栈帧rbp | | | | +--------------+ -&gt; 下面就是函数B的栈帧，当前rbp | | | | | local(N-1) | -&gt; 函数B的本地变量 | | | v +--------------+ | | | | +--------------+ -&gt; 当前栈顶 上面get_sp()函数是通过汇编实现获取当前寄存器rsp的值，如下:12345.text.globl get_spget_sp: movq %rsp,%rax ret 其实就是简单的返回了rsp寄存器的值而已，翻译为c函数的话像这样:123void *get_sp()&#123; return register(rsp);&#125; 到这里就是实现了真正意义上的根root，只要当前栈未被释放，那么当前栈帧上能搜索到的的对象都是合法对象","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"gc-learning","slug":"blog/gc-learning","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/"},{"name":"前言","slug":"blog/gc-learning/前言","permalink":"http://wiki.brewlin.com/categories/blog/gc-learning/前言/"}]},{"title":"最小生成树","date":"2020-11-09T13:28:59.000Z","path":"wiki/blog/algorithm/最小生成树/","text":"什么是最小生成树 在一个有权图中，所有的边连接为一个图，那么用最少的边将所有节点连接起来且该连接和最小，可以称为最小生成树 如上图: 图中==红色边==连接起来的就是最小树，既然最小，那么图就是有权的（有可比较的数值） 最小生成树 一定有v-1条边 v是顶点，也就是每个点只有一条连接前置要求 带权无向图 (每个节点具有可比较的值) 针对连通图 应用场景举例 铁路线路构建 1234每个城市之间其实不需要都建立铁轨，只要保证所有的城市之间能够连通即可如上图:所有城市组成了一个图，而所有边是城市的连接.那么只有红色边是需要建立铁轨的，且保证了所有城市都有连通线路 电线布局 1依然如此，使用最短的路径来连接所有节点 求证思路假入我们有如下组成的图结构: 总共有a,b,c,d,e,f6个节点，且存在10条边，每条边上的数字代表了该路径权值. 拿上面铁轨来说就是每个城市之间的距离。现在需要求出最小生成树，也就是去掉无关的边 从a开始访问，将a的所有边加入最小堆中，且标记a为已访问` 123从a出发有3条边 a-b a-e a-c那么可以看到a-b的权值为1 最小，且b没有访问过那么a-b就一定是最小生成树的一条边，进行标记并去除最小堆 将b的所有连接边加入最小堆,并取出最小权值的边 12可以发现b-f在最小堆中权值最小，且f点未被访问过.那么b-f绝对是最小生成树中的一条边，对f进行标记并移除最小堆 将f对应的边加入最小堆，并取出最小权值的边 12f-c 权值为2，目前为堆中最小，且c未被访问过，则f-c为生成树的一条边进行标记，剔除最小堆 没有新加入边则，继续在堆中找出最小边 123发现有三个节点的权值相同，但有一点不同b-c a-c 两个边的点都被标记过了，所以需要剔除最后只剩下b-e 最小，则进行标记并剔除最小堆 加入e关联的边，继续找出堆中最小边 12a-e 已经访问过了，需要剔除e-d 最小，且d未访问过，则一定是最小生成树的边，进行标记、剔除 这样基本就全部访问完了，接下来就是剔除无关的边，最后得出如下最小生成树","tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"graph","slug":"graph","permalink":"http://wiki.brewlin.com/tags/graph/"},{"name":"tree","slug":"tree","permalink":"http://wiki.brewlin.com/tags/tree/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"algorithm","slug":"blog/algorithm","permalink":"http://wiki.brewlin.com/categories/blog/algorithm/"}]},{"title":"Goos-底层协程实现(三)","date":"2020-08-13T13:28:59.000Z","path":"wiki/blog/goos/Goos-底层协程实现(三)/","text":"本节主要讲解什么是多线程协程的投递、调度、以及切换的汇编实现 Goos-多线程协程实现简要 Goos-协程底层实现(一) Goos-线程协程隔离(二) Goos-线程切换实现(三) Goos-抢占调度实现(四) Goos-监控线程实现(五) 协程调度流程全局队列队列投递我们在php层创建一个协程的方法如下:123go(function())&#123; //do something...;&#125;); 调用go函数，将一个php函数参数传入协程调度器执行，这里go函数执行完毕之前是异步的，不会立即就执行该任务，而是将该任务投递到一个全局队列里，等待线程接收后处理 投递任务:1234567891011121314//coroutine/Coroutine.cpplong Coroutine::run()&#123; //投递到 proc 线程去执行该协程 if(proc == nullptr)&#123; cout &lt;&lt; \"未初始化线程\" &lt;&lt;endl; throw \"未初始化线程\"; &#125; proc-&gt;gogo(ctx); //本来是会新生成一个协程id返回的，但是目前没什么用 return 1;&#125; 主要是判断 线程调度器有没有初始化，proc == nullptr 调用全局proc-&gt;gogo(ctx) 将封装好的一个ctx协程投递到线程中去 全局队列结构123456789101112131415//runtime/Proc.hclass Proc&#123;public: //method ....public: //...省略其他字段 condition_variable cond; queue&lt;Context *&gt; tasks;private: vector&lt;thread&gt; workers; mutex queue_mu; bool stop;&#125;; cond 条件变量，用户获取锁的时候使cpu睡眠时等待唤醒的条件 tasks 为一个全局队列，用于接收投递的协程G workers 默认启动的线程M queue_mu 线程锁 新的协程创建后会投递到tasks队列，然后随机唤醒一个线程M来处理该协程:123456789//runtime/proc.cppvoid Proc::gogo(Context* ctx)&#123; unique_lock&lt;mutex&gt; lock(queue_mu); now = chrono::steady_clock::now(); this-&gt;tasks.emplace(ctx); cond.notify_one();&#125; 协程调度执行每个线程M的初始化执行后，会进入schedule事件循环，如果没有信号过来则默认会进入睡眠状态，等待唤醒后处理投递进来的协程G，并初始化协程环境后绑定当前M-G的关系后执行该php用户态函数123456789101112131415161718192021222324252627282930313233343536//runtime/pro.cppvoid Proc::schedule()&#123; for(;;)&#123; Context* ctx; Coroutine* co; //省略本地队列 。。相关逻辑 &#123; unique_lock&lt;mutex&gt; lock(this-&gt;queue_mu); this-&gt;cond.wait(lock,[this,rq]&#123; return this-&gt;stop || !this-&gt;tasks.empty(); &#125;); if(this-&gt;stop &amp;&amp; this-&gt;tasks.empty()) break; if(!this-&gt;tasks.empty())&#123; ctx = move(this-&gt;tasks.front()); this-&gt;tasks.pop(); co = static_cast&lt;Coroutine *&gt;(ctx-&gt;func_data); &#125; &#125; if(co == nullptr)&#123; cout &lt;&lt; \"co exception:\"&lt;&lt;co&lt;&lt;endl; continue; &#125; //当前线程分配到一个未初始化的G if(co-&gt;gstatus == Gidle) co-&gt;newproc(); //恢复被暂停的G else co-&gt;resume(); //G运行结束 销毁栈 if(ctx-&gt;is_end) co-&gt;close(); //省略一些其他的。。。。 &#125;&#125; 当前线程处于cpu睡眠态，等待唤醒的方式目前有两个情景 gogo() 协程投递的时候会触发唤醒随机线程 cond-&gt;notify_one() sysmon 监控线程有一些管理任务会涉及当前线程去处理任务 pop tasks 出队列拿到一个协程G任务 判断该G是新协程还是需要再次恢复的调度协程 新协程为co-&gt;newproc() 开始走新协程的调用 中断协程的恢复走co-&gt;resume()恢复协程的继续运行 如果协程状态为close则回收该协程资源 协程的c栈内存模型协程的创建执行针对新协程的执行:1234567891011121314//coroutine/Coroutine.cppvoid Coroutine::newproc()&#123; callback-&gt;is_new = 0; callback-&gt;prepare_functions(this); PHPCoroutine::save_stack(&amp;main_stack); GO_ZG(_g) = this; //每次切入时出去时需要更新tick 和时间 GO_ZG(schedwhen) = chrono::steady_clock::now(); GO_ZG(schedtick) += 1; gstatus = Grunnable; ctx-&gt;swap_in();&#125; 准备当前G的php环境，比如拷贝当前G对应引用的php全局变量，类对象，外部引用等等,这个会在线程协程隔离中说明 保存当前php栈信息，如第一章中函数本质部分说的，在调用一个函数前，会将当前sp,bp,ss:ip等必要寄存器压栈保存，在函数放回的时候会找到该地址，然后进行跳转实现返回。不过这个是php栈 GO_ZG(_g) = this 将当前G绑定到M上 gstatus = Grunable 标记当前G运行状态 ctx-&gt;swap_in() 正式执行该协程 C栈内存结构首先是c栈的内存申请过程1234567//runtime/Context.cppContext::Context(run_func func,void *data):_fn(func),func_data(data)&#123; bp = new char[DEFAULT_STACK]; make_context(&amp;cur_ctx,&amp;context_run, static_cast&lt;void *&gt;(this),bp,DEFAULT_STACK);&#125; 创建一个8k的堆内存，用于实现c的函数栈 调用make_context 初始化该栈帧内存结构 在实际执行用户传递的php函数前还有一个包装流程:1234567891011121314//runtime/Context.cpp/** * 主要运行的函数 * @param arg */void Context::context_run(void *arg)&#123; Context *_this = static_cast&lt;Context *&gt;(arg); _this-&gt;_fn(_this-&gt;func_data); _this-&gt;is_end = true; GO_ZG(_g) = nullptr; _this-&gt;swap_out();&#125; 这里的_this-&gt;func_data就是协程G对象，实际执行单元 _this-&gt;_fn 是一个函数指针，指向PHPCoroutine.cpp::run(),该函数初始化php栈帧信息，准备执行实际的php函数 _this-&gt;_fn 执行完毕则代表该G生命周期完毕，否则说明当前G已经被暂停，切换出去了，等待恢复继续执行 _this-&gt;is_end =true 标志当前G 已结束, GO_ZG(_g) = nullptr 解绑当前G - M的绑定关系 _this-&gt;swap_out() 这里很重要，当前函数依然是在协程范围内，所以必须显式通过swap_out()模拟函数return返回到之前的函数调用，否则没有任何意义，因为cpu不知道下一条待执行的指令是什么，无法回到正常的执行流程 c栈的内存模型这里比较重要，需要将堆内存转换为函数栈，且将一些必要配置初始化，例如将协程G的函数地址压栈(压堆)，以及增加安全机制 通过调用make_context 将堆内存转换为普通c函数栈模型，为实现函数调用做准备1234567891011121314//runtime/asm/make_context.cpp#define NUM_SAVED 6void make_context (asm_context *ctx, run_func fn, void *arg, void *sptr, size_t ssize)&#123; if (!fn) return; ctx-&gt;sp = (void **)(ssize + (char *)sptr); *--ctx-&gt;sp = (void *)abort; *--ctx-&gt;sp = (void *)arg; *--ctx-&gt;sp = (void *)fn; ctx-&gt;sp -= NUM_SAVED; memset (ctx-&gt;sp, 0, sizeof (*ctx-&gt;sp) * NUM_SAVED);&#125; 检查fn是否存在 因为函数栈内存是从高地址往低地址增长，所以 sp寄存器指向的栈顶要指向堆的结束地址位置((void **)(ssize + (char *)sptr)) *--ctx-&gt;sp = (void *)abort; 其实就是压栈，将一个abort函数地址压栈，且sp地址自动下移，abort函数是一个保障机制，如果某个协程G没有实现跳转回主流程，则调用abort报异常 *--ctx-&gt;sp = (void *)arg; 将函数参数压栈，在跳转的时候可能需要传递参数，到时候通过popq %rdi将arg送入rdi寄存器实现函数传参 *--ctx-&gt;sp = (void *)fn 将函数地址压栈，cpu在执行时通过获取该地址后跳转，实现函数调用 ctx-&gt;sp - = 6; 腾出6个变量的位置，用于存储上下文信息，比如在函数切换前要保存之前的寄存器变量信息 协程切换的汇编解析协程切换的汇编实现为/runtime/asm/jump_context.s:12345678910111213141516171819202122.text.globl jump_contextjump_context: pushq %rbp pushq %rbx pushq %r12 pushq %r13 pushq %r14 pushq %r15 movq %rsp, (%rdi) movq (%rsi), %rsp popq %r15 popq %r14 popq %r13 popq %r12 popq %rbx popq %rbp popq %rcx popq %rdi jmpq *%rcx popq %rcx jmpq *%rcx 汇编指令解析 .text 标明下面是一块代码段，在cpu指令执行过程中能够确认他们是指令段而非数据段 .globl jump_context 这里相当于c语言声明一个函数名的作用，对于cpu来说函数其实就是一个指令地址，这里也是用于在连接过程中将当前函数的地址进行标记 保存上下文 保存当前函数的上下文，对于程序上下文来说，其实细分到cpu，就是保存该函数时刻的寄存器对应的值和函数栈bp,sp的位置，基本靠这些就可以标明当前某个函数的执行状态了123456789下面的6个寄存器应该符合调用者规约，也就是在调用其他函数前应该由调用者保存起来，防止在子函数中被篡改%rbx,%rbp,%r12,%r13,%r14,%r15 pushq %rbp 将当前函数栈底rbp寄存器保存起来 pushq %rbx 将基地址寄存器保存起来，bx操作评率较高，bx默认指 ds数据段，一般用作内存访问 pushq %r12 pushq %r13 pushq %r14 pushq %r15 函数参数 接受参数: jump_context() 接收两个参数，prev指针，其实就是当前c栈,next* 目标c栈，因为函传参的底层汇编实现是通过寄存器来实现的，所以prev,next参数默认是按照保存到rdi,rdx寄存器中 顺便提一下:通常如果参数比较少的话（一般6个作为界限），则通过寄存器进行传参数。顺序为:123%rdi,%rsi,%rdx,%rcx,%r8,%r9 依次对应func(arg1,arg2,arg3,arg4,arg5,arg6); 如果超过了6个，就需要栈来辅助接受函数参数了，如上图所示。在调用者函数栈顶前一个，则是存储的函数参数 函数栈祯切换这个就是核心功能了，我们知道在正常的函数调用执行流中，我们都是使用了程序装载前分配的那个系统栈，不出意外从程序开始到结束都是不断的复用该程序栈。但是由于协程的出现，基于堆内存模拟的函数栈。那么在调用函数的时候就必须切换栈如上图，只要是默认的c函数或者业务函数都是基于系统栈祯的，例如调用A函数的时候默认在系统栈祯下面使用新的空间来存储A函数的栈祯，都是使用的系统栈 而如果我们此时要进行协程调用，则需要将cpu的sp等寄存器切换到我们的协程B函数的栈祯首地址，那么cpu的执行流就会切换到协程B栈上执行，所有的变量内存都会依赖心的协程B栈，注意:毕竟协程B的栈是堆模拟出来的，所以是预分配有限制大小的内存，在使用的时候不要越栈，并且协程B栈执行完后一定要恢复到兄台你栈祯的继续执行 12movq %rsp, (%rdi)movq (%rsi), %rsp 这两条汇编指令实现了系统栈 - 协程栈的切换，rsp当前系统栈栈顶，rdi第一个函数参数,保存调用者的栈信息(可能是系统栈，也可能是协程切换了多次，也可能是协程栈本身)。rsi第二个函数参数,保存的被调用者函数的地址信息(可能是协程栈祯，也可能是协程结束后，准备切换为系统栈的栈祯) 恢复环境上下文到这里已经切换到了协程栈，远离的系统栈，下面的汇编指令是实现恢复上下文寄存器，在第一次协程创建的时候是空的，但是当切换多次后就会发现，者6个寄存器永远保持上一个协程状态的环境 123456popq %r15popq %r14popq %r13popq %r12popq %rbxpopq %rbp pop的过程如下，总的来说就是将栈上的变量恢复到寄存器中，实现函数状态的恢复，第一次协程是没有意义的因为默认是6个寄存器的占位符 函数的调用目前的函数栈祯如下1234567------------| abort |------------| arg |------------| func |----------- 可以看到我们的函数栈只剩下三个值了，接下来的汇编指令将pop栈，实现函数调用123popq %rcxpopq %rdijmpq *%rcx 这里有两次pop说明出栈了两个数据func,arg刚好对应我们的函数地址和函数参数地址， popq %rcx： 这里将函数地址保存到rcx寄存器,为什么选rcx寄存器呢，没啥区别，选啥都可以，反正就是为了拿到函数地址而已 pop %rdi : 这里就是将arg指针保存到rdi寄存器，前面说过函数传参按照顺序来说第一个参数的寄存器就是rdi所以讲arg指针保存到rdi寄存器实现函数传参 jmpq *%rcx: 这里就是真正执行的函数调用，rcx保存的是我们的函数地址，jumq 就是让cpu跳转到该函数指令地址执行，实现函数调用 协程栈收尾到这里的时候，说明程序已经崩溃了，目前协程栈内存模型:123------------| abort |------------ 如果执行到这里，说明我们的协程==没有切回主系统栈==,那么这里直接调用abort给一个通知 12popq %rcxjmpq *%rcx 执行abort()函数 总结我们通过自己申请一块堆内存来模拟函数栈实现函数调用是为了更好的控制该函数的生命周期，以此实现函数的暂停、恢复等操作，有点类似于线程，但是性能更好、代价更小，甚至和普通函数调用无差别，这就是协程、一种用户态线程","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"coroutine","slug":"coroutine","permalink":"http://wiki.brewlin.com/tags/coroutine/"},{"name":"thread","slug":"thread","permalink":"http://wiki.brewlin.com/tags/thread/"},{"name":"scheduler","slug":"scheduler","permalink":"http://wiki.brewlin.com/tags/scheduler/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"goos","slug":"blog/goos","permalink":"http://wiki.brewlin.com/categories/blog/goos/"}]},{"title":"Goos-底层协程实现(一)","date":"2020-08-10T13:28:59.000Z","path":"wiki/blog/goos/Goos-底层协程实现(一)/","text":"本节主要讲解什么是协程、协程的实现、php的协程封装的内容，从为什么我们需要协程到如何实现协程，主要讲解协程、php、c、汇编指令的相关关系，从整体窥探它的整个结构 Goos-多线程协程实现简要 Goos-协程底层实现(一) Goos-线程协程隔离(二) Goos-线程切换实现(三) Goos-抢占调度实现(四) Goos-监控线程实现(五) 协程本质协程最直观的就是我们将一个闭包函数当做参数丢给了某个任务去执行，那么实际执行的其实就是我们自定义的函数，如:12345678&lt;?phpRuntime::GOMAXPROCS(10);function task()&#123; echo \"start doing sth\";&#125;go(task);Runtime::wait(); 可以看到我们将task函数交给go去执行，某些情况下和我们直接task()调用无任何区别，那么我们为什么还要通过go来调用呢，因为我们想要更好的控制该函数的生命周期，试下一下如下场景: 网络等待导致当前进程阻塞与网络调用 123456function task()&#123; //maybe 10s+ waiting $data = scoket_read(fd); //then do sting&#125; 业务逻辑死循环导致进程挂起 1234567function task()&#123; for(;;)&#123; if(sth is true) then break loop; &#125;&#125; 单纯是需要利用多核cpu，且不想采用多进程的方式 如果我们直接就调用执行了task。上面的三种情况都会导致性能杀手或者进程卡死，有没有一种方法可以控制函数的执行并且能无需受到到所写的业务代码还要担心阻塞等心智负担呢。有没有办法能够充分利用多核实现并行执行呢，所以多线程协程才有了意义。 针对第一种网络阻塞等三方接口调用导致的阻塞，将该代码丢入协程调度器去执行，那么发生阻塞的时候会自动跳过当前函数，继续执行其他任务，完美解决当前问题。当然我们还需要一个契机去恢复上一次函数的继续执行，这就是后续要实现的poller网络轮训器来作为调度过程的一部分，当网络事件到来则恢复刚才暂停的函数继续去执行 如果某个函数长期占有cpu，导致其他函数得不到执行，这种情况就可以发起抢占，将当前函数从调度器中移除，继续执行其他的任务，很好的解决了进程卡死和效率低的问题 当然对于多线程来说本身就是可以利用多核cpu的，这样就更好的控制了并发 继续回到协程本质的话题，协程本质就是可以通过调度器来管理一个用户自定义的函数，且该自定义函数被执行的期间的任务可以称为协程，和直接调用函数的区别在于协程的整个期间可以由内由外来进行控制， 函数本质我们通过函数来将我们的业务逻辑划分为多个子集，为了更好的管理工程和设计，我们可以拿函数来作为例子讲解一下实际的执行过程 php函数的实现引用这里的文档:https://www.kancloud.cn/lifei6671/php-kernel/675135,来简单分析下函数的本质 php函数实际对应于c语言的zend_function结构体:123456789101112131415161718192021typedef union _zend_function zend_function;//zend_compile.hunion _zend_function &#123; zend_uchar type; /* MUST be the first element of this struct! */ struct &#123; zend_uchar type; /* never used */ zend_uchar arg_flags[3]; /* bitset of arg_info.pass_by_reference */ uint32_t fn_flags; zend_string *function_name; zend_class_entry *scope; //成员方法所属类，面向对象实现中用到 union _zend_function *prototype; uint32_t num_args; //参数数量 uint32_t required_num_args; //必传参数数量 zend_arg_info *arg_info; //参数信息 &#125; common; zend_op_array op_array; //函数实际编译为普通的zend_op_array zend_internal_function internal_function;&#125;; php实际有两种函数，一种是普通函数，另外一只是对象成员函数。 成员函数和普通函数的区别在于,底层zend_function指针内部的scope 会指向一个对象，普通函数则为NULL，成员函数则会指向当前的zend_class_entry对象指针来实现this功能 对于php函数还有两个区别,用户自定义函数和内部函数,虽然所有的函数都被包装成为了zend_function，但zend_function是一个联合体，所以不同类型的函数在结构上还是有区别的 php的内部函数、动态扩展提供的c函数等，这些都是直接存储了一个函数指针给php层面调用即可，即zend_function-&gt;internal_function指向的是c层面的函数指针，无需其他初始化操作 php用户自定义函数，这个时候就有点复杂了，这个层面是zend引擎通过词法、语法分析等将php代码翻译为opcode码、基本就是汇编代码，直接装到op_array中，在发生函数调用是,会将op_array载入全局execute_globals执行引擎，等待执行opcode码 c函数的实现c语言函数就显得非常纯粹了，完全是按照cpu的执行方式来进行思考的，需要完整的考虑内存如:堆、栈等信息，在c层面我们就能想到很多问题，那么我们来讲讲什么是堆？什么是栈? 对于cpu来说内部有多个寄存器，同一时间只能存储一个值，所以显然是不够的，我们的程序拥有无比复杂的变量定义和逻辑运算，例如x64位cpu有16个通用寄存器:1234通用: %rax %rbx %rdx %esi %edi %rbp %rsp %8-%15 栈段: %ss %sp码段: %cs %ip数据段: %ds,%es 即使这样依然是不够的，我们需要一种比较持久的方法来存储我们的变量以及相关函数地址。那就是栈,那怎么标识一个栈的位置呢，比如栈的起始位置和结束位置:1234cpu中有两个关键的寄存器用于标识栈的信息，ss:sp:bp 等段基础寄存器ss: 指向栈段的顶点边界sp: 指向的是栈底边界bp: 一般在函数开始的时候，指向当前函数的栈底，sp=bp 然后对于栈上的变量都是基于bp+偏移量访问的 问题: 同时多个实例的内存是怎么区分的每个程序在编译为机器码后，对应的ss，sp段寄存器的地址都是一样的，在编译期间就计算了，例如 这个是一个win 16的debug.exe，可以看到每个cpu指令执行期间的每个寄存器的值，当你的程序被启动多次，也就是产生了多个进程时，对于cpu来说执行的指令没有任何区别，包括上面ss,sp对于的栈地址也是一样 那就产生一个疑问，这样的话多进程下岂不是变量共享了，其实到这里就需要引申一个虚拟地址的问题，其实我们的运行的程序所有变量的地址都是虚拟地址，在实际访问时，由操作系统转为实际的物理地址 这就是为什么你针对多个进程debug，查看同一个变量地址时都是相同的，但是实际所指的地址却不是同一个东西的原因 函数栈的形成123456789101112131415161718192021222324252627282930313233343536SP 栈顶: 0x100001. 这里是main函数 +--------------+ main函数起始地址 | | + | | 这里是本地的变量存储区域 | +--------------+ | | | | | arg(N-1) | 这里起始就开始准备调用函数了 | | | | +--------------+ | | | | | argN | | | | | +--------------+ | | |2.start call | |Return address| %rbp + 8Stack grows down | | |===================================================================================3.new function | +--------------+ 新的函数栈起始地址 | | | | | %rbp | 在刚初始化的时候 sp=bp | | | | +--------------+ | | | | | local var1 | %rbp - 8 | | | | +--------------+ | | | | | local var 2 | &lt;-- %rsp | | | v +--------------+ | | | | +--------------+SS 栈段边界 0x00000 main函数开始执行时从sp栈开始初开始存储，这个sp当前是栈内存区域的最大边界，没新增一个变量或者一些存储操作则进行 压栈操作，如: 123456789101112131415161718#include &lt;stdio.h&gt;int main()&#123; int a = 2; return 0;&#125;会被翻译为如下汇编指令main: push rbp mov rbp, rsp // 通过rbp -4 也就是用了栈的下面4字节来存储 int 2 // 也就是压栈操作，其实这是一种直接操作栈的方式，这是编译器优化的结果 // 正常情况下 应该使用 push 2;这种方式来操作栈，这样的话 sp始终会指向栈顶 // 而通过偏移量来操作栈则不会引起 sp栈顶的变化 mov DWORD PTR [rbp-4], 2 mov eax, 0 pop rbp ret 函数返回时的执行流程: 123456789101112131415161718int test()&#123; return 2;&#125;//汇编指令test: //这里是压栈，当前的rbp其实是 调用放函数的rsp地址 push rbp //将当前栈顶 复制给rbp寄存器，从此开辟了一个新的函数栈区 mov rbp, rsp //这里就是我们程序实际逻辑开始的地方 mov eax, 2 //程序结束，恢复调用方函数的栈底 pop rbp //这里就是返回调用方调用函数的地方，恢复函数继续运行 ret //所谓函数返回，其实只是修改cpu的ip cs寄存器，修改cpu下一条需要执行的指令 //那么下一条需要执行的指令其实就是 上面的Return address地址，我们也可以通过其他方法来实现ret // jmp %rbp+8;(%rbp+8 就是调用方函数的下一个cpu指令地址)从而实现了返回函数的功能 函数调用流程整理来自：https://juejin.im/post/6844903930497859591 go plan9 汇编的函数调用图 因为总体流程大致相似 每个函数执行期间 通过 bp,sp寄存器来表示内存区域 bp寄存器一般不会发生改变，一般通过bp+偏移量来获取相关栈上的变量 sp表示的是栈顶，调用push指令会自动修改sp指向的值 通过整体流程的熟悉后，就能明白为什么栈数据是局部变量，会被回收（其实不是立即回收）1234我们的栈是一个整段内存 0x00000 - 010000,整个栈内存都会不断复用，如上所示，当函数返回时，当前bp就会被恢复为之前调用方函数的栈，那么当前函数的区域就保持不变。如果发生其他调用，则会复用当前函数的区域，则会覆盖当前变量所以在c语言中返回一个局部变量地址，在其他地方依然能够访问的前提是因为没有新函数的栈内存将当前栈覆盖 栈&amp;堆的区别 栈是一块连续内存，由操作系统在程序执行期间为整个进程分配的生命周期 堆内存是独立于当前栈的另外一个快内存，自然该内存不会受到像栈那样覆盖的影响，所以需要开发者自己管理，所以在c等静态语言中存在一个非常恐怖的问题(内存泄露),堆内存如果申请次数！=释放次数，那么你的内存就会逐渐飙升，等待系统给你kill吧 其实对于计算机来说，所有的都是二进制数据，没有代码和数据的区别，那怎么区分代码和数据呢，在cpu中有一个寄存器叫ip寄存器，存储的是下一条指令的地址，如果不发生中断的情况下顺序读取ip寄存器的值来进行执行，所谓的数据段只是应用层面划分的一块区域，使ip寄存器不会去访问该区域而实现的一个数据块，堆和栈就是典型的数据块，栈数据块会被多次复用，而堆数据块是栈快之外的额外需要向操作系统申请的一块内存 函数翻译后的cpu指令再来看看一个c语言函数被编译后的汇编指令，因为汇编语言已经是最底层的语法表达，基本就是二进制指令一一对应，所以可以用汇编来表示最底层的cpu指令 下面是一个函数调用test和定义一个全局变量的例子12345678910111213#include &lt;stdio.h&gt;char *str = \"string data\";int test()&#123; return 2;&#125;int main()&#123; int a = 2; test(); return 0;&#125; 编译后的汇编1234567891011121314151617181920.LC0: .string &quot;string data&quot;str: .quad .LC0test: push rbp mov rbp, rsp mov eax, 2 pop rbp retmain: push rbp mov rbp, rsp sub rsp, 16 mov DWORD PTR [rbp-4], 2 mov eax, 0 call test mov eax, 0 leave ret 汇编最左边是一个标号，也可以当做地址，在其他地方直接通过该标号就可以引用到该地址 main: 这个标号是在程序启动时由外部来进行调用跳转的，所以程序开始的地方就是 main标号，也就是 $rip = main:设置 ip寄存器为main，开始执行main函数 push rbp: 基本所有的函数在执行前都要执行这行指令，表示将之前的栈底rbp保存起来，我们知道函数调用返回后需要恢复当前的栈环境，那么在调用函数之前，要保存当前的栈信息，所以需要push rbp mov rbp,rsp: 这个就比较清楚了，表示开辟一个新栈，把当前的栈顶设置为新函数的栈底,那么新函数的执行环境就在新的栈空间使用 sub rsp,16 : 这个模拟压栈，我们知道rsp代表的是栈顶，那么我们也可以手动将栈顶下移一定的空间，而申请的空间我们可以存储变量等信息,这行和手动执行2次push ***是相同的，因为push首先rsp -= 8然后在将数据写入栈区 mov dword ptr [rbp-4],2: 步骤4的时候新开辟了16字节的空间，这里就是通过对rbp进行偏移量来获取第一个4字节空间，然后将2存储进去，实现的一种手动压栈 mov eax,0: 这个没什么特别的，ax寄存器一般用作计算、传参等作用的寄存器，这里先初始化恢复为0 call test: 如1所说的，test是一个标号，也是一个地址，所以这里实际的执行可以分为如下两个步骤: 123push cs //将代码段基段 cs保存起来push ip //将ip段保存起来，这里相当于这个ip就是返回地址，当被调用函数返回的时，会获取当前换个ip在jmp %ripjmp test // 跳转到test标号的地址，实现函数调用 test: 进入test函数内部，首先执行push rbp 保存上一个函数的栈底指针 mov rbp,rsp: 和main函数一样开辟新栈 mov eax,2: 这里就是我们的c代码return 2的实际汇编指令，因为返回一般用ax寄存器存储，所以这里现将2存入eax寄存器 pop rbp: 恢复main函数的栈底指针，准备返回到main函数的下一行代码继续执行 ret: 可以表示为如下汇编pop ip实际就是获取main函数的之前保存的ip值，然后恢复到ip寄存器中，实现函数返回 最后讲讲全局变量:1234567//char *str = &quot;string data&quot;;c代码会被翻译为如下的汇编指令，可以看到全局变量也是放到整个代码段上面的，如何区分该代码是数据还是代码呢，区别就在我们的程序如何去对待他比如我们不管在何时引用.LCO时都是把他当做一个数据来处理，而不是加载到ip当做指令来执行.LC0: .string &quot;string data&quot;str: .quad .LC0 协程的创建这里来讲讲我们php扩展怎么创建一个协程，php代码和扩展的c代码怎么交互的问题 php创建协程php执行一个协程函数12345function task()&#123; echo \"go task\";&#125;go(task); c层面获取该函数wrapper/coroutine.cpp：123456789101112PHP_FUNCTION(go_create)&#123; zend_fcall_info fci = empty_fcall_info; zend_fcall_info_cache fcc = empty_fcall_info_cache; //1 -1 可变参数 ZEND_PARSE_PARAMETERS_START(1,-1) Z_PARAM_FUNC(fci,fcc) Z_PARAM_VARIADIC(\"*\",fci.params,fci.param_count) ZEND_PARSE_PARAMETERS_END_EX(RETURN_FALSE); long cid = PHPCoroutine::go(fcc.function_handler,fci.params,fci.param_count); RETURN_LONG(cid);&#125; 通过PHP_FUNCTION申明一个提供给php调用的api，go实际执行的是c的go_create。fci,fcc可以表示一个php传过来的函数参数.通过PHPCoroutine::go来初始化一个协程，并投递到调度器去执行 123456789101112/coroutine/PHPCoroutine.cpp/** * 创建一个协程G运行 * @param call * @return */long PHPCoroutine::go(zend_function *func,zval *argv,uint32_t argc)&#123; ZendFunction *call = new ZendFunction(func,argv,argc); Coroutine *ctx = new Coroutine(run, call); return ctx-&gt;run();&#125; 拷贝当前用户函数，因为多线程协程情况下已经采取了线程隔离TSRM,所以该闭包任务呗调度到其他线程执行时环境不同，且当前函数返回后可能被回收等因素，需要对用户的函数进行硬拷贝，拷贝会专门在线程隔离中说明。 创建一个G绑定当前php用户函数，等待投递调度 1234567891011121314//coroutine/Coroutine.cpp * 投递到调度到其他线程CPU中去执行 * @return */long Coroutine::run()&#123; //投递到 proc 线程去执行该协程 if(proc == nullptr)&#123; cout &lt;&lt; \"未初始化线程\" &lt;&lt;endl; throw \"未初始化线程\"; &#125; proc-&gt;gogo(ctx); return 1;&#125; 到这里基本就完成了一个php协程创建到执行的过程了，proc-&gt;gogo后面就是属于调度和任务投递的事情了，这个是多线程调度处理的，会有专门的章节讲解 全局队列与本地队列目前实现的多线程协程基于两个队列来调度任务，一个是全局队列，所有线程获取时需要枷锁，另外一个是本地队列，目前只处理被调度过的协程，不接受新协程投递123456789101112131415161718192021//runtime/proc.cpp unique_lock&lt;mutex&gt; lock(this-&gt;queue_mu); this-&gt;cond.wait(lock,[this,rq]&#123; return this-&gt;stop || !this-&gt;tasks.empty() || !rq-&gt;q-&gt;isEmpty(); &#125;); if(this-&gt;stop &amp;&amp; this-&gt;tasks.empty() &amp;&amp; rq-&gt;q-&gt;isEmpty()) break; if(!this-&gt;tasks.empty())&#123; ctx = move(this-&gt;tasks.front()); this-&gt;tasks.pop(); co = static_cast&lt;Coroutine *&gt;(ctx-&gt;func_data); &#125;else&#123; co = rq-&gt;q-&gt;pop(); &#125; &#125; if(co == nullptr)&#123; cout &lt;&lt; \"co exception:\"&lt;&lt;co&lt;&lt;endl; continue; &#125; tasks 是一个全局队列，新创建的协程优先投递到tasks等待所以线程获取，这里的问题就是会导致竞争严重，多线程会同时获取锁来争抢该协程 rq-&gt;q 是一个本地队列，通过GO_ZG(rq)来获取该队列，所以调度的前提就是本地队列和全局队列都有数据则触发调度循环，获取待处理的协程进行切入 协程的释放协程的释放，目前协程的释放会回收c栈和php栈，会极大的影响性能，后面会实现c和php栈复用，更好的提高性能123456789//coroutine/coroutine.cppvoid Coroutine::close()&#123; zend_vm_stack stack = EG(vm_stack); free(stack); restore_stack(&amp;main_stack); delete ctx; delete this;&#125; 将当前的通过堆申请的栈销毁，也就是销毁php栈 恢复在协程切入前的主php栈，模拟函数返回 删除ctx也就是c栈，回收c栈 delete this删除G相关内存，回收内存","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"coroutine","slug":"coroutine","permalink":"http://wiki.brewlin.com/tags/coroutine/"},{"name":"thread","slug":"thread","permalink":"http://wiki.brewlin.com/tags/thread/"},{"name":"scheduler","slug":"scheduler","permalink":"http://wiki.brewlin.com/tags/scheduler/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"goos","slug":"blog/goos","permalink":"http://wiki.brewlin.com/categories/blog/goos/"}]},{"title":"Goos-多线程协程实现简要","date":"2020-07-10T13:28:59.000Z","path":"wiki/blog/goos/Goos-多线程协程实现简要/","text":"简介Goos 是一个借鉴Golang的多线程协程调度器的设计而利用C++实现的PHP扩展。笔者在接触golang的协程调度器的力量后不能自拔，感受到协程的魅力后也想试试能不能为php也实现这么炫酷的功能 Goos 目的是实现一个真正意义的单进程多线程协程调度器，充分利用多核,使动态语言也能高效的开发出高性能的服务。目前主要实现进展如下: php环境线程隔离，协程隔离 实现G-M调度,任意协程G创建后，自动绑定到线程M上去执行 实现多线程协程G调度，切出与恢复 优化php内存相关 引入P, 实现G-P-M 任务窃取调度 协程栈自动收缩，防止 stack overflow 实现抢占调度,可以对任意在执行的协程发起抢占 优化抢占调度,检查任意超过10ms持有G的线程，发起抢占调度 目前主要在优化内存方面的实现、引入P的实现、周边工具的开发(lock…) 接下来的其他文章将陆续讲解从底层至汇编指令-php应用层的整个实现过程 Goos-多线程协程实现简要 Goos-协程底层实现(一) Goos-线程协程隔离(二) Goos-线程切换实现(三) Goos-抢占调度实现(四) Goos-监控线程实现(五) 现在php其实也有许多相关扩展都带有协程实现的、如swoole。swoole和golang区别还是挺大的。下面来讲讲swoole和golang的简单区别吧 swoole的协程相关swoole的协程为单进程协程,无完整调度器，只有触发了相关hook后才能切换，例如：swoole可以替换function_table中的sleep变成非阻塞，当调用sleep后直接切出当前协程 在内存方面swoole会申请c栈和php栈，基本上每个协程会占有2m的堆内存，且在协程销毁后该内存没有复用而是直接释放，因为swoole协程没有栈的收缩，所以需要注意在协程内的不要越栈Stack Overflow，否则system会给你一个segment error kill 进程。 综上建议不要什么都往协程上扔，针对这种协程机制需要严格考虑场景否则协程就是你的瓶颈。 总结一下swoole的协程机制：123456789- 无协程调度只能依赖hook原生函数实现切换- 协程栈无复用导致频繁大内存申请释放- 无栈内存收缩，当协程栈溢出后即致命错误- 无抢占调度(发生for死循环将永远占用cpu)、- 同步协程模型 上面的声明只是针对swoole的协程相关，因为swoole在多进程模式下也能充分利用多核cpu，弥补了一些不足，并且swoole的task-worker模型也做的足够出色了，可以轻松的实现一个多进程常驻通讯服务 为什么无完整调度器协程我认为调度过程应该是一个底层的分配管理过程，就像linux的调度一样是一个更加底层的管理，无需用户去关注，而针对协程的调度目前主要有两个方面 协程让出:1234一个正在运行的G，享有独立的栈空间，该栈是从堆上分配的一块独立内存来模拟栈行为。且该独立的函数栈在执行过程中能够中断，能够暂停后被切出就像我们的系统进程，线程一样，对于上层开发者来说是无感知的，其实系统随时都在进行着切换 协程恢复12一个独立的函数栈因为在执行到一半的时候被调度出去了，那么在恢复的时候我们要能够让cpu继续执行在让出时的那条指令。从而达到该暂停的函数能够继续向下执行，在执行完毕的时候要能够返回到我们正常的流程这里 具体协程的底层实现和流程我们会单独拿一个文章来说 swoole目前的协程是能够进行随意的切出和让出的，但是我想标注的点在于切出和让出的点应该有调度器来完全完成，而swoole目前是需要开发者具备协程的切出和恢复时机的 接下来讲讲swoole协程调度的点，swoole目前主要有两种实现来切换让出协程 Hook php原生函数 swoole相关api都加入检查是否需要切出 Hook php原生函数在讲讲hook前，我们先说一下php函数的调用12345678php在脚本初始化阶段会初始化所有模块，并将对应模块函数 zend_function* 和php内置的函数存入一个全局EG(function_table)中，这个是一个hash表。其实就是php里的数组底层的实现，然后key就是对应的php内置的函数名那么能够想到value就是该函数的实际地址或者opcode汇编指令，这里不细说，因为php函数有好几种类型。普通的c动态库扩展的函数就是一个函数指针指向扩展里的实际函数地址，而php内部函数比如用户自定义的函数可能就是一份编译过后的opcode码指令在函数调用前(针对内置函数 比如sleep)，会先去全局EG(function_table)-&gt;zend_hash_index(sleep) 查找是否存在，如果存在则获取对应的value，并设置对应的php函数栈帧信息，并执行 所以这里所说的hook，我们就可以理解为，在我们的php扩展里将全局函数替换为自己的自定函数，当用户执行sleep时12345678910111213141516171819202122232425&lt;?phpfunction co()&#123; sleep(10000);//实际被替换为协程版的sleep实现&#125;go(co);//--------------demo.sleep.cEG(function_table)-&gt;zend_hash_update_ptr(\"sleep\",co_sleep);void co_sleep(long sec)&#123; timer.add(_g,sec); _g.swap_out();&#125;void timer_loop()&#123; int n = epoll_wait(epfd,events,0); for(....)&#123; g = events[i]; //在timer定时器中在执行恢复该协程 g.swap_out() &#125;&#125; 实际执行的是一个协程切换的方法，并且将当前协程加入 timer中，等待epoll时间片到期后恢复 在api中埋点监测协程这个容易想到，在swoole的新增api中，都会监测是否需要切入或者恢复，例如调用swoole协程客户端send，因为该tcp端点属性被设置为边缘模式，也就是如果没有就绪事件则不阻塞进程，而是直接返回EAGAIN，那么此时swoole就会将该G加入到epoll_add中管理，等待事件到来后 在恢复该执行 什么是栈复用一个协程的准备环境是需要申请两次大内存，一个是php栈，一个是c栈，来看看什么是函数栈，来着曹大的图:12345678910111213141516171819202122232425262728293031 +--------------+ | | + | | | +--------------+ | | | | | arg(N-1) | starts from 7&apos;th argument for x86_64 | | | | +--------------+ | | | | | argN | | | | | +--------------+ | | | | |Return address| %rbp + 8Stack grows down | | | | +--------------+ | | | | | %rbp | Frame base pointer | | | | +--------------+ | | | | | local var1 | %rbp - 8 | | | | +--------------+ | | | | | local var 2 | &lt;-- %rsp | | | v +--------------+ | | | | +--------------+ 首先受限于寄存器数量的原因，大多数变量都是存储在在栈中，每次新调用一个函数，那么就会保存当前上下文变量到栈中，最后将当前指令地址 cs,ip(就是函数的返回地址)压栈，然后在jump到目的指令地址实现函数调用，新函数栈会在系统栈下面继续使用，不断从高地址往低地址增长，如果函数返回则低地址往高地址增长出栈。所以这就是为什么栈上的变量在函数退出后不能再使用了的原因(虽然变量不会被立即销毁，但是如果发生其他函数调用，则会复用该地址的数据，这样就会导致非法内存访问，发生难以排查的致命bug) 上面的图加上粗略的描述了函数栈后来讲讲为什么要用堆模拟栈： 协程也是一个函数，那为什么要另外申请一个堆内存来当做该函数的执行栈呢，而不用本身系统为当前进程分配的栈呢，正如上面讲的当前栈在函数退出后，会被其他函数栈给覆盖，那么当前函数的所有上下文和变量都变成了未知内存 所以想要支持协程函数的切换和恢复，那么肯定是需要一直保存该函数栈的上下文信息的，所以只能用堆内存来当做栈使用 让我们继续回到swoole栈复用的问题，因为每次协程创建都会申请8kphp栈和2mc栈，且协程释放后会销毁该内存，所有目前swoole会存在这种频繁申请和释放的浪费情况，因为swooole是进程模型所以协程是同步的，所以就算创建千万协程也是同步排队执行，不会导致内存飙升 为什么是无栈内存收缩上面降了函数栈的模型，我们知道在函数内所有产生的栈变量都会压栈，不断的使用栈空间，但是这个栈是系统分配的栈空间，默认是可以达到进程上限的 而我们要实现的协程是申请的一份堆内存来模拟的栈，所以大小一开始就固定好的且不会太大，当我们在协程内做了大量操作栈溢出后，就会触发堆溢出引发致命问题12345678910111213141516171819高地址位 堆内存的末尾位置 ┼───────────┼ │ 返回值g │ ┼───────────┼ │ 返回值f │ ┼───────────┼ │ 返回值e │ ┼───────────┼ │ 参数之c │ ┼───────────┼ │ 参数之b │ ┼───────────┼ │ 参数之a │ &lt;-- FP ┼───────────┼ │ PC │ &lt;-- SP ┼───────────┼ |。。。。。 | 低地址位 堆内存的起始位置 swoole貌似目前在协程里跑大的数组进行遍历就会导致栈溢出，这就需要开发者在开发中小心这类问题 这就是无栈收缩会导致的问题，如果栈能够自动收缩，就无需考虑协程预分配大小,栈溢出等问题，既能节省内存也能是开发效率高效 为什么无抢占调度何谓抢占调度，就是强制的被动触发的调度。在正常情况下发生调度都依赖于函数执行流遇到了阻塞或是主动让出才会触发切换。那抢占的意义又是什么呢,想象一下如下场景在swoole中使用1234567&lt;?phpgo(function()&#123; for(;;) //do sth //then break&#125;); 如果上面的没有发生死循环，始终会等到某个条件中断该循环，那么依然会存在如下问题 123456789如果该协程是在网络触发事件中被恢复的协程，那么自然能想到如下的情景for(;;)&#123; epoll_wait(...) //co-&gt;resume()&#125;那么如果这时候上面那个协程执行的时间过长，都会直接影响其他流程的精度，比如timer是挂在epoll上触发的，那么定时器就会一直得不到执行，且网络事件也得不到执行这时候就会有其他意外产生 如果上面的协程发生死循环，永远不会中断 1在目前没有抢占调度的情况下，自然阻塞当前进程，任何其他都得不到执行，基本就是死锁的样子了 这个时候就知道了抢占调度的意义了，监测每个协程的执行时间，严格控制时间，发生超时则调度该协程切出，这都是一个完整的协程调度器需要考虑的事情 golang的调度golang 的调度就非常完整了，golang走的单进程多线程协程实现并发控制，swoole基于多进程同步协程实现并发控制，各有优缺点，我认为最大的区别就是 对于技术实现来说： golang的多线程协程对于实现者来说非常复杂，而swoole的多进程同步协程对于实现者来说要相对友好，反正基于线程的实现都是异常恐怖的 对于技术使用者来说: 多线程的协程当然用起来要高效简单很多，无需关心进程通信等，而多进程对于开发者来说就稍微不友好一点 golang的协程和swoole比起来当然是完全不同的，golang走的多线程协程，所以几乎上面的特性都支持例如: 多线程调度 任务窃取器调度 抢占式调度 以及一些协程的优化:栈内存自动收缩 还有超多的协程生态工具链:lock,channel..等等 简要总结上面的协程方面的设计确实还是和golang相差较大，swoole本身走的是多进程路线，同步协程只是为它在加了一份力，所以硬要和golang完整的单进程多线程协程比是没意义的 所以GOOS由此而来，想为php生效一个多线程协程版调度，从而使php既能保持动态语言编写代码的高效又能实现golang等静态语言的高性能并发控制","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"coroutine","slug":"coroutine","permalink":"http://wiki.brewlin.com/tags/coroutine/"},{"name":"thread","slug":"thread","permalink":"http://wiki.brewlin.com/tags/thread/"},{"name":"scheduler","slug":"scheduler","permalink":"http://wiki.brewlin.com/tags/scheduler/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"goos","slug":"blog/goos","permalink":"http://wiki.brewlin.com/categories/blog/goos/"}]},{"title":"mini_ngx_实现四-event模块","date":"2020-04-18T13:28:59.000Z","path":"wiki/blog/nginx/mini_ngx/4.mini_ngx_实现四-event模块/","text":"事件模型概述主要分为两个方面事件收集器、事件分发器 事件收集器也就是向epoll添加、更新、删除等事件，让epoll事件去管理 EPOLL_CTL_MOD EPOLL_CTL_ADD EPOLL_CTL_DEL事件分发器实际是调用epoll_wait 收集内核通知的就绪事件，然后调用ev-&gt;handler执行用户自定义该事件的处理方法 ngx 事件初始化事件的初始化实际就是对epoll进行初始化，如epoll_create（）调用创建epollfd event_list事件列表内存申请 1234567891011121314151617181920..... for (m = 0; cycle-&gt;modules[m]; m++) &#123; if (cycle-&gt;modules[m]-&gt;type != EVENT_MODULE) &#123; continue; &#125; if (cycle-&gt;modules[m]-&gt;ctx_index != ecf-&gt;use) &#123; continue; &#125; module = cycle-&gt;modules[m]-&gt;ctx; if (module-&gt;actions.init(cycle, timer_resolution) != OK) &#123; /* fatal */ exit(2); &#125; break; &#125;..... 这里是event核心模块被cycle_init（）主函数进行init_process()初始化时调用的函数，在上一节有说明，该函数是对连接池 ,读事件 ,写事件等进行内存申请初始化，串联成链表 这里也是其中的工作之一，因为nginx高度可扩展，所以event实际的系统实现有很多种epoll,kqueue,pool,select..等，在./configure时会进行环境检查，将兼容平台的实现，如epoll_module.c加入到cycle-&gt;modules[m]中，所以上面的循环就是找出如epoll的实现并去调用该初始化方法，准备好接受事件 全局epoll接口加入平台的event实现为epoll则会调用epoll_moudle.c 的初始化方法，将相关的接口添加到 event_actions全局变量上123456789101112131415161718192021//src/event/module/epoll_module.c:369static event_module_t epoll_module_ctx = &#123; &amp;epoll_name, epoll_create_conf, /* create configuration */ epoll_init_conf, /* init configuration */ &#123; epoll_add_event, /* add an event */ epoll_del_event, /* delete an event */ epoll_add_event, /* enable an event */ epoll_del_event, /* disable an event */ epoll_add_connection, /* add an connection */ epoll_del_connection, /* delete an connection */ epoll_process_events, /* process the events */ epoll_init, /* init the events */ epoll_done, /* done the events */ &#125;&#125;;event_actions = epoll_module_ctx.actions; 也就是将epoll的add,del,add_con,del_con,epoll_process_events等接口条件到全局actions上，提供外部访问，收集外部事件，并分发就绪事件 事件相关api下面统一接口的实现假定为epoll实现1234567891011121314151617181920typedef struct &#123; int_t (*add)(event_t *ev, int_t event, uint_t flags); int_t (*del)(event_t *ev, int_t event, uint_t flags); int_t (*enable)(event_t *ev, int_t event, uint_t flags); int_t (*disable)(event_t *ev, int_t event, uint_t flags); int_t (*add_conn)(connection_t *c); int_t (*del_conn)(connection_t *c, uint_t flags); int_t (*notify)(event_handler_pt handler); int_t (*process_events)(cycle_t *cycle, msec_t timer, uint_t flags); int_t (*init)(cycle_t *cycle, msec_t timer); void (*done)(cycle_t *cycle);&#125; event_actions_t;event_actions_t event_actions; 在event.c 中会定义全局变量event_actions，改变量对应的平台实现的相关事件接口，如上文初始化时，如果平台支持epoll则将epoll事件的相关api添加到全局变量event_actions中，提供外部调用注册事件 12345678#define process_events event_actions.process_events#define done_events event_actions.done#define add_event event_actions.add#define del_event event_actions.del#define add_conn event_actions.add_conn#define del_conn event_actions.del_conn 并且默认提供了相关宏定义，直接通过宏定义更加方便些 @add_event 注册事件12345678910111213141516171819202122232425262728293031323334353637383940414243static int_tepoll_add_event(event_t *ev, int_t event, uint_t flags)&#123; int op; uint32_t events, prev; event_t *e; connection_t *c; struct epoll_event ee; c = ev-&gt;data; events = (uint32_t) event; if (event == READ_EVENT) &#123; e = c-&gt;write; prev = EPOLLOUT; events = EPOLLIN; &#125; else &#123; e = c-&gt;read; prev = EPOLLIN; events = EPOLLOUT; &#125; if (e-&gt;active) &#123; op = EPOLL_CTL_MOD; events |= prev; &#125; else &#123; op = EPOLL_CTL_ADD; &#125; ee.events = events | (uint32_t) flags; ee.data.ptr = (void *) ((uintptr_t) c | ev-&gt;instance); log_info(c-&gt;log,\"epoll add event %d \",c-&gt;fd); if (epoll_ctl(ep, op, c-&gt;fd, &amp;ee) == -1) &#123; log_error(c-&gt;log,\"epoll_ctl %d failed\\n\",c-&gt;fd); return ERROR; &#125; ev-&gt;active = 1; return OK;&#125; 判断是新增还是修改，e-&gt;active如果为1，说明之前注册过该事件，需要走更改事件流程epoll_ctl_mod 例如http流程中假如需要等待客户端发送body才能进行下面的操作，那么就可以将该http的读事件通过这个接口注册到epoll中 当客户端发送了数据，内核收到的数据后分发该就绪事件，将内核数据拷贝到用户态空间调用ev-&gt;handler()回调函数继续执行上一次中断的函数 @del_event 删除事件12345678910111213141516171819202122232425static int_tepoll_del_event(event_t *ev, int_t event, uint_t flags)&#123;....... if (e-&gt;active) &#123; op = EPOLL_CTL_MOD; ee.events = prev | (uint32_t) flags; ee.data.ptr = (void *) ((uintptr_t) c | ev-&gt;instance); &#125; else &#123; op = EPOLL_CTL_DEL; ee.events = 0; ee.data.ptr = NULL; &#125; log_info(c-&gt;log,\"epoll_ctl %d\",c-&gt;fd); if (epoll_ctl(ep, op, c-&gt;fd, &amp;ee) == -1) &#123; log_error(c-&gt;log,\"epoll_ctl :%d failed\",c-&gt;fd); return ERROR; &#125; ev-&gt;active = 0; return OK;&#125; 同样当http请求生命周期结束，也就是http 引用计数count真正为0的时候，会触发event_del,pool_destory,socket_close..等进行事件删除，内存池回收，tcp关闭等一系列回收机制 event事件删除后，epoll不在负责相关事件监控 @add_conn 注册连接事件该方法更加方便，直接将connection_t连接注册到epoll中12345678910111213141516171819static int_tepoll_add_connection(connection_t *c)&#123; struct epoll_event ee; ee.events = EPOLLIN|EPOLLOUT|EPOLLET; ee.data.ptr = (void *) ((uintptr_t) c | c-&gt;read-&gt;instance); log_info(c-&gt;log,\"epoll add connection fd:%d\",c-&gt;fd); if (epoll_ctl(ep, EPOLL_CTL_ADD, c-&gt;fd, &amp;ee) == -1) &#123; log_error(c-&gt;log,\"epoll add connection fd:%d failed\",c-&gt;fd); return ERROR; &#125; c-&gt;read-&gt;active = 1; c-&gt;write-&gt;active = 1; return OK;&#125; 直接调用epoll_ctl()将该事件添加到epoll_ctl中 @del_conn 删除事件12345678910111213141516171819202122232425static int_tepoll_del_connection(connection_t *c, uint_t flags)&#123; int op; struct epoll_event ee; if (flags &amp; CLOSE_EVENT) &#123; c-&gt;read-&gt;active = 0; c-&gt;write-&gt;active = 0; return OK; &#125; op = EPOLL_CTL_DEL; ee.events = 0; ee.data.ptr = NULL; if (epoll_ctl(ep, op, c-&gt;fd, &amp;ee) == -1) &#123; printf(\"del connection failed\"); return ERROR; &#125; c-&gt;read-&gt;active = 0; c-&gt;write-&gt;active = 0; return OK;&#125; 直接del移除该事件即可 @process_events 事件分发nginx是所有的事件执行都来自事件循环监测事件并发事件执行,该函数在nginxwoker进程启动后作为while(1){}循环事件调用,12345static int_tepoll_process_events(cycle_t *cycle, msec_t timer, uint_t flags)&#123; .......&#125; 事件分发主要分为如下重要部分 调用epoll_wait监测就绪事件，如tcp连接，数据读写，tcp关闭。。。等等就绪事件,events为就绪事件的总数 1events = epoll_wait(ep, event_list, (int) nevents, timer); 分发所有就绪事件 12345678910111213141516171819202122 for (i = 0; i &lt; events; i++) &#123; c = event_list[i].data.ptr; instance = (uintptr_t) c &amp; 1; c = (connection_t *) ((uintptr_t) c &amp; (uintptr_t) ~1); rev = c-&gt;read; //判断该连接是否已经失效，因为如果在执行之前的连接事件的时候将当前连接关闭了，单该连接又被新连接给复用了，这就需要instance来解决了，closed无法解决新连接将之前连接复用的例外 if (c-&gt;fd == -1 || rev-&gt;instance != instance) &#123; /* * the stale event from a file descriptor * that was just closed in this iteration */ log_debug1(LOG_DEBUG_EVENT, cycle-&gt;log, 0, &quot;epoll: stale event %p&quot;, c); continue; &#125; 取出事件 revents = event_list[i].events;&#125; 这里比较重要，nginx是基于事件来执行的，如果其中任何一个事件阻塞了，将会导致整个进程得不到处理任何任务，例如新连接accept可能需要优先执行，而普通收发数据可能需要放到延迟队列去执行 12345if (flags &amp; POST_EVENTS) &#123; post_event(wev, &amp;posted_events);&#125; else &#123; wev-&gt;handler(wev);&#125;","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"nginx","slug":"nginx","permalink":"http://wiki.brewlin.com/tags/nginx/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"nginx","slug":"blog/nginx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/"},{"name":"mini_ngx","slug":"blog/nginx/mini-ngx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/mini-ngx/"}]},{"title":"mini_ngx_实现三-http模块","date":"2020-04-17T13:28:59.000Z","path":"wiki/blog/nginx/mini_ngx/3.mini_ngx_实现三-http模块/","text":"@http_process_init 主要启动函数上面cycle初始化的时候start_module启动的就是当前http入口模块函数1234567891011121314151617181920212223242526272829303132333435//这里其实应该是核心http模块的启动，主要是启动监听端口//但是端口配置添加 listening_t 在nginx中是通过nginx.conf配置解析时添加的//我们这里作为演示就直接放到http core模块启动方法中static int_t http_process_init(cycle_t *cycle)&#123; log_info(cycle-&gt;log,\"http: process init\"); http_listen_opt_t lsopt; struct sockaddr_in serv_addr; memzero(&amp;lsopt, sizeof(http_listen_opt_t)); memzero(&amp;serv_addr,sizeof(serv_addr)); // listen 127.0.0.1:8000; // listen 127.0.0.1 不加端口，默认监听80端口; // listen 8000 // listen *:8000 // listen localhost:8000 serv_addr.sin_family = AF_INET; serv_addr.sin_addr.s_addr = INADDR_ANY; serv_addr.sin_port = htons(8089); lsopt.sockaddr = (struct sockaddr *)&amp;serv_addr; lsopt.socklen = sizeof(serv_addr); lsopt.backlog = BACKLOG; lsopt.rcvbuf = -1; lsopt.sndbuf = -1; listening_t *ls; ls = http_add_listening(cycle, &amp;lsopt); if (ls == NULL) &#123; return ERROR; &#125; //初始化对应socket return open_listening_sockets(cycle);&#125; 之前有讲过，nginx会在启动期间init_cycle会去解析nginx.conf配置并且将所有匹配的配置项传递给对应的模块，其实就是寻找ngx_command_t定义的模块配置项，可以看模块开发文章相关介绍:http://wiki.brewlin.com/wiki/blog/nginx/http_%E6%A8%A1%E5%9D%97%E5%BC%80%E5%8F%91%E7%9A%84%E6%AD%A5%E9%AA%A4%EF%BC%88%E4%B8%80%EF%BC%89/ 那么当发现一个listen 80;配置后就会立即调用如上方法，新增初始化一个listening_t对象保存到cycle-&gt;listening上用于后面监听对应端口 我们这里也模仿对应的事件，因为不是配置行为，所以在这里手动添加了一个端口，模仿解析到了配置listen 主要流程@handler 处理新连接事件每个监听对象上面都会有一个listening-&gt;handler回调事件，每个模块都会去重写他，那么在http模块中为 http_init_connection：123src/http/http.c:71ls-&gt;handler = http_init_connection; 该方法在event事件监测到该端口有新连接到来时，会立即accept然后调用但当前http_init_connection方法表明接下来都会进行http相关操作 这种方法很好的解耦操作，不同协议之间只需要替换handler就可替换不同的实现 @http_init_connection 初始化http请求1234567891011121314151617static void http_init_connection(connection_t *c)&#123; event_t *rev; rev = c-&gt;read; rev-&gt;handler = http_init_request; c-&gt;write-&gt;handler = http_empty_handler; if (rev-&gt;ready) &#123; rev-&gt;handler(rev); return; &#125; if (handle_read_event(rev, 0) != OK) &#123; http_close_connection(c); return; &#125;&#125; 将该新的http连接的read事件取出来，判断是否已标示为可读状态 如果当前事件已就绪，则直接执行对应的handler也就是http_init_request 如果不是的话，就将该事件在放回到epoll中，等待下次事件就绪，在从连接中拿出来继续处理上次中断的地方 @http_init_request 解析http协议走到这里，说明tcp连接以就绪，客户端已发送了http数据包，准备解析，如果没有则如上面一样继续丢到epoll中继续监听，直到http协议数据包就绪12345678910111213141516171819202122232425static void http_init_request(event_t *rev)&#123; connection_t *c; http_connection *hc; c = rev-&gt;data; hc = c-&gt;data; if (hc == NULL) &#123; hc = pcalloc(c-&gt;pool, sizeof(http_connection)); if (hc == NULL) &#123; http_close_connection(c); return; &#125; &#125; c-&gt;data = hc; hc-&gt;connection = c; hc-&gt;log = c-&gt;log; connection_init(hc); rev-&gt;handler = connection_handler; // connection_handler(hc); // connection_close(hc); // http_close_connection(c); rev-&gt;handler(rev);&#125; 分配一个http_connection_t http请求对象并挂载到connection中 将事件handler置为connection_handler以后事件触发默认就走connection_handler 直接执行对应事件 rev-&gt;handler(rev) 我们这里没有关闭连接，而是一气呵成在connection_handler去关闭他，而真实nginx处理的时候要复杂的多。 因为现在是全部基于事件来处理对应流程，所以每个函数可能会多次调用，那么释放的问题就变的头疼，所以nginx真正对于http_request的释放是增加了引用计数的机制，也就是每个事件都负责引用计数+1当该函数执行完毕-1并且判断是否为0，为0则真正释放连接，不为0说明有其他事件被派生出来了，所以每个事件只需要关注当前自己的session即可 而我们的程序只有单一流程，所以不需要做引用计数，只需要读取本地html文件，响应客户端，然后在connection_handler中关闭连接释放资源即可 http核心处理函数上面说了，nginx一个请求的处理可能涉及到数十个`子模块和子过程`所以在哪里释放就是一个重要的问题，nginx用引用计数来解决了这个问题，而我们的mini版只涉及一个流程，所以不用引用计数来实现 直接在当前函数处理请求、响应请求、关闭请求、释放资源即可123456789101112131415161718192021222324252627282930313233343536373839404142/* * HTTP请求处理函数 * - 从socket中读取数据并解析HTTP请求 * - 解析请求 * - 发送响应 * - 记录请求日志 */// int connection_handler(http_connection *con) &#123;void connection_handler(event_t *ev) &#123; connection_t *sock = (connection_t *)ev-&gt;data; http_connection *con = sock-&gt;data; char buf[512]; int nbytes; while ((nbytes = sock-&gt;recv(sock,(u_char*)buf,sizeof(buf))) &gt; 0) &#123; string_append_len(con-&gt;recv_buf, buf, nbytes); if (http_request_complete(con) != 0) break; &#125; if (nbytes &lt;= 0) &#123; if (nbytes == 0) &#123; log_info(con-&gt;log, \"socket %d closed\", sock-&gt;fd); http_close_connection(sock); return; &#125; else if (nbytes == AGAIN) &#123; if (handle_read_event(ev, 0) != OK) &#123; http_close_connection(sock); return; &#125; log_error(con-&gt;log, \"read: %s\", strerror(errno)); return; &#125; &#125; http_request_parse(con); http_response_send(con); log_request(con); http_close_connection(sock);&#125; 当我们调用sock-&gt;recv的时候，可能会返回AGAIN,说明该连接可能没有数据可读，我们只需要再次加入epoll监听即可， 当sock-&gt;recv返回0 ，说明对方主动关闭，我们也只需要关闭资源，释放连接即可 其他情况，我们只需要读出用户态缓冲区数据，解析http协议，处理请求，并释放资源就可以了 http_request_parse： 解析http请求 http_response_send: 响应客户端数据 log_request(con) : 记录请求日志 http_close_connection ： 回收资源、连接等","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"nginx","slug":"nginx","permalink":"http://wiki.brewlin.com/tags/nginx/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"nginx","slug":"blog/nginx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/"},{"name":"mini_ngx","slug":"blog/nginx/mini-ngx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/mini-ngx/"}]},{"title":"mini_ngx_实现二-core模块","date":"2020-04-16T13:28:59.000Z","path":"wiki/blog/nginx/mini_ngx/2.mini_ngx_实现二-core模块/","text":"main启动函数主要调用init_cycle() 进入框架事件循环123456789101112131415161718int main()&#123; cycle_t * cycle = init_cycle(); //程序结束 回收内存池内存 if(cycle-&gt;pool)&#123; destroy_pool(cycle-&gt;pool); &#125; if(cycle-&gt;connections)&#123; free(cycle-&gt;connections); &#125; if(cycle-&gt;read_events)&#123; free(cycle-&gt;read_events); &#125; if(cycle-&gt;write_events)&#123; free(cycle-&gt;write_events); &#125; free(cycle);&#125; 当返回时，说明程序已经结束，剩下的只需要销毁内存池，连接池，读写事件内存即可 cycle 相关函数@init_cycle 主循环函数1234567891011121314151617181920212223cycle_t* init_cycle()&#123; //初始化全局结构体 cycle_t* cycle = init(); //初始化模块 init_module(cycle); //启动模块 if(start_module(cycle) != OK)&#123; return cycle; &#125; //epoll wait 分发事件 while(1)&#123; if(process_events(cycle,event_flags) == ERROR)&#123; goto end; &#125; &#125;end: close_listening_sockets(cycle); return cycle;&#125; 初始化cycle结构体： 如nginx那样做一些初始工作，分配内存池，初始化监听socket列表、打开日志文件，判断是否需要守护进程，注意：nginx都是基于配置来做的，但是我们省去了配置相关流程，直接手动在代码里面配置 初始化模块： 如nginx一样，变量全局模块数组，执行所有的模块初始化工作 启动模块： 调用每个模块init_process方法，例如http则启动监听socket初始化，event则初始化连接池，创建epoll等等 事件循环：接下来则是事件循环，调用event等待事件就绪，注意nginx的实现是有定时器的，我们这里为了跑通主流程，将定时器省去 全局变量12345cycle_t *GCYCLE;module_t* modules[] = &#123; &amp;http_core_module, &amp;event_core_module,&#125;; 如nginx一样 有一个全局cycle modules 保存了所有模块的地址，也就掌握了程序的核心启动入口，nginx所有的功能都是以单独的模块module_t来进行扩充的，而且模块之前还有启动顺序 @init 初始化cycle 申请内存池，默认1024字节，不够会单独扩充，注意需要先调用getpagesize()获取内核内存分页大小初始化全局pagesize变量 有了内存池后，其他所有内存申请都走内存池管理 打开日志文件 判断是否需要守护进程，这里在nginx中依然是通过解析配置来对应设置相关参数的，我们这里直接设置123456789101112131415161718192021222324252627//创建初始化cycle 全局结构体static cycle_t * init()&#123; pagesize = getpagesize(); cycle_t * cycle = (cycle_t*) malloc(sizeof(cycle_t)); memzero(cycle,sizeof(cycle_t)); cycle-&gt;pool = create_pool(1024); cycle-&gt;pool-&gt;max = MAX_ALLOC_FROM_POOL; GCYCLE = cycle;//global cycle //初始化监听端口链表 if (array_init(&amp;cycle-&gt;listening, cycle-&gt;pool, 10,sizeof(listening_t)) != OK)&#123; return NULL; &#125; // 打开日志文件 cycle-&gt;log = palloc(cycle-&gt;pool,sizeof(log_t)); cycle-&gt;log-&gt;use_logfile = 1; log_open(cycle-&gt;log, &quot;./run.log&quot;); //开启守护进程 cycle-&gt;is_daemon = 0; daemonize(cycle); return cycle; &#125; @init_module 初始化模块这里在nginx中其实是非常复杂的，因为在编译之前环境检查的时候就已经构造好了模块数组，所以做了大量的工作，但是本质其实就是将所有模块都加入到全局模块数组中，在后面cycle-&gt;init()的时候统一初始化 我们这里省去了前面初始化工作，直接加入我们仅有的两个模块http,event1234567//模拟nginx模块注册流程static void init_module(cycle_t *cycle)&#123; log_info(cycle-&gt;log,&quot;cycle: init module&quot;); cycle-&gt;modules_n = 2; cycle-&gt;modules = modules;&#125; @start_module 启动模块如nginx一样，在cycle_init中初始化所有核心模块，非核心模块应该在核心模块启动后自己管理的，我们只有两个核心模块，像nginx那样变量数组，直接调用init_process即可 我们这里也是由顺序的，必须先启动http模块将所有socket资源先初始化，然后在启动event模块，因为在event模块中需要收集相关网络事件，如监听的端口等12345678910111213//启动模块int_t start_module(cycle_t *cycle)&#123; log_info(cycle-&gt;log,\"cycle: start module\"); for(int i = 0;i &lt; cycle-&gt;modules_n ; i++)&#123; //http 注册tcp监听端口 //event 模块创建epoll epoll_events if(cycle-&gt;modules[i]-&gt;init_process(cycle) != OK)&#123; log_error(cycle-&gt;log,\"cycle: start module init process error\"); return ERROR; &#125; &#125; return OK;&#125; connection 相关封装了连接池相关代码，可以看 http://wiki.brewlin.com/wiki/blog/nginx/1.ngx_%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B8%8E%E4%BA%8B%E4%BB%B6%E5%B0%81%E8%A3%85(%E4%B8%80)/ http://wiki.brewlin.com/wiki/blog/nginx/2.ngx_%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B8%8E%E4%BA%8B%E4%BB%B6%E5%B0%81%E8%A3%85(%E4%BA%8C)/ mem_pool 相关封装了内存池相关代码，可以看 http://wiki.brewlin.com/wiki/blog/nginx/nginx_%E5%86%85%E5%AD%98%E6%B1%A0%E5%B0%81%E8%A3%85/ log 日志记录相关@log_open 日志打开这里可以看到，日志文件资源充分的利用了内存池机制，将资源类型自定义handler扔到内存池中，无需关心释放问题，在程序结束后销毁内存池时自动释放该文件资源 相关特性请看文章： http://wiki.brewlin.com/wiki/blog/nginx/nginx_%E5%86%85%E5%AD%98%E6%B1%A0%E5%B0%81%E8%A3%85/12345678910111213141516171819// 以append模式打开日志文件void log_open(log_t *log, const char *logfile) &#123; if (log-&gt;use_logfile) &#123; log-&gt;logfp = fopen(logfile, &quot;a&quot;); if (!log-&gt;logfp) &#123; perror(logfile); exit(1); &#125; //auto clean the file pool_cleanup_t *cl = pool_cleanup_add(GCYCLE-&gt;pool,sizeof(log_t)); cl-&gt;handler = clean; cl-&gt;data = log; return; &#125; openlog(&quot;weblog_t&quot;, LOG_NDELAY | LOG_PID, LOG_DAEMON);&#125; @log_request 记录日志请求12// 记录HTTP请求void log_request(http_connection *con) &#123;&#125; @log_error 错误日志打印12345678// 记录出错信息void log_error(log_t *log, const char *format, ...) &#123; va_list ap; va_start(ap, format); log_write(log, \"error\", format, ap); va_end(ap);&#125; @log_info 普通日志记录信息123456789// 记录日志信息void log_info(log_t *log, const char *format, ...) &#123; va_list ap; va_start(ap, format); log_write(log, \"info\", format, ap); va_end(ap);&#125; cmake 编译配置相关12345678910111213141516project(demo)add_definitions(&quot;-Wall -g&quot;)include_directories(./include)add_subdirectory(./core)add_subdirectory(./event)add_subdirectory(./http)add_executable(demo main.c)target_link_libraries(demo core http event core http) 在最后链接的时候，会发现有相互依赖的问题，原因是我们的程序相关隔离性还是没有划分的太好 比如在demo - core 中demo链接core中的函数，但是core中的函数又依赖http，所以只有在后面再多加一个连接即可","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"nginx","slug":"nginx","permalink":"http://wiki.brewlin.com/tags/nginx/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"nginx","slug":"blog/nginx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/"},{"name":"mini_ngx","slug":"blog/nginx/mini-ngx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/mini-ngx/"}]},{"title":"mini_ngx_实现一-简述","date":"2020-04-15T13:28:59.000Z","path":"wiki/blog/nginx/mini_ngx/1.mini_ngx_实现一-简述/","text":"简介github: https://github.com/brewlin/just-for-fun/mini_nginx mini_ngx 主要是抽取出nginx主体框架实现一个mini版demo，拆分nginxcycle http event等主要模块 主要抽取的相关知识点有,连接池,内存池,模块封装,epoll模块,非阻塞socket，端口复用,log.nginx为了保证高性能和挂平台会有大量的兼容性代码和细节优化代码，当前demo为了保证主流程的连贯，去掉相关优化和兼容，例如时间模块指定epoll实现，http只进行本地文件读取后响应客户端 相关配置 cycle-&gt;is_daemon = 0|1; 模拟nginx是否开启守护进程 cycle-modules_n = 2;cycle-&gt;modules = modules; 模拟nginx的模块架构,因为nginx所有的功能都封装为模块化，在编译期间就将所有的模块添加到一个数组中，并且在启动期间赋值给cycle-&gt;modules，因为我们只实现了两个模块http,event所以默认为2个模块 日志配置，nginx日志很强大，目前我们只实现对应的日志记录功能即可，需要手动配置 123456//src/core/cycle.c:92// 打开日志文件cycle-&gt;log = palloc(cycle-&gt;pool,sizeof(log_t));cycle-&gt;log-&gt;use_logfile = 1;log_open(cycle-&gt;log, \"./run.log\") 监听端口配置，因为nginx主要完全基于nginx.conf配置，所以每个模块都是根据配置中的参数做对应的初始化操作，例如listen配置会使用http模块来添加对应socket套接字和监听，我们的demo中就没有实现配置解析，所以模拟在个个模块中配置对应的监听端口 1234567//src/http/http.c:28//这里本来是http模块的初始化，每发现一个lisetn配置就会调用如下方法进行添加到cycle-&gt;istening链表上serv_addr.sin_family = AF_INET;serv_addr.sin_addr.s_addr = INADDR_ANY;//我们这里模仿nginx 就写死在模块初始化方法里默认监听8090端口serv_addr.sin_port = htons(8089) 连接池大小配置， nginx连接池大小是由event{ worker_connection 1000;}配置来决定的，同样我们在event模块初始化的时候是写在初始化方法里，模仿由配置文件中读取的连接池大小 12345678//src/event/event.c:74//初始化100个连接池cycle-&gt;connection_n = 100;//初始化epoll事件的大小内存申请//init epoll_create epoll_eventsevent_actions.init(cycle,cycle-&gt;connection_n/2); 功能简介 监听8089 tcp协议 将8090 加入epoll监听可读事件 http请求到来，触发epoll_wait就绪事件 分发8090socket accept接受新连接 为该连接分配内存池，并加入epoll读事件，等待客户端发送body数据 http请求发送body请求，触发epoll_wait就绪事件，分发该tcp连接连接ev-&gt;handler 解析http协议，读取对应html文件内容，响应客户端 回收内存池，删除epoll事件，关闭客户端fd，回收该连接 组织代码结构12345678910111213141516171819202122232425262728mini_nginx----------core 核心模块--------------cycle.c 启动函数--------------array.c 链表库--------------connection.c 连接池--------------mem_pool.c 内存池--------------log.c 日志记录--------------CMakeLists.txt 编译配置----------event 事件模块---------------event.c 核心函数---------------epoll_module.c 主要实现---------------event_accept.c accept---------------CMakeLists.txt 编译配置----------http http模块--------------http.c 主要函数--------------http_connection.c --------------http_header.c --------------request.c--------------response.c--------------stringutils.c--------------CMakeLists.txt 编译配置----------include 头文件库----------main.c main函数----------CMakeLists.txt 链接配置 编译启动12345&gt; cd /just-for-fun/mini_nginx&gt; cp -r www /tmp/www&gt; mkdir bin;cd bin&gt; cmake ../&gt; make 启动服务1&gt; ./demo 12&gt; curl http://127.0.0.1:8089/index.html&gt; tailf ./run.log","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"nginx","slug":"nginx","permalink":"http://wiki.brewlin.com/tags/nginx/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"nginx","slug":"blog/nginx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/"},{"name":"mini_ngx","slug":"blog/nginx/mini-ngx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/mini-ngx/"}]},{"title":"ngx_连接池与事件封装(二)","date":"2020-04-12T13:28:59.000Z","path":"wiki/blog/nginx/2.ngx_连接池与事件封装(二)/","text":"事件模型概述主要分为两个方面事件收集器、事件分发器 事件收集器也就是向epoll添加、更新、删除等事件，让epoll事件去管理 EPOLL_CTL_MOD EPOLL_CTL_ADD EPOLL_CTL_DEL事件分发器实际是调用epoll_wait 收集内核通知的就绪事件，然后调用ev-&gt;handler执行用户自定义该事件的处理方法 ngx 事件初始化事件的初始化实际就是对epoll进行初始化，如epoll_create（）调用创建epollfd event_list事件列表内存申请 123456789101112131415161718192021//src/event/ngx_event.c:608 ngx_event_process_init()..... for (m = 0; cycle-&gt;modules[m]; m++) &#123; if (cycle-&gt;modules[m]-&gt;type != NGX_EVENT_MODULE) &#123; continue; &#125; if (cycle-&gt;modules[m]-&gt;ctx_index != ecf-&gt;use) &#123; continue; &#125; module = cycle-&gt;modules[m]-&gt;ctx; if (module-&gt;actions.init(cycle, ngx_timer_resolution) != NGX_OK) &#123; /* fatal */ exit(2); &#125; break; &#125;..... 这里是event核心模块被cycle_init（）主函数进行init_process()初始化时调用的函数，在上一节有说明，该函数是对连接池 ,读事件 ,写事件等进行内存申请初始化，串联成链表 这里也是其中的工作之一，因为nginx高度可扩展，所以event实际的系统实现有很多种epoll,kqueue,pool,select..等，在./configure时会进行环境检查，将兼容平台的实现，如epoll_module.c加入到cycle-&gt;modules[m]中，所以上面的循环就是找出如epoll的实现并去调用该初始化方法，准备好接受事件 全局epoll接口加入平台的event实现为epoll则会调用epoll_moudle.c 的初始化方法，将相关的接口添加到 ngx_event_actions全局变量上123456789101112131415161718192021//src/event/module/epoll_module.c:369static ngx_event_module_t ngx_epoll_module_ctx = &#123; &amp;epoll_name, ngx_epoll_create_conf, /* create configuration */ ngx_epoll_init_conf, /* init configuration */ &#123; ngx_epoll_add_event, /* add an event */ ngx_epoll_del_event, /* delete an event */ ngx_epoll_add_event, /* enable an event */ ngx_epoll_del_event, /* disable an event */ ngx_epoll_add_connection, /* add an connection */ ngx_epoll_del_connection, /* delete an connection */ ngx_epoll_process_events, /* process the events */ ngx_epoll_init, /* init the events */ ngx_epoll_done, /* done the events */ &#125;&#125;;ngx_event_actions = ngx_epoll_module_ctx.actions; 也就是将epoll的add,del,add_con,del_con,epoll_process_events等接口条件到全局actions上，提供外部访问，收集外部事件，并分发就绪事件 事件相关api下面统一接口的实现假定为epoll实现1234567891011121314151617181920typedef struct &#123; ngx_int_t (*add)(ngx_event_t *ev, ngx_int_t event, ngx_uint_t flags); ngx_int_t (*del)(ngx_event_t *ev, ngx_int_t event, ngx_uint_t flags); ngx_int_t (*enable)(ngx_event_t *ev, ngx_int_t event, ngx_uint_t flags); ngx_int_t (*disable)(ngx_event_t *ev, ngx_int_t event, ngx_uint_t flags); ngx_int_t (*add_conn)(ngx_connection_t *c); ngx_int_t (*del_conn)(ngx_connection_t *c, ngx_uint_t flags); ngx_int_t (*notify)(ngx_event_handler_pt handler); ngx_int_t (*process_events)(ngx_cycle_t *cycle, ngx_msec_t timer, ngx_uint_t flags); ngx_int_t (*init)(ngx_cycle_t *cycle, ngx_msec_t timer); void (*done)(ngx_cycle_t *cycle);&#125; ngx_event_actions_t;ngx_event_actions_t ngx_event_actions; 在event.c 中会定义全局变量ngx_event_actions，改变量对应的平台实现的相关事件接口，如上文初始化时，如果平台支持epoll则将epoll事件的相关api添加到全局变量ngx_event_actions中，提供外部调用注册事件 12345678#define ngx_process_events ngx_event_actions.process_events#define ngx_done_events ngx_event_actions.done#define ngx_add_event ngx_event_actions.add#define ngx_del_event ngx_event_actions.del#define ngx_add_conn ngx_event_actions.add_conn#define ngx_del_conn ngx_event_actions.del_conn 并且默认提供了相关宏定义，直接通过宏定义更加方便些 @ngx_add_event 注册事件12345678910111213141516171819202122232425262728293031323334353637383940414243static int_tepoll_add_event(event_t *ev, int_t event, uint_t flags)&#123; int op; uint32_t events, prev; event_t *e; connection_t *c; struct epoll_event ee; c = ev-&gt;data; events = (uint32_t) event; if (event == READ_EVENT) &#123; e = c-&gt;write; prev = EPOLLOUT; events = EPOLLIN; &#125; else &#123; e = c-&gt;read; prev = EPOLLIN; events = EPOLLOUT; &#125; if (e-&gt;active) &#123; op = EPOLL_CTL_MOD; events |= prev; &#125; else &#123; op = EPOLL_CTL_ADD; &#125; ee.events = events | (uint32_t) flags; ee.data.ptr = (void *) ((uintptr_t) c | ev-&gt;instance); log_info(c-&gt;log,\"epoll add event %d \",c-&gt;fd); if (epoll_ctl(ep, op, c-&gt;fd, &amp;ee) == -1) &#123; log_error(c-&gt;log,\"epoll_ctl %d failed\\n\",c-&gt;fd); return ERROR; &#125; ev-&gt;active = 1; return OK;&#125; 判断是新增还是修改，e-&gt;active如果为1，说明之前注册过该事件，需要走更改事件流程epoll_ctl_mod 例如http流程中假如需要等待客户端发送body才能进行下面的操作，那么就可以将该http的读事件通过这个接口注册到epoll中 当客户端发送了数据，内核收到的数据后分发该就绪事件，将内核数据拷贝到用户态空间调用ev-&gt;handler()回调函数继续执行上一次中断的函数 @ngx_del_event 删除事件12345678910111213141516171819202122232425static int_tepoll_del_event(event_t *ev, int_t event, uint_t flags)&#123;....... if (e-&gt;active) &#123; op = EPOLL_CTL_MOD; ee.events = prev | (uint32_t) flags; ee.data.ptr = (void *) ((uintptr_t) c | ev-&gt;instance); &#125; else &#123; op = EPOLL_CTL_DEL; ee.events = 0; ee.data.ptr = NULL; &#125; log_info(c-&gt;log,\"epoll_ctl %d\",c-&gt;fd); if (epoll_ctl(ep, op, c-&gt;fd, &amp;ee) == -1) &#123; log_error(c-&gt;log,\"epoll_ctl :%d failed\",c-&gt;fd); return ERROR; &#125; ev-&gt;active = 0; return OK;&#125; 同样当http请求生命周期结束，也就是http 引用计数count真正为0的时候，会触发event_del,pool_destory,socket_close..等进行事件删除，内存池回收，tcp关闭等一系列回收机制 event事件删除后，epoll不在负责相关事件监控 @ngx_add_conn 注册连接事件该方法更加方便，直接将connection_t连接注册到epoll中12345678910111213141516171819static int_tepoll_add_connection(connection_t *c)&#123; struct epoll_event ee; ee.events = EPOLLIN|EPOLLOUT|EPOLLET; ee.data.ptr = (void *) ((uintptr_t) c | c-&gt;read-&gt;instance); log_info(c-&gt;log,\"epoll add connection fd:%d\",c-&gt;fd); if (epoll_ctl(ep, EPOLL_CTL_ADD, c-&gt;fd, &amp;ee) == -1) &#123; log_error(c-&gt;log,\"epoll add connection fd:%d failed\",c-&gt;fd); return ERROR; &#125; c-&gt;read-&gt;active = 1; c-&gt;write-&gt;active = 1; return OK;&#125; 直接调用epoll_ctl()将该事件添加到epoll_ctl中 @ngx_del_conn 删除事件12345678910111213141516171819202122232425static int_tepoll_del_connection(connection_t *c, uint_t flags)&#123; int op; struct epoll_event ee; if (flags &amp; CLOSE_EVENT) &#123; c-&gt;read-&gt;active = 0; c-&gt;write-&gt;active = 0; return OK; &#125; op = EPOLL_CTL_DEL; ee.events = 0; ee.data.ptr = NULL; if (epoll_ctl(ep, op, c-&gt;fd, &amp;ee) == -1) &#123; printf(\"del connection failed\"); return ERROR; &#125; c-&gt;read-&gt;active = 0; c-&gt;write-&gt;active = 0; return OK;&#125; 直接del移除该事件即可 @ngx_process_events 事件分发nginx是所有的事件执行都来自事件循环监测事件并发事件执行,该函数在nginxwoker进程启动后作为while(1){}循环事件调用,12345static ngx_int_tngx_epoll_process_events(ngx_cycle_t *cycle, ngx_msec_t timer, ngx_uint_t flags)&#123; .......&#125; 事件分发主要分为如下重要部分 调用epoll_wait监测就绪事件，如tcp连接，数据读写，tcp关闭。。。等等就绪事件,events为就绪事件的总数 1events = epoll_wait(ep, event_list, (int) nevents, timer); 分发所有就绪事件 12345678910111213141516171819202122 for (i = 0; i &lt; events; i++) &#123; c = event_list[i].data.ptr; instance = (uintptr_t) c &amp; 1; c = (ngx_connection_t *) ((uintptr_t) c &amp; (uintptr_t) ~1); rev = c-&gt;read; //判断该连接是否已经失效，因为如果在执行之前的连接事件的时候将当前连接关闭了，单该连接又被新连接给复用了，这就需要instance来解决了，closed无法解决新连接将之前连接复用的例外 if (c-&gt;fd == -1 || rev-&gt;instance != instance) &#123; /* * the stale event from a file descriptor * that was just closed in this iteration */ ngx_log_debug1(NGX_LOG_DEBUG_EVENT, cycle-&gt;log, 0, &quot;epoll: stale event %p&quot;, c); continue; &#125; 取出事件 revents = event_list[i].events;&#125; 这里比较重要，nginx是基于事件来执行的，如果其中任何一个事件阻塞了，将会导致整个进程得不到处理任何任务，例如新连接accept可能需要优先执行，而普通收发数据可能需要放到延迟队列去执行 12345if (flags &amp; NGX_POST_EVENTS) &#123; ngx_post_event(wev, &amp;ngx_posted_events);&#125; else &#123; wev-&gt;handler(wev);&#125;","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"epoll","slug":"epoll","permalink":"http://wiki.brewlin.com/tags/epoll/"},{"name":"nginx","slug":"nginx","permalink":"http://wiki.brewlin.com/tags/nginx/"},{"name":"connection-pool","slug":"connection-pool","permalink":"http://wiki.brewlin.com/tags/connection-pool/"},{"name":"event","slug":"event","permalink":"http://wiki.brewlin.com/tags/event/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"nginx","slug":"blog/nginx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/"}]},{"title":"linux_内核_链表偏移量技巧","date":"2020-04-10T13:28:59.000Z","path":"wiki/blog/php/linux_内核_链表偏移量技巧/","text":"@container_of 定义在看linux_os_link.c内核链表的时候，看到的一个高级技巧，通过结构体偏移量定位实际对象的指针地址 定义如下：123#define container_of(ptr, type, member) (&#123; \\ const typeof( ((type *)0)-&gt;member ) *__mptr = (ptr); \\ (type *)( (char *)__mptr - __offsetof(type,member) );&#125;) 总的来说ptr一个type对象里面的member成员指针，现在如果你只有member成员的指针，但是你想拿到type对象的地址那么container_of就发挥了重要作用，如下图所示:整个链表通过node指针串联起来，所以能够想到，当我们通过*node指针遍历所有的节点时，我们怎么获取到整个对象的地址呢答案当然是上面提到的container_of技巧:1234567//假如们已经遍历到了第一个node节点link_node *node;//现在我们想获取 struct test对象指针则可以这样struct test *obj = container_of(node,struct test,node);//现在obj 就是模板对象的指针了，是不是很方便呢， 当然这种技巧主要还是为了节省内存，你也可以在node结构体中加入一个自定义的结构体指针指向struct test即可，就不用通过偏移量定位了 通过container_of显然可以节省一个指针内存的空间了，这在很多高性能场景必然发挥了重要作用 container_of 解析（一）我们先来看第一行12#define container_of(ptr, type, member) (&#123; \\ const typeof( ((type *)0)-&gt;member ) *__mptr = (ptr); \\ ((type *)0)-&gt;memeber 通过将0X00地址转换为type自定义类型，再访问对应的member成员 typeof 编译期间获取member成员类型，其实就是获取node节点的结构体类型 const node *_mptr = (ptr) 首先ptr是链表的node节点指针，这行代码主要就是单独定义一个node指针执行ptr而已 container_of 解析 (二)这行代码是实际的偏移量计算代码1(type *)( (char *)__mptr - __offsetof(type,member) );&#125;) (char *)_mptr 我们知道指针的运算受限于指针类型，如果指针类型为int那么对int*指针 +1，则地址可能位移了4个字节,所以强制转换为char * 保证更加精确 _offsetof(type,member) 计算出成员member相对于结构体对象的内存偏移量 mptr - offsetof(type,membr) 12345678910111213//加入有一个结构体如下typedef struct&#123; char a, char b, link_node *node;&#125;test;//mptr 就是node指针//那么有如下计算offsetof(test,node) = 2;//因为node之前有两个字节，所以node相对于test结构体的偏移量为2所以mptr-offsetof(test,node) = test结构体的指针地址 @offsetof 定义offsetof可以用于计算某个成员相对于结构体对应的偏移量，这样当我们能拿到任意成员地址时，都能获取到结构体对象地址1#define __offsetof(TYPE, MEMBER) ((size_t) &amp;((TYPE *)0)-&gt;MEMBER ( (TYPE *)0) 将零转型为TYPE类型指针; ((TYPE *)0)-&gt;MEMBER 访问结构中的数据成员; &amp;( ( (TYPE *)0 )-&gt;MEMBER )取出数据成员的地址; (size_t)(&amp;(((TYPE*)0)-&gt;MEMBER))结果转换类型.巧妙之处在于将0转换成(TYPE*)，结构以内存空间首地址0作为起始地址，则成员地址自然为偏移地址； php扩展中的技巧场景在通过c++开发对应php扩展class时，会有这样的场景，对应php扩展类实例化的时候通常对应一个c++类，那么就会存在php-class对应一个c++-class关系 那么他们怎么关联的呢？可能最容易想到的是1234zend_declare_property_string(lib_co_server_ce_ptr, ZEND_STRL(&quot;obj&quot;), &quot;&quot;, ZEND_ACC_PRIVATE)Test *test = new Test();zend_update_property_string(lib_co_server_ce_ptr, getThis(), ZEND_STRL(&quot;obj&quot;), Z_VAL_P(test)); 总的来说就是在php属性中增加一个私有成员变量，将实例化的c++对象赋值给php成员变量 这种做法总的来说是灾难的，php内核不保证会做什么其他操作，非常不安全，还有就是每次访问对应的c++对象都需要进行读取操作，非常不友好 通过偏移量来绑定对应对象这种方式也是官方推荐的方式，健全、安全、且友好 首先定义主体结构体12345typedef struct&#123; Server *serv; zend_object std;&#125;serv 可以看出 std成员就是php对象实际指针，serv成员就是c++对象指针 定义对象生成事件12345678910111213static serv* lib_server_fetch_object(zend_object *obj)&#123; return (serv *)((char *)obj - lib_server_handlers.offset);&#125;static zend_object* lib_server_create_object(zend_class_entry *ce)&#123; serv *serv_t = (serv *)ecalloc(1, sizeof(serv) + zend_object_properties_size(ce)); zend_object_std_init(&amp;serv_t-&gt;std, ce); object_properties_init(&amp;serv_t-&gt;std, ce); serv_t-&gt;std.handlers = &amp;lib_server_handlers; return &amp;serv_t-&gt;std;&#125; 在php层面new serv()时，会调用lib_server_create_object函数，且函数内部我们不是直接去创建一个zend_object返回,而是创建一个serv 当我们想要获取c++对象时会调用fetch_object函数传入php对象指针obj其实就是上面的那个zend_object std，所以根据上面的技巧我们显然可以通过偏移量来获得c++指针的地址 结构体地址 也可以当做是第一个成员的地址这是c语言内存布局的特性，所以通过这个技巧就可以巧妙绑定c++对象以及php对象指针","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"os","slug":"os","permalink":"http://wiki.brewlin.com/tags/os/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"php","slug":"blog/php","permalink":"http://wiki.brewlin.com/categories/blog/php/"}]},{"title":"ngx_连接池与事件封装(一)","date":"2020-04-10T13:28:59.000Z","path":"wiki/blog/nginx/1.ngx_连接池与事件封装(一)/","text":"连接池概述nginx的连接池是属于短链接池的，因为主要业务场景为代理服务器，生命周期是有限的，下面来看看两种类型的连接池的区别 长连接连接池我们说连接池一般指的是：http连接池,tcp连接池,udp连接池等常用的网络连接复用。例如tcp连接池，当你有两个服务并且存在相互调用进行数据传输，那么必然存在连接建立(三次握手),连接关闭(四次挥手)等交互 问题是如果每次发送数据都要建立连接和关闭，那对于系统消耗还是很大的，每次创建连接不但要进行系统资源的消耗，而且用户层面也要申请内存来存放相关结构体 那么连接池的作用这时候就显得格外重要了，想象一下每次建立连接后不关闭呢，就让两个服务保持长连接通讯可以不呢？答案当然是yes 将所有连接一次性初始化,或者动态添加到连接池中，每次准备向对方发送数据时，直接去连接池里拿存活连接，没有就走新建连接流程 短连接池nginx的连接池其实是属于短连接池的，连接池的主要作用当然也是为了节省内存，提高tcp交互速度 但是短连接池还是有一些不一样的，因为在短链接的场景下网络连接是无法复用的，唯一能够复用的就是承载该网络连接的那个结构体,对于nginx来说，内存当然是能省就省 当然连接池里的连接也可以被某个持久长连接占用,而且是长期占用，对于代理的场景，那可能是双倍占用 连接池注意事项nginx的连接池在初始化启动期间就完全根据nginx.conf 中connections数量分配对应的内存，所以内存是一次性占有的，新连接进来也就是有一个fd数据变更 注意：连接池为空则丢弃该请求，不在处理新请求,例如你的worker_connections=5 那么当6条长连接请求过来时，最后一条肯定是不会被处理，一直处于等待期间 连接池初始化连接池初始化时属于event事件模块的任务，在event_core_module核心模块启动的时候（模块的启动由 cyle_init 中遍历所有的模块统一启动初始化）进行的初始化 static ngx_int_t ngx_event_process_init(ngx_cycle_t *cycle)为实际初始化连接池的函数 1234cycle-&gt;connections = ngx_alloc(sizeof(ngx_connection_t) * cycle-&gt;connection_n, cycle-&gt;log);if (cycle-&gt;connections == NULL) &#123; return NGX_ERROR;&#125; cycle-&gt;connection_n该参数在cycle_init主函数中 解析nginx.conf配置文件中worker_connection参数进行初始化，可以看出，该参数直接导致nginx在启动时会占用申请多少的内存，并且该内存会持续到nginx生命周期结束后释放 12345678910cycle-&gt;read_events = ngx_alloc(sizeof(ngx_event_t) * cycle-&gt;connection_n, cycle-&gt;log);if (cycle-&gt;read_events == NULL) &#123; return NGX_ERROR;&#125;rev = cycle-&gt;read_events;for (i = 0; i &lt; cycle-&gt;connection_n; i++) &#123; rev[i].closed = 1; rev[i].instance = 1;&#125; 连接池和读写事件是密不可分的，这里先申请对应数量的读事件并初始化为closed，在下文会和连接池进行一一绑定 12345678910cycle-&gt;write_events = ngx_alloc(sizeof(ngx_event_t) * cycle-&gt;connection_n, cycle-&gt;log);if (cycle-&gt;write_events == NULL) &#123; return NGX_ERROR;&#125;wev = cycle-&gt;write_events;for (i = 0; i &lt; cycle-&gt;connection_n; i++) &#123; wev[i].closed = 1;&#125; 申请写事件内存，和上面读事件对应，都是用于向epoll添加事件时的关联参数 12345678910111213i = cycle-&gt;connection_n;next = NULL;do &#123; i--; c[i].data = next; c[i].read = &amp;cycle-&gt;read_events[i]; c[i].write = &amp;cycle-&gt;write_events[i]; c[i].fd = (ngx_socket_t) -1; next = &amp;c[i];&#125; while (i); 将所有的连接 和对应的读写事件一一绑定，在epoll_wait 监听事件的时候就可以通过connection_t *c = ev-&gt;data获取对应连接对象 连接池相关接口 ngx_get_connection ngx_free_connection ngx_close_connection ngx_reusable_connection ngx_drain_connections @ngx_get_connection 获取空闲连接用的最多的接口，当accept被动打开新连接的时候，需要从连接池中获取空闲的connection_t结构体封装tcp连接 1234567891011121314c = ngx_cycle-&gt;free_connections;if (c == NULL) &#123; ngx_drain_connections((ngx_cycle_t *) ngx_cycle); c = ngx_cycle-&gt;free_connections;&#125;if (c == NULL) &#123; ngx_log_error(NGX_LOG_ALERT, log, 0, \"%ui worker_connections are not enough\", ngx_cycle-&gt;connection_n); return NULL;&#125; 直接通过cycle-&gt;free_connections 全局链表上拿表头的那个连接，如果不为空，说明空闲，直接走面初始化流程即可 如果连接为空，则需要调用ngx_drain_connections去释放空闲连接（去挨个执行所有的连接事件，尽可能的释放出一下空闲连接出来） 12345678910111213141516ngx_cycle-&gt;free_connections = c-&gt;data;ngx_cycle-&gt;free_connection_n--;if (ngx_cycle-&gt;files &amp;&amp; ngx_cycle-&gt;files[s] == NULL) &#123; ngx_cycle-&gt;files[s] = c;&#125;rev = c-&gt;read;wev = c-&gt;write;ngx_memzero(c, sizeof(ngx_connection_t));c-&gt;read = rev;c-&gt;write = wev;c-&gt;fd = s;c-&gt;log = log; 这里就是获取连接的主要操作了，连接池的所有连接都是在一个链表上通过c-&gt;data串起来的，所以，这里只是将空闲指针移动到下一位即可，回收的时候也只需要插入表头指针前面即可,存取的复杂度都是O(1) @ngx_drain_connections 释放空闲连接在上面从连接池中获取连接的时候，会发现如果没有空余的连接则会调用如下的方法看看是否能强制空出一些连接来12345678910111213141516171819202122static voidngx_drain_connections(void)&#123; ngx_int_t i; ngx_queue_t *q; ngx_connection_t *c; for (i = 0; i &lt; 32; i++) &#123; if (ngx_queue_empty(&amp;ngx_cycle-&gt;reusable_connections_queue)) &#123; break; &#125; q = ngx_queue_last(&amp;ngx_cycle-&gt;reusable_connections_queue); c = ngx_queue_data(q, ngx_connection_t, queue); ngx_log_debug0(NGX_LOG_DEBUG_CORE, c-&gt;log, 0, \"reusing connection\"); c-&gt;close = 1; c-&gt;read-&gt;handler(c-&gt;read); &#125;&#125; 其实主要就是看看queue长连接链表上选取32个出来，对他们全部执行c-&gt;close = 1,read-&gt;handler(c-&gt;read),由于close属性会导致http_close_connection回收该链接 但是强制回收链接前会对他进行一个读取事件的操作recv(fd)，如果返回0 则说明对端已关闭，也需要在handler中释放该链接到free_connections上。 @ngx_reuseable_connection 添加长连接队列该方法当客户端设置keep-alive长连接属性时，nginx会将它丢到c-&gt;queue队列上，遇到上面连接池不够时，会释放掉长连接队列上的 不活跃链接1234567891011121314151617181920voidngx_reusable_connection(ngx_connection_t *c, ngx_uint_t reusable)&#123; // 一旦一个keepalive的连接正常处理了，就将其从reusable队列中移除 if (c-&gt;reusable) &#123; ngx_queue_remove(&amp;c-&gt;queue); &#125; // 在ngx_http_set_keepalive中会将reusable置为1，reusable为1的直接效果 // 就是将该连接插到reusable_connections_queue中 c-&gt;reusable = reusable; // 当reusable为0时，意味着该keepalive被正常的处理掉了，不应该被再次添加 // 到reusable队列中了。 if (reusable) &#123; /* need cast as ngx_cycle is volatile */ // 这里使用头插法，较新的连接靠近头部，时间越久未被处理的连接越靠尾 ngx_queue_insert_head( (ngx_queue_t *) &amp;ngx_cycle-&gt;reusable_connections_queue, &amp;c-&gt;queue); &#125; @free_connection 归还到空闲连接池链表上@close_connection 关闭连接并清理回收会进行一系列清除工作 移除epoll监听的读写事件 删除任务队列post_event队列 标记读写事件关闭 从长连接链表里面移除该链接归还到 空闲链表上 调用上面free_connection归还链接到空闲链表上 close(fd) 关闭tcp对端 连接池在框架初始化中的体现在nginx启动期间，读取nginx.conf中的配置，并调用个个模块的方法来处理它 例如server{ listen 8080; }这种配置，会全部被http核心模块解析 每发现一个listen配置，就会调用http模块create_conf,init_conf等来保存该配置 并且将每一个端口 初始化为listening_t结构体保存到全局cycle-&gt;listening数组中 在cycle_init主函数中，调用每个模块的时候会触发http-&gt;init_process初始化http核心模块，然后将所有的端口都进行sock_create(),bind(),listen等操作创建socket 最后从连接池中为每个socket 分配一个connection_t连接包装其他 服务端socket 和 普通tcp的连接有什么不同呢？其实主要是在conneciton-&gt;read读事件为accept，非常灵活的将各种类型的连接都统一为相同的接口 @ngx_create_listening 保存监听端口每从nginx.conf中读取一个listen配置，都需要创建一个listenint_t结构体保存到全局链表上123456789101112//core/ngx_connection.c:20 ls = ngx_array_push(&amp;cf-&gt;cycle-&gt;listening); if (ls == NULL) &#123; return NULL; &#125; ngx_memzero(ls, sizeof(ngx_listening_t)); sa = ngx_palloc(cf-&gt;pool, socklen); if (sa == NULL) &#123; return NULL; &#125; @ngx_open_listening_sockets 创建所有socket12345678910//core/ngx_connection.c:269ls = cycle-&gt;listening.elts;for (i = 0; i &lt; cycle-&gt;listening.nelts; i++) &#123; s = ngx_socket(ls[i].sockaddr-&gt;sa_family, ls[i].type, 0) if (setsockopt(s, SOL_SOCKET, SO_REUSEADDR, (const void *) &amp;reuseaddr, sizeof(int)) if (bind(s, ls[i].sockaddr, ls[i].socklen) == -1) if (listen(s, ls[i].backlog) == -1) &#123;&#125; 总之就是初始化所有配置文件中定义的socket @ngx_event_process_init epoll监听所有socket12345678910111213141516171819202122232425262728event/event.c ls = cycle-&gt;listening.elts; for (i = 0; i &lt; cycle-&gt;listening.nelts; i++) &#123; c = ngx_get_connection(ls[i].fd, cycle-&gt;log); if (c == NULL) &#123; return NGX_ERROR; &#125; c-&gt;log = &amp;ls[i].log; c-&gt;listening = &amp;ls[i]; ls[i].connection = c; rev = c-&gt;read; rev-&gt;handler = ngx_event_accept; if (ngx_event_flags &amp; NGX_USE_RTSIG_EVENT) &#123; if (ngx_add_conn(c) == NGX_ERROR) &#123; return NGX_ERROR; &#125; &#125; else &#123; if (ngx_add_event(rev, NGX_READ_EVENT, 0) == NGX_ERROR) &#123; return NGX_ERROR; &#125; &#125; &#125; 从连接池中获取空闲连接包装socket 将event事件设置为ngx_event_accept 当事件触发了，那一定可能是新是连接的到来需要accept 将socket读写事件加入epoll监听","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"epoll","slug":"epoll","permalink":"http://wiki.brewlin.com/tags/epoll/"},{"name":"nginx","slug":"nginx","permalink":"http://wiki.brewlin.com/tags/nginx/"},{"name":"connection-pool","slug":"connection-pool","permalink":"http://wiki.brewlin.com/tags/connection-pool/"},{"name":"event","slug":"event","permalink":"http://wiki.brewlin.com/tags/event/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"nginx","slug":"blog/nginx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/"}]},{"title":"线程池","date":"2020-03-31T13:28:59.000Z","path":"wiki/c-ext/thread/线程池/","text":"demo1234567891011121314&lt;?php$pool = new Lib\\Thread\\Pool(4);$ref = [1,2,3,4];//future = Lib\\Thread\\Pool\\Future//future-&gt;get() 可以阻塞返回结果$future = $pool-&gt;add(function()use(&amp;$ref)&#123; sleep(1); var_dump($ref);&#125;);$future-&gt;get();; @construct 创建线程数量构造函数需要传入线程创建的参数，在初始化就默认创建固定的线程数量 @add 投递执行任务add() 函数接受一个php闭包函数，可通过引用的方式附加传入参数 投递后如果有线程空闲，立即执行该任务 @线程池销毁 与释放流程123456&lt;?phptest();function test()&#123; $pool = new Lib\\Thread\\Pool(4); $pool-&gt;add(function()&#123;&#125;);&#125; $pool 的生命周期在test函数内，如果函数调用结束，那么触发$pool垃圾回收，且该类为自定义类型，所以回收会触发如下线程回收流程: php : $pool-&gt;destruct(); php对象释放 php : $pool-&gt;free_object(); php对象底层扩展进行释放内存处理 c++ : pool-&gt;~pool() 调用c++线程池对象析构函数 c++ : 加锁改变线程状态 并唤醒所有线程，等待回收线程 12345678910ThreadPool::~ThreadPool()&#123; &#123; unique_lock&lt;mutex&gt; lock(queue_mu); stop = true; &#125; cond.notify_all(); for(thread &amp;w : workers)&#123; w.join(); &#125;&#125; 所以线程池的生命周期，依赖php对象实例，如果需要常驻运行，则需要将$pool 设置为全局或者静态变量 @Lib\\Thread\\Pool\\Future投递任务后立即返回一个future包装器，可用于阻塞等待任务结束获取返回值，转换为同步阻塞程序 1$future = $pool-&gt;add(function()&#123;&#125;); @furture-&gt;get() 等待该异步任务处理结束该函数用于等待，当前线程执行的任务结束,并获取返回值12345$future = $pool-&gt;add(function()&#123; return [1,3,4,5];&#125;);$res = $future-&gt;get();//res = [1,3,4,5] @异步任务demo将100个任务全部投递到线程排队处理，然后当前继续执行其他任务123456for($i = 0;$i &lt; 100 ;$i ++)&#123; $pool-&gt;add(function()&#123; sleep(1); &#125;);&#125;//这里继续执行其他任务 @同步任务demo将100个任务投递到线程处理，并逐一等待每一任务执行完毕12345678for($i = 0;$i &lt; 100 ;$i ++)&#123; $future = $pool-&gt;add(function()use($i)&#123; sleep(1); return $i; &#125;); var_dump($future-&gt;get());&#125;//这里继续阻塞，直到上面100s过期后任务处理完毕","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"thread","slug":"thread","permalink":"http://wiki.brewlin.com/tags/thread/"},{"name":"pool","slug":"pool","permalink":"http://wiki.brewlin.com/tags/pool/"}],"categories":[{"name":"c-ext","slug":"c-ext","permalink":"http://wiki.brewlin.com/categories/c-ext/"},{"name":"thread","slug":"c-ext/thread","permalink":"http://wiki.brewlin.com/categories/c-ext/thread/"}]},{"title":"ngx_内存池封装","date":"2020-03-10T13:28:59.000Z","path":"wiki/blog/nginx/nginx_内存池封装/","text":"内存池主要作用nginx里几乎所有内存申请都是从ngx_pool_t上申请的，nginx封装了自己的内存池技术提升性能主要有三点好处，内存分配速度快,防止内存碎片,方便内存回收，防止内存泄漏 内存分配速度快主要因为c没有垃圾回收机制，没有gc，并且区分堆内存/栈内存。且堆内存上的数据申请后就必须由开发者手动回收，如果不释放则会内存一直堆积，直到系统资源消耗殆尽，系统回收进程 如果许许多多的变量创建并且都是通过直接像系统申请(malloc)的话，那么整体性能肯定会有所影响和下降，内存池是怎么发挥作用的呢：其实就是预分配的操作，创建内存池的时候首先向操作系统申请一块适当的内存(16k的样子)。在程序运行期间其他所有的内存申请都通过内存池去获取，直接用该段由内存池返回的内存即可 减少了向操作系统申请的次数 防止内存碎片摘自网友们的说法： 内存碎片的经典症状是，即使您似乎有足够的可用内存，您也尝试分配一个大块而您却无法分配。另一个可能的结果是该进程无法将内存释放回OS（因为从OS分配的所有块中仍然有一些对象在使用中，即使这些块现在几乎未使用）。 方便内存回收，防止内存泄漏这个特性是利好的，想像一下函数A里分配了一块内存，但是b,c,d,e,ft...等等其他地方都有调用，而且每个功能片区都有成百行代码，可想而知，该内存由谁来释放，或者多次释放将是多么灾难的事情 nginx的内存池其实主要是针对场景的。因为大多数程序都是有生命周期的，例如http请求到来，在整个处理期间可能会异步处理很多过程，分配很多数据，那么终会有连接断开和结束的时候，那么这个时候内存池的技术就发挥了非常重要的作用，连接到来创建内存池 - 结束连接统一销毁所有内存：中间其他所有的操作压根儿不用关系内存释放的问题，只管申请，想想都是非常轻松的事情在连接期间各种模块之间的调用远比这个要复杂的多，要是每个地方都需要关注上下文将是多么灾难的事情 引入内存池后只需要两行代码即可消除大部分安全隐患12345pool_t *pool = pool_create(default);//.....do lot of thingspool_destory(pool); nginx内存池定义相关定义结构体@pool_t 内存池指针pool_t是一个链表头主结构体1234567struct pool_s &#123; pool_data_t d; size_t max; pool_t *current; pool_large_t *large; pool_cleanup_t *cleanup;&#125;; 新创建的内存池默认可用内存大小其实是这样计算的size - sizeof(pool_t) = 可用内存大小,因为总体内存池的首地址就是pool_t的地址 pool_data_t 1当内存不够用，需要扩容时，会将新申请的内存通过pool_data_t-&gt;next串联起来，组成一个链表 size_t max 判断待申请的内存属于大块还是小块 123小块内存则直接在当前内存池返回一段可用内存即可打开内存需要单独向操作系统申请，并挂载到当前的内存池pool_large_t large的链表上 current 指向当前可用内存池 1因为内存池扩容的机制是，重新生成一块内存并通过链表挂载一起，那么current就显得格外重要，它直接指向新生成的可用内存池即可 large 挂载大块内存的链表，如上第2点所说 cleanup 内存池还有一个机制就是可以管理非内存资源的释放，后文详说 @pool_data_t 链表主要作用就是作为pool_t的一部分，将所有内存池串联成为一个链表，最后释放时遍历链表释放123456typedef struct &#123; u_char *last; u_char *end; pool_t *next; uint_t failed;&#125; pool_data_t; last 指向可以用内存的首地址 end 指向内存池尾部地址 next指向 下一块内存池地址 failed 比较重要12341. 当前内存池不够分配使用时，会新申请一个内存池，并通过next挂在链表上2. 同时failed += 1, 但是current指针不变3. 那么下次依然会去上面那个内存池继续分配，如果依然不满足条件，failed += 1；4. 直到failed 值 大于4时，内存池的current指向下一个内存池，实现完全转移到新的内存池 @pool_large_t 大内存块链表这个比较容易理解，当待分配内存大于pool-&gt;max时，则向操作系统分配大内存块挂到pool-&gt;large链表上，最后在同一删除，也可以自己手动删除12345typedef struct pool_large_s pool_large_t;struct pool_large_s &#123; pool_large_t *next; void *alloc;&#125;; alloc 实际内存地址 内存池主要接口 create_pool(size_t size) 创建一块内存池 desotry_pool(pool_t *pool) 释放回收所有相关内存 reset_pool(pool_t *pool) 复位内存池 palloc(pool_t *poo,size_t size) 从内存池分配内存，默认字节对齐 pnalloc(pool_t *poo,size_t size) 从内存池分配内存,不对齐字节 pmemalign(pool_t *pool,size_t size,size_t alignment) 分配专用大块内存 pfree(pool_t *pool,void *p) 回收大块内存 pool_cleanup_add(pool_t *p,size_t size) 增加自定资源释放handler 其实总的来说就3个接口比较重要create_pool,destory_pool,palloc，分别是创建内存池，销毁内存池，申请内存，就可以了 其他地方只需要调用palloc申请内存就行，无需关系释放问题,所以其他接口也不需要太关注 内存池主要接口实现@create_pool 创建内存池实现nginx内存池的申请场景主要是针对每个连接而言的，例如针对http连接有如下的条件: 未每个http连接申请一个内存池,该内存池指针会随着http的生命周期一直存在 每个连接期间通过该pool进行内存申请，无需关注释放 http生命周期结束，也就是tcp连接关闭的时候释放内存池pool_t *pool释放内存完成任务 所以基本上每个请求都是自带自己的内存池，这样减少了内存释放不干净的风险（大概是吧，有太多原因这样做了）。 还有就是每个连接池默认大小为deafult_pool_size = 16k，所以不用担心每个连接都申请内存这种做法会太耗内存，实际内存会在使用中进行扩容 实现如下:1234567891011121314151617181920pool_t *p; //分配对齐内存 p = memalign(POOL_ALIGNMENT, size); if (p == NULL) &#123; return NULL; &#125; p-&gt;d.last = (u_char *) p + sizeof(pool_t); p-&gt;d.end = (u_char *) p + size; p-&gt;d.next = NULL; p-&gt;d.failed = 0; size = size - sizeof(pool_t); p-&gt;max = (size &lt; MAX_ALLOC_FROM_POOL) ? size : MAX_ALLOC_FROM_POOL; p-&gt;current = p; p-&gt;large = NULL; p-&gt;cleanup = NULL; return p; 分配对其内存，默认16k 总体可分配内存= 16k - sizeof(pool_t) d.last指针指向可用内存 d.end指针指向内存池末尾 d.failed 归 0 current指向当前内存池，因为初始化的就是当前可用内存池 其他都置为空指针 @destory_pool 回收内存池实现一般是在连接的生命周期结束close的时候销毁内存池，那么内存池会逐个遍历内存池链表挨个释放所有的内存，包括小内存块,大内存块,释放自定义资源 代码实现如下:123456789101112131415161718192021222324252627282930//内存池销毁//1.调用所有注册在pool_t上的清理事件//2.清理large内存块//3.清理所有pool_t内存块void destroy_pool(pool_t *pool)&#123; pool_t *p, *n; pool_large_t *l; pool_cleanup_t *c; for (c = pool-&gt;cleanup; c; c = c-&gt;next) &#123; if (c-&gt;handler) &#123; c-&gt;handler(c-&gt;data); &#125; &#125; for (l = pool-&gt;large; l; l = l-&gt;next) &#123; if (l-&gt;alloc) &#123; free(l-&gt;alloc); &#125; &#125; for (p = pool, n = pool-&gt;d.next; /* void */; p = n, n = n-&gt;d.next) &#123; free(p); if (n == NULL) &#123; break; &#125; &#125;&#125; 遍历自定义事件，清除所有的自定义非内存资源：如文件fd 遍历大内存块，回收所有大内存块数据 遍历小内存块，回收所有小内存块，相当简洁12因为pool_t *pool;就是整个小内存块首地址，所以直接free(p) 即可，非常灵活 @palloc 内存分配实现作为使用场景最多的接口，提供分配内存，并内部自动管理内存，无需手动释放 该接口分配的内存默认是字节对齐，为了减少内存碎片而设计 代码实现如下:1234567891011121314151617181920212223242526static inline void *palloc_small(pool_t *pool, size_t size, uint_t align)&#123; u_char *m; pool_t *p; p = pool-&gt;current; do &#123; m = p-&gt;d.last; if (align) &#123; m = align_ptr(m, ALIGNMENT); &#125; if ((size_t) (p-&gt;d.end - m) &gt;= size) &#123; p-&gt;d.last = m + size; return m; &#125; p = p-&gt;d.next; &#125; while (p); return palloc_block(pool, size);&#125; 获取当前可分配内存池的指针pool-&gt;current 遍历当前内存池链表，找到可容纳的内存并直接返回，如果不满足则进行第3步 说明当前内存池空间不够，需要向操作系统申请内存palloc_block 123456789101112131415161718192021222324252627282930313233static void *palloc_block(pool_t *pool, size_t size)&#123; u_char *m; size_t psize; pool_t *p, *new; psize = (size_t) (pool-&gt;d.end - (u_char *) pool); m = memalign(POOL_ALIGNMENT, psize); if (m == NULL) &#123; return NULL; &#125; new = (pool_t *) m; new-&gt;d.end = m + psize; new-&gt;d.next = NULL; new-&gt;d.failed = 0; m += sizeof(pool_data_t); m = align_ptr(m, ALIGNMENT); new-&gt;d.last = m + size; for (p = pool-&gt;current; p-&gt;d.next; p = p-&gt;d.next) &#123; if (p-&gt;d.failed++ &gt; 4) &#123; pool-&gt;current = p-&gt;d.next; &#125; &#125; p-&gt;d.next = new; return m;&#125; 向操作系统分配一块和之前内存池一样大小(psize)的内存 初始化新申请的pool_t内存池结构 遍历之前所有可用内存池链表，将失败次数failed+1，如果大于4，则将current可用内存池指针下移，丢弃该不可用内存池 将新申请的小块内存池挂载到整个内存池链表的末尾，完成内存分配逻辑,返回可用内存空间(return m)给调用方 内存池其他接口相关@reset_pool 复位内存池该接口可能用的比较少，但是却对于内存复用非常有用，试想一下，如果每个连接来都申请内存、结束释放内存,如果并发量大，是不是可以有优化的空间呢，答案当然是yes 那继续来讲讲内存池可分配的原理1234567891011121314typedef struct &#123; u_char *last; u_char *end; pool_t *next; uint_t failed;&#125; pool_data_t;struct pool_s &#123; pool_data_t d; size_t max; pool_t *current; pool_large_t *large; pool_cleanup_t *cleanup;&#125;; 标志一段内存池是否空间足够主要是根据last,end指针来判断的 实际可分配内存为 size = end - last 那么在连接关闭的时候，其实我们不用将内存池返回给操作系统，而是直接调用reset_pool将last置为初始位置即可，那么下一个连接就可以继续使用该段内存，没有任何后顾之忧 就这样就完成了内存的交接，该复用逻辑可以根据自己的场景进行改装，当前内存池实现只是一个通用，可扩展的库 @pncall 分配不对齐内存也就是从内存池上直接顺序从后面获取可分配内存,不用计算字节内存偏移量，这样有好处也有坏处 好处：不用浪费一定字节的内存 坏处：当然是可能造成内存碎片 非内存资源回收机制内存池不但能管理内存资源，还可以管理非内存资源等回收，例如文件资源，其他socket资源等 但是需要用户提前将该资源回收事件提前注册到内存池内，在内存释放的时候统一释放 相关结构体123456typedef struct pool_cleanup_s pool_cleanup_t;struct pool_cleanup_s &#123; pool_cleanup_pt handler; void *data; pool_cleanup_t *next;&#125;; handler 是一个函数指针，指向用户自定义的函数，当内存清理的时候需要调用该函数指向用户自己的资源回收逻辑 *data 用户自定义的结构体，当回调用户的函数时，会回传给用户 *next 所有的自定义事件串联为链表，在内存池回收时统一调用 @clean_up 实现123456789101112131415161718192021222324252627//注册清除资源事件，内存回收时会调用该回调函数清除相关自定义资源pool_cleanup_t *pool_cleanup_add(pool_t *p, size_t size)&#123; pool_cleanup_t *c; c = palloc(p, sizeof(pool_cleanup_t)); if (c == NULL) &#123; return NULL; &#125; if (size) &#123; c-&gt;data = palloc(p, size); if (c-&gt;data == NULL) &#123; return NULL; &#125; &#125; else &#123; c-&gt;data = NULL; &#125; c-&gt;handler = NULL; c-&gt;next = p-&gt;cleanup; p-&gt;cleanup = c; return c;&#125; 申请一个pool_cleanup_t内存，表示当前资源事件 如果用户有自定义资源，则申请size内存并返回用户使用，一般都是需要的，不然释放什么呢 将当前事件链接到链表中，并返回用户该事件提供注册回收函数，和回收数据 @clean_up demo123456789101112131415161718typedef struct &#123; int fd; u_char *name;&#125; file_t;void clean(void *data)&#123; file_t *c = data; if(close(c-&gt;fd) == FILE_ERROR) &#123; printf(\"close file failed\\n\"); &#125; //不需要 free(data),因为内存是在内存池上分配的&#125;int main()&#123; pool_cleanup_t *c = pool_cleanup_add(pool,sizeof(file_t)); ((file_t *)c-&gt;data)-&gt;fd = i; c-&gt;handler = clean; &#125; 定义自己的资源结构体 调用pool_cleanup_add 新增一个事件 设置自己的资源清理函数，并挂载到事件上 这样就完成了自定义资源的释放了，在内存最终回收时能正确全部释放 注意事项 内存池没有暴露大内存块的申请接口,palloc_large，因为统一在palloc中判断，如果目标内存大于pool-&gt;max则自动走大内存分配逻辑，不再从pool上分配，而是直接从堆内存中分配，挂载到pool-&gt;large链表上 pool-&gt;max 值的确定,必须要提前调用pagesize()设置全局变量的大小12345int main()&#123; //pagesize 在 palloc.h 中定义的全局变量 pagesize = getpagesize(); reutrn 0;&#125; 完整代码zip完整代码code: mempool.zip 简易预览123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304#include \"palloc.h\"static void *palloc_small(pool_t *pool, size_t size,uint_t align);static void *palloc_block(pool_t *pool, size_t size);static void *palloc_large(pool_t *pool, size_t size);//创建内存池，默认分配的内存包含了pool_t结构体的大小，所以实际可分配内存为size - sizeof(pool_t);pool_t *create_pool(size_t size)&#123; pool_t *p; //分配对齐内存 p = mem_memalign(POOL_ALIGNMENT, size); if (p == NULL) &#123; return NULL; &#125; p-&gt;d.last = (u_char *) p + sizeof(pool_t); p-&gt;d.end = (u_char *) p + size; p-&gt;d.next = NULL; p-&gt;d.failed = 0; size = size - sizeof(pool_t); p-&gt;max = (size &lt; MAX_ALLOC_FROM_POOL) ? size : MAX_ALLOC_FROM_POOL; p-&gt;current = p; p-&gt;large = NULL; p-&gt;cleanup = NULL; return p;&#125;//内存池销毁//1.调用所有注册在pool_t上的清理事件//2.清理large内存块//3.清理所有pool_t内存块void destroy_pool(pool_t *pool)&#123; pool_t *p, *n; pool_large_t *l; pool_cleanup_t *c; for (c = pool-&gt;cleanup; c; c = c-&gt;next) &#123; if (c-&gt;handler) &#123; c-&gt;handler(c-&gt;data); &#125; &#125; for (l = pool-&gt;large; l; l = l-&gt;next) &#123; if (l-&gt;alloc) &#123; free(l-&gt;alloc); &#125; &#125; for (p = pool, n = pool-&gt;d.next; /* void */; p = n, n = n-&gt;d.next) &#123; free(p); if (n == NULL) &#123; break; &#125; &#125;&#125;//重置内存池//1.销毁所有的large内存块//2.复位每个pool_t内存块的last起始位置，以前的数据不再生效void reset_pool(pool_t *pool)&#123; pool_t *p; pool_large_t *l; for (l = pool-&gt;large; l; l = l-&gt;next) &#123; if (l-&gt;alloc) &#123; free(l-&gt;alloc); &#125; &#125; for (p = pool; p; p = p-&gt;d.next) &#123; p-&gt;d.last = (u_char *) p + sizeof(pool_t); p-&gt;d.failed = 0; &#125; pool-&gt;current = pool; pool-&gt;large = NULL;&#125;//分配地址对齐的内存void *palloc(pool_t *pool, size_t size)&#123; if (size &lt;= pool-&gt;max) &#123; return palloc_small(pool, size, 1); &#125; return palloc_large(pool, size);&#125;//分配内存时不对齐内存void * pnalloc(pool_t *pool, size_t size)&#123; if (size &lt;= pool-&gt;max) &#123; return palloc_small(pool, size, 0); &#125; return palloc_large(pool, size);&#125;//分配内存主函数static inline void *palloc_small(pool_t *pool, size_t size, uint_t align)&#123; u_char *m; pool_t *p; p = pool-&gt;current; do &#123; m = p-&gt;d.last; if (align) &#123; m = align_ptr(m, ALIGNMENT); &#125; if ((size_t) (p-&gt;d.end - m) &gt;= size) &#123; p-&gt;d.last = m + size; return m; &#125; p = p-&gt;d.next; &#125; while (p); return palloc_block(pool, size);&#125;static void *palloc_block(pool_t *pool, size_t size)&#123; u_char *m; size_t psize; pool_t *p, *new; psize = (size_t) (pool-&gt;d.end - (u_char *) pool); m = mem_memalign(POOL_ALIGNMENT, psize); if (m == NULL) &#123; return NULL; &#125; new = (pool_t *) m; new-&gt;d.end = m + psize; new-&gt;d.next = NULL; new-&gt;d.failed = 0; m += sizeof(pool_data_t); m = align_ptr(m, ALIGNMENT); new-&gt;d.last = m + size; for (p = pool-&gt;current; p-&gt;d.next; p = p-&gt;d.next) &#123; if (p-&gt;d.failed++ &gt; 4) &#123; pool-&gt;current = p-&gt;d.next; &#125; &#125; p-&gt;d.next = new; return m;&#125;//分配大块内存主函数static void *palloc_large(pool_t *pool, size_t size)&#123; void *p; uint_t n; pool_large_t *large; p = malloc(size); if (p == NULL) &#123; return NULL; &#125; n = 0; for (large = pool-&gt;large; large; large = large-&gt;next) &#123; if (large-&gt;alloc == NULL) &#123; large-&gt;alloc = p; return p; &#125; if (n++ &gt; 3) &#123; break; &#125; &#125; large = palloc_small(pool, sizeof(pool_large_t), 1); if (large == NULL) &#123; free(p); return NULL; &#125; large-&gt;alloc = p; large-&gt;next = pool-&gt;large; pool-&gt;large = large; return p;&#125;//分配对其内存，并挂到large链表上void *pmemalign(pool_t *pool, size_t size, size_t alignment)&#123; void *p; pool_large_t *large; p = mem_memalign(alignment, size); if (p == NULL) &#123; return NULL; &#125; large = palloc_small(pool, sizeof(pool_large_t), 1); if (large == NULL) &#123; free(p); return NULL; &#125; large-&gt;alloc = p; large-&gt;next = pool-&gt;large; pool-&gt;large = large; return p;&#125;//回收指定large内存int_t pfree(pool_t *pool, void *p)&#123; pool_large_t *l; for (l = pool-&gt;large; l; l = l-&gt;next) &#123; if (p == l-&gt;alloc) &#123; free(l-&gt;alloc); l-&gt;alloc = NULL; return OK; &#125; &#125; return ERROR;&#125;//分配对其并初始化该段内存void *pcalloc(pool_t *pool, size_t size)&#123; void *p; p = palloc(pool, size); if (p) &#123; memzero(p, size); &#125; return p;&#125;//注册清除资源事件，内存回收时会调用该回调函数清除相关自定义资源pool_cleanup_t *pool_cleanup_add(pool_t *p, size_t size)&#123; pool_cleanup_t *c; c = palloc(p, sizeof(pool_cleanup_t)); if (c == NULL) &#123; return NULL; &#125; if (size) &#123; c-&gt;data = palloc(p, size); if (c-&gt;data == NULL) &#123; return NULL; &#125; &#125; else &#123; c-&gt;data = NULL; &#125; c-&gt;handler = NULL; c-&gt;next = p-&gt;cleanup; p-&gt;cleanup = c; return c;&#125;#if (HAS_POSIX_MEMALIGN)void *mem_memalign(size_t alignment, size_t size)&#123; void *p; int err = posix_memalign(&amp;p, alignment, size); if (err) &#123; p = NULL; &#125; return p;&#125;#elif (HAS_MEMALIGN)void *mem_memalign(size_t alignment, size_t size)&#123; return memalign(alignment, size);&#125;#endif","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"pool","slug":"pool","permalink":"http://wiki.brewlin.com/tags/pool/"},{"name":"nginx","slug":"nginx","permalink":"http://wiki.brewlin.com/tags/nginx/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"nginx","slug":"blog/nginx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/"}]},{"title":"dns协议api","date":"2020-03-06T13:28:59.000Z","path":"wiki/net-protocol/2.应用层/dns/3.dns协议api/","text":"1234567891011121314151617181920212223242526272829package mainimport ( \"fmt\" \"github.com/brewlin/net-protocol/protocol/application/dns\" \"github.com/brewlin/net-protocol/protocol/header\")func main() &#123; d := dns.NewEndpoint(\"www.baidu.com\") fmt.Println(\"DNS lookuphost : www.baidu.com\") defer d.Close() ir,err := d.Resolve(); if err != nil &#123; fmt.Println(err) return &#125; for _,v := range *ir &#123; switch v.Type &#123; case header.A: fmt.Println(\"A(host name) :\",v.Address) case header.CNAME: fmt.Println(\"CNAME (alias name):\",v.Address) &#125; &#125; &#125; @NewEndpoint(domain)新建一个dns客户端，主要负责udp客户端初始化，以及一些主要工作 @Resolve()负责发送dns数据包请求，以及解析响应数据 @ir 响应结构体改结构是一个数组指针，复用数据12345678910//DNSResource ansower,authority,additionaltype DNSResource struct &#123; Name uint16 Type DNSResourceType Class uint16 TTL uint32 RDlen uint16 RData []byte Address string&#125; 在接收到的数据，包含多条记录，只有A类型是ip地址,所以需要过滤一下12345678for _,v := range *ir &#123; switch v.Type &#123; case header.A: fmt.Println(\"A(host name) :\",v.Address) case header.CNAME: fmt.Println(\"CNAME (alias name):\",v.Address) &#125;&#125; 执行demo","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"client","slug":"client","permalink":"http://wiki.brewlin.com/tags/client/"},{"name":"dns","slug":"dns","permalink":"http://wiki.brewlin.com/tags/dns/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"2.应用层","slug":"net-protocol/2-应用层","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/"},{"name":"dns","slug":"net-protocol/2-应用层/dns","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/dns/"}]},{"title":"dns协议简介","date":"2020-03-06T13:28:59.000Z","path":"wiki/net-protocol/2.应用层/dns/1.dns协议简介/","text":"@整体包结构 header+bodyDNS请求与响应的格式是一致的，其整体分为Header、Question、Answer、Authority、Additional5部分，如下图所示：1234567891011+-+-+-+-+-------+-+-------------+| Header | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Question | the question for the name server+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Answer | RRs answering the question+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Authority | RRs pointing toward an authority+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Additional | RRs holding additional information+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ @Header 包结构Header部分是一定有的，长度固定为12个字节；其余4部分可能有也可能没有，并且长度也不一定，这个在Header部分中有指明。Header的结构如下：12345678910111213140 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16+-+-+-+-+-------+-+-------------+-----------------------| ID |+------------------------------------------------------- |QR| OPCODE |AA|TC|RD|RA| RSV | RCODE |+------------------------------------------------------- | QUESTION COUNT |+------------------------------------------------------- | ANSWER COUNT |+------------------------------------------------------- | AUTHORITY SCOUNT |+------------------------------------------------------- | ADITION COUNT |+------------------------------------------------------- 下面说明一下各个字段的含义: ID：占16位。该值由发出DNS请求的程序生成，DNS服务器在响应时会使用该ID，这样便于请求程序区分不同的DNS响应。 QR：占1位。指示该消息是请求还是响应。0表示请求；1表示响应。 OPCODE：占4位。指示请求的类型，有请求发起者设定，响应消息中复用该值。0表示标准查询；1表示反转查询；2表示服务器状态查询。3~15目前保留，以备将来使用。 AA（Authoritative Answer，权威应答）：占1位。表示响应的服务器是否是权威DNS服务器。只在响应消息中有效。 TC（TrunCation，截断）：占1位。指示消息是否因为传输大小限制而被截断。 RD（Recursion Desired，期望递归）：占1位。该值在请求消息中被设置，响应消息复用该值。如果被设置，表示希望服务器递归查询。但服务器不一定支持递归查询。 RA（Recursion Available，递归可用性）：占1位。该值在响应消息中被设置或被清除，以表明服务器是否支持递归查询。 Z：占3位。保留备用。 RCODE（Response code）：占4位。该值在响应消息中被设置。取值及含义如下： 0：No error condition，没有错误条件； 1：Format error，请求格式有误，服务器无法解析请求； 2：Server failure，服务器出错。 3：Name Error，只在权威DNS服务器的响应中有意义，表示请求中的域名不存在。 4：Not Implemented，服务器不支持该请求类型。 5：Refused，服务器拒绝执行请求操作。 6~15：保留备用。 QUESTION COUNT：占16位（无符号）。指明Question部分的包含的实体数量。 ANSWER COUNT：占16位（无符号）。指明Answer部分的包含的RR（Resource Record）数量。 AUTHORITY COUNT：占16位（无符号）。指明Authority部分的包含的RR（Resource Record）数量。 ADDITIONAL COUNT：占16位（无符号）。指明Additional部分的包含的RR（Resource Record）数量。 @Question 包结构1234567890 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16+-+-+-+-+-------+-+-------------+-----------------------/ QUESTION NAME 字节数不固定 存储host name // /+------------------------------------------------------- | Question type |+------------------------------------------------------- | question class |+------------------------------------------------------- QNAME：字节数不定，以0x00作为结束符。表示查询的主机名。注意：众所周知，主机名被”.”号分割成了多段标签。在QNAME中，每段标签前面加一个数字，表示接下来标签的长度。比如：www.baidu.com 表示成QNAME时，会在”www”前面加上一个字节0x03，”baidu”前面加上一个字节0x04，”com”前面加上一个字节0x03,最后在加0x00表示结尾 QTYPE：占2个字节。表示RR类型，见以上RR介绍； QCLASS：占2个字节。表示RR分类，见以上RR介绍。 @ Answer、Authority、Additional 包结构三个包结构都是一致的，而且字节数都是动态的如下图:12345678910111213141516170 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16+-+-+-+-+-------+-+-------------+-----------------------/ Name // /+------------------------------------------------------- | type |+------------------------------------------------------- | class |+------------------------------------------------------- | TTl || |+------------------------------------------------------- | len |+-------------------------------------------------------/ data // /+------------------------------------------------------- NAME：长度不定，可能是真正的数据，也有可能是指针（其值表示的是真正的数据在整个数据中的字节索引数），还有可能是二者的混合（以指针结尾）。若是真正的数据，会以0x00结尾；若是指针，指针占2个字节，第一个字节的高2位为11。算法方式详见具体的go实现 TYPE：占2个字节。表示RR的类型，如A、CNAME、NS等，见以上RR介绍； CLASS：占2个字节。表示RR的分类，见以上RR介绍； TTL：占4个字节。表示RR生命周期，即RR缓存时长，单位是秒； RDLENGTH：占2个字节。指定RDATA字段的字节数； RDATA：即之前介绍的value，含义与TYPE有关，见以上RR介绍。","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"client","slug":"client","permalink":"http://wiki.brewlin.com/tags/client/"},{"name":"dns","slug":"dns","permalink":"http://wiki.brewlin.com/tags/dns/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"2.应用层","slug":"net-protocol/2-应用层","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/"},{"name":"dns","slug":"net-protocol/2-应用层/dns","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/dns/"}]},{"title":"dns协议实现","date":"2020-03-06T13:28:59.000Z","path":"wiki/net-protocol/2.应用层/dns/2.dns协议实现/","text":"@封装发送包体123456//protocol/appliction/dns/endpoint.go h := header.DNS(make([]byte,12)) h.Setheader(e.ID) h.SetCount(1,0,0,0) h.SetQuestion(e.Domain,1,1) 首先创建一个Dns的字节数组，默认给12字节大小，因为header头固定为12字节大小 @header头封装主要是初始化ID 和 一些flag标志位123456789101112h.SetHeader(e.ID)//Setheaderfunc (d DNS) Setheader(id uint16)&#123; d.setID(id) d.setFlag(0,0,0,0,1,0,0)&#125;//setID 将前两个字节 初始化idfunc (d DNS)setID(id uint16)&#123; //set id binary.BigEndian.PutUint16(d[ID:], id)&#125; 设置标志位,都给默认值123456789101112131415161718192021//SetFlag//QR 表示请求还是响应//OPCODE 1表示反转查询；2表示服务器状态查询。3~15目前保留，以备将来使用//AA 表示响应的服务器是否是权威DNS服务器。只在响应消息中有效。//TC 指示消息是否因为传输大小限制而被截断//RD 该值在请求消息中被设置，响应消息复用该值。如果被设置，表示希望服务器递归查询。但服务器不一定支持递归查询//RA 。该值在响应消息中被设置或被清除，以表明服务器是否支持递归查询。//Z 保留备用//RCODE: 该值在响应消息中被设置。取值及含义如下：//0：No error condition，没有错误条件；//1：Format error，请求格式有误，服务器无法解析请求；//2：Server failure，服务器出错。//3：Name Error，只在权威DNS服务器的响应中有意义，表示请求中的域名不存在。//4：Not Implemented，服务器不支持该请求类型。//5：Refused，服务器拒绝执行请求操作。//6~15：保留备用func (d DNS) setFlag(QR uint16, OPCODE uint16, AA uint16, TC uint16, RD uint16, RA uint16, RCODE uint16) &#123; //set flag op := QR&lt;&lt;15 + OPCODE&lt;&lt;11 + AA&lt;&lt;10 + TC&lt;&lt;9 + RD&lt;&lt;8 + RA&lt;&lt;7 + RCODE binary.BigEndian.PutUint16(d[OP:],op)&#125; 到这里包头header4字节就算封装好了 @Count 封装因为是查询包体，只需要设置query count即可，现在只支持单条查询，所以默认给11234567891011//SetCountfunc (d DNS) SetCount(qd,an,ns,qa uint16) &#123; //SetQdcount binary.BigEndian.PutUint16(d[QDCOUNT:], qd) //SetAncount binary.BigEndian.PutUint16(d[ANCOUNT:] ,an) //SetNscount binary.BigEndian.PutUint16(d[NSCOUNT:],ns) //SetQAcount binary.BigEndian.PutUint16(d[ARCOUNT:],qa)&#125; 这里每个标志位占2字节，总共8字节，加上上面的header4字节 总共12字节 @Question 封装这里主要是将需要查询的域名写入包体中，这里有个地方需要计算:123456789101112131415161718192021222324252627func (d *DNS)SetQuestion(domain string,qtype,qclass uint16)&#123; for _,b := range d.getDomain(domain) &#123; *d = append((*d),b) &#125; //d.setDomain(domain) q := DNSQuestion&#123; QuestionType: qtype, QuestionClass: qclass, &#125; var buffer bytes.Buffer binary.Write(&amp;buffer,binary.BigEndian,*d) binary.Write(&amp;buffer,binary.BigEndian,q) *d = buffer.Bytes()&#125;func (d *DNS)getDomain(domain string) []byte &#123; var ( buffer bytes.Buffer segments []string = strings.Split(domain, \".\") ) for _, seg := range segments &#123; binary.Write(&amp;buffer, binary.BigEndian, byte(len(seg))) binary.Write(&amp;buffer, binary.BigEndian, []byte(seg)) &#125; binary.Write(&amp;buffer, binary.BigEndian, byte(0x00)) return buffer.Bytes()&#125; 首先计算待查询的域名动态字节并返回 最后在封装DNSQuestion4字节追加到末尾 这里基本完成了所有的请求包的构建 @发送数据包dns是基于dns协议查询，直接将上面进行udp发送即可1234567891011//sendQuery udp query dnsfunc (e *Endpoint) sendQuery () ( *[]header.DNSResource ,error ) &#123; if err := e.c.Connect();err != nil &#123; return nil,err &#125; if err := e.c.Write(*e.req) ; err != nil &#123; return nil,err &#125; return e.parseResp()&#125; @解析响应包体主要就是接收udp响应数据，注意：==udp当前实现是 如果对端不可访问。在read时才会接收到icmp错误控制消息==123456789101112//parseResp//解析响应func (e *Endpoint) parseResp() (*[]header.DNSResource,error)&#123; rsp,err := e.c.Read() if err != nil &#123; return nil,err &#125; p := header.DNS(rsp) e.resp = &amp;p e.answer = p.GetAnswer(e.Domain) return e.parseAnswer()&#125; @获取Answer包体主要是计算三个count计数总和，判断总共有多少条响应记录 剩下的是挨着字节数遍历读取即可12345678910111213141516171819202122232425262728//GetAnswerfunc (d DNS) GetAnswer(domain string) *[]DNSResource &#123; //answer 起始地址 asLen := DOMAIN + len(d.getDomain(domain)) + 4 answer := []DNSResource&#123;&#125; for i := 0; i &lt; (int(d.GetANCount() + d.GetNSCount() + d.GetARCount())) ;i ++ &#123; rs := DNSResource&#123;&#125; //判断是不是指针 pointer地址 if checkP := d[asLen]; checkP &gt;&gt; 6 == 3 &#123; //pointer := (d[asLen] &amp; 0x3F &lt;&lt; 8) + d[asLen+1] rs.Name = binary.BigEndian.Uint16(d[asLen:asLen+2]) asLen += 2 rs.Type = DNSResourceType(binary.BigEndian.Uint16(d[asLen:asLen+2])) asLen += 2 rs.Class = binary.BigEndian.Uint16(d[asLen:asLen+2]) asLen += 2 rs.TTL = binary.BigEndian.Uint32(d[asLen:asLen+4]) asLen += 4 rs.RDlen = binary.BigEndian.Uint16(d[asLen:asLen+2]) asLen += 2 rs.RData = d[asLen:asLen+int(rs.RDlen)] asLen += int(rs.RDlen) answer = append(answer,rs) &#125; &#125; return &amp;answer&#125; @解析Answer address这里主要解析A类型 和Cname类型，基本满足场景了1234567891011func (e *Endpoint) parseAnswer()(*[]header.DNSResource,error)&#123; for i := 0; i &lt; len(*e.answer) ; i++ &#123; switch (*e.answer)[i].Type &#123; case header.A: (*e.answer)[i].Address = e.parseAName((*e.answer)[i].RData) case header.CNAME: (*e.answer)[i].Address = e.parseCName((*e.answer)[i].RData) &#125; &#125; return e.answer,nil&#125;","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"client","slug":"client","permalink":"http://wiki.brewlin.com/tags/client/"},{"name":"dns","slug":"dns","permalink":"http://wiki.brewlin.com/tags/dns/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"2.应用层","slug":"net-protocol/2-应用层","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/"},{"name":"dns","slug":"net-protocol/2-应用层/dns","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/dns/"}]},{"title":"udp-客户端","date":"2020-03-05T13:28:59.000Z","path":"wiki/net-protocol/7.客户端/udp-客户端/","text":"@客户端创建12345678910111213141516171819202122232425262728package mainimport ( \"fmt\" _ \"github.com/brewlin/net-protocol/pkg/logging\" \"github.com/brewlin/net-protocol/protocol/transport/udp/client\")func main() &#123; con := client.NewClient(\"10.0.2.15\", 9000) defer con.Close() if err := con.Connect(); err != nil &#123; fmt.Println(err) &#125; con.Write([]byte(\"send msg\")) res, err := con.Read() if err != nil &#123; fmt.Println(err) con.Close() return &#125; // var p [8]byte // res, _ := con.Readn(p[:1]) fmt.Println(string(res))&#125;&#125; 实现了基本的udp客户端连接读写等函数 依赖tap虚拟网卡，所以需要启动网卡依赖 依赖ARP,udp,IPV4等协议，所以默认注册了该协议 注意：默认本地地址为192.168.1.0/24 网段，如果目标ip为127.0.0.1 导致无法arp查询物理层地址,请填写局域网物理机器ip,或者外网ip @NewClient 创建客户端构造函数传入目的ip,端口等参数，默认返回一个*Client 指针1con := client.NewClient(\"10.0.2.15\", 8080) 注意:默认本地地址为192.168.1.0/24 网段，如果目标ip为127.0.0.1 导致无法arp查询物理层地址 @Connect ==notice==不进行真正的连接，只处理一些初始化工作 @Write 写入数据1con.Write([]byte(\"send msg\")) 直接向对端连接写入数据，错误返回err，udp协议直接通过ip数据包像对端发送数据，因为无连接状态，需要等待对方的icmp报文如果没有收到icmp报文表示发送成功，收到了icmp报文也需要在read()函数中才能标识出来 @Read 读取数据==在这里可以判断对端服务是否正常，因为这里会返回用户层icmp报文情况== 一次只读取一次数据，如果缓存没有读取完，则会返回 ErrWouldBlock错误，可以 在此监听该读方法12345678res, err := con.Read()if err != nil &#123; //这里的错误可能 就会是上面write 写入 对端数据后，对端返回的icmp control msg 表示一些异常情况，如对端端口不可达等 //如果需要阻塞 进行arp查询等一些操作 会自动进行，这里一般不会出现 fmt.Println(err) con.Close() return&#125; @Readn 读取n字节数据123// var p [8]byte// res, _ := con.Readn(p[:1])// fmt.Println(p) 可以根据传入参数填充对应的字节数数据，如果不够则会阻塞等待数据填充满为止 golang 的slice底层是一个指针，所以虽然传值，但是实际会复制指针，那么该slice实际值会在Readn（）函数里被改变填充完后返回","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"udp","slug":"udp","permalink":"http://wiki.brewlin.com/tags/udp/"},{"name":"client","slug":"client","permalink":"http://wiki.brewlin.com/tags/client/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"7.客户端","slug":"net-protocol/7-客户端","permalink":"http://wiki.brewlin.com/categories/net-protocol/7-客户端/"}]},{"title":"http_模块开发的步骤","date":"2020-02-10T13:28:59.000Z","path":"wiki/blog/nginx/http_模块开发的步骤（一）/","text":"http 流程的生命周期在开发模块前我们需要了解http流程的生命周期，然后确定我们需要扩展的功能在哪个阶段，最后才能在该阶段介入我们扩展的功能。 nginx 的http流程有11个阶段，每个阶段都可以认为是单独的模块在负责对应的职责，每个阶段的处理可能不止一次，可能会发生循环作用，这个完全由每个模块来决定对应的后续行为，如下为默认基础的11个生命周期: 1234567891011121314151617181920212223242526272829303132# NGX_HTTP_POST_READ_PHASE = 0在接收到完整的http头部后处理的http阶段# NGX_HTTP_SERVER_REWRITE_PHASE 处理头部阶段在还没有查询到uri匹配的location前，这时==rewrite重写url==也作为一个独立的http阶段# NGX_HTTP_FIND_CONFIG_PHASE 寻找匹配的location根据uri寻找匹配的location，这个阶段通常由ngx_http_core_module模块实现，不建议其他http模块重写定义这一阶段的行为# NGX_HTTP_REWRITE_PHASE在config_phase阶段之后重写url的意义与server_rewrite_phase阶段显然是不同的，因为这两者会导致查到不同的location快(location 是与uri进行匹配的)# NGX_HTTP_POST_REWRITE_PHASE 重新查找到对应的uir匹配的location模块这一阶段是由于rewrite重写url后会重新跳到ngx_http_find_config_phase阶段，找到与新的uri匹配的location，所以这一阶段是无法由第三方http模块处理的，而仅由ngx_http_core_module模块使用# NGX_HTTP_PREACCESS_PHASE 处理access接入前的阶段处理ngx_http_access_phase阶段前，http模块可以介入的处理阶段# NGX_HTTP_ACCESS_PHASE 判断是否允许访问nginx服务器这个阶段用于让http模块判断是否允许这个请求访问nginx服务器# NGX_HTTP_POST_ACCESS_PHASE 构造拒绝服务响应给客户端，进行收尾当ngx_http_access_phase阶段中http模块的handler处理方法返回不允许访问的错误码时，这个阶段将构造拒绝服务的用户响应。所以这个阶段实际上用于给ngx_http_access_phase阶段收尾# NGX_HTTP_TRY_FILES_PHASE 专门针对try_files配置进行静态文件处理这个阶段完全是为了try_files配置项而设立的，当http请求访问静态文件资源时,try_files配置项可以使这个请求顺序地访问多个静态文件资源，如果某一次访问失败，则继续访问try_files中指定的下一个静态资源，另外这个功能完全是在NGX_HTTP_TRY_FIELS_phase阶段中实现的# NGX_HTTP_CONTENT_PHASE 处理http内容的阶段用于处理http请求内容的阶段，这是大部分http模块最喜欢介入的阶段# NGX_HTTP_LOG_PHASE 最后日志记录收尾的阶段处理完请求后记录日志的阶段，例如NG_HTTP_LOG_MODULE 模块就在这个阶段中加入了一个handler处理方法，使得每个http请求处理完毕后惠济路access_log日志 一、扩展开发初始工作扩展开发前，我们需要了解nginx编译的流程和工作模式 1.配置检查在nginx编译的时候我们都会执行./configure命令，去检查平台编译环境后设置对应的宏命令支持对应的方法，并且./configure带有很多可选项参数，比如--add-module=path 就可以设定我们扩展目录的所在路径 简单讲下--add-module=path的工作原理：12345678910111213141516171819202122//这里是 ./configure --add-module=path 命令会调用的脚本检查//主要就是遍历 传入的path的路径，并去调用该路径下所有的config配置脚本//所以在这里，我们就需要在我们的扩展目录下有一个config配置文件if test -n \"$NGX_ADDONS\"; then echo configuring additional modules for ngx_addon_dir in $NGX_ADDONS do echo \"adding module in $ngx_addon_dir\" if test -f $ngx_addon_dir/config; then . $ngx_addon_dir/config echo \" + $ngx_addon_name was configured\" else echo \"$0: error: no $ngx_addon_dir/config was found\" exit 1 fi donefi 2.配置定义如下是扩展开发的编译配置path/to/modules/print/config的具体内容:123ngx_addon_name = ngx_http_print_moduleHTTP_MODULES=&quot;$HTTP_MODULES ngx_http_print_module&quot;NGX_ADDON_SRCS=&quot;$NGX_ADDON_SRCS $ngx_addon_dir/ngx_http_print_module.c&quot; 主要有两个需要注意的 ngx_addon_name 仅在configure期间使用，设置模块名称 HTTP_MODULES,NGX_ADDON_SRCS 这两个变量可以看出都是追加操作，用于将我们的扩展代码文件追加到待编译的列表中，而且HTTP_MODULES用于告诉nginx这是一个http扩展，且扩展的入口是ngx_http_pirnt_module这个我们在代码中定义的全局结构体变量(它会被加入到http生命周期中去，且包含了扩展的入口，后文会详细涉及到) 3.扩展目录这里我们以一个print模块为例，后面我们将介绍一个print模块的示例12345678910- nginx-src----------- auto----------- conf----------- man----------- html----------- src----------- modules------------------- print------------------------- ngx_http_print_module.c------------------------- config 这里样的目录方便我们后期扩展，上面讲到了./configure --add-module=path/modules 会去遍历该目录下所有的config，因此后期只需要在该目录下增加扩展目录即可 二、 http 基础模块的开发1.定义主模块入口该结构体在configure阶段的时候就会被写入到nginx全局的一个链表里，用于nginx启动时解析nginx.conf时遇到http配置项时会遍历调用所有相关的http模块 所以如下结构是作为一个扩展的启动入口1234567891011//ngx_http_print_module.cngx_module_t ngx_http_print_module = &#123; NGX_MODULE_V1, &amp;ngx_http_print_module_ctx, ngx_http_print_commands, NGX_HTTP_MODULE, NULL,NULL,NULL,NULL,NULL,NULL,NULL, NGX_MODULE_V1_PADDING&#125;; 2.定义配置存储解析入口commands是一个很重要的结构体，同时也被ngx_http_print_module引用，用于匹配nginx.conf中的配置项 例如本例中，如果在nginx.conf中中出现print test 1;配置项，则nginx会通过本模块ngx_http_print_module在找到commands,并且会调用set回调方法,也就是下面定义的ngx_http_print_register方法去将nginx.conf中的值保存到我们自定义的结构体中，方便我们在模块内使用123456789101112131415//ngx_http_print_module.c//当解析nginx.conf 时 没发现一个如下的print配置，就会调用该set回调方法(ngx_http_print)static ngx_command_t ngx_http_print_commands[] = &#123; &#123; ngx_string(\"print\"), // The command name NGX_HTTP_LOC_CONF | NGX_HTTP_SRV_CONF| NGX_CONF_TAKE2, ngx_http_print_register, // The command handler NGX_HTTP_LOC_CONF_OFFSET, 0, // offsetof(ngx_http_print_conf_t, str), NULL &#125;, ngx_null_command&#125;; 3.定义存储配置的结构体自定义的配置可以任何的设计，根据自己的场景来，本次例子只是简单的将nginx.conf中自定义的配置保存到如下的配置中去123456//ngx_http_print_module.ctypedef struct &#123; ngx_str_t str; ngx_int_t num;&#125;ngx_http_print_conf_t 4.实现ngx_http_print_register保存配置当nginx在启动阶段解析nginx.conf时，匹配到我们自定义的command则会调用对应的set回调函数，也就是ngx_http_print_register方法1234567891011121314151617181920212223242526//ngx_http_print_module.c//nginx.conf解析阶段，没发现一个匹配项就会调用当前函数注册相关handler 也就是请求处理的真正函数static char * ngx_http_print_register(ngx_conf_t *cf,ngx_command_t *cmd,void *conf)&#123; printf(\"sfdsfs\"); ngx_http_core_loc_conf_t *clcf; clcf = ngx_http_conf_get_module_loc_conf(cf,ngx_http_core_module); //当http请求命中该配置后，会指行如下函数 clcf-&gt;handler = ngx_http_print_handler; //解析conf中的 配置 ngx_http_print_conf_t *cur_conf = conf; //是一个ngx_array_t 数组 保存着ngx解析nginx.conf中的配置参数 ngx_str_t *value = cf-&gt;args-&gt;elts; cur_conf-&gt;str = value[1]; if(cf-&gt;args-&gt;nelts &gt; 2)&#123; cur_conf-&gt;num = ngx_atoi(value[2].data,value[2].len); if(cur_conf-&gt;num == NGX_ERROR)&#123; return \"invalid number\"; &#125; &#125; return NGX_CONF_OK;&#125; 其实到这里还有个重要的东西没有注意到，函数的void *conf指向的是我们自定义的结构体，但是内存需要我们自己申请，那么什么时候申请呢，这就需要用到ngx_http_module_t的特性了 该结构用于我们监听框架初始化事件，当框架启动扫描时会调用我们模块自定义的事件，并且会多次调用12345678910111213例如：http&#123; print a 1; server &#123; print b 2; location / &#123; print c 3; &#125; location /test &#123; print d 4; &#125; &#125;&#125; 如上就会调用4次我们自定义的函数,用于处理相关参数，也包括我们会提前预分配好内存保存 4.1 绑定请求事件上面可以看到我们设置了这一行代码1clcf-&gt;handler = ngx_http_print_handler; 其实这行就是重点，该函数是nginx运行时请求真正的处理函数 也就是当有配置命中了我们的模块，那么自定义的函数会被介入到http框架的11个生命周期中，进行http请求处理 详情请看下面 第三部分 模块请求入口函数 的实现 5.定义框架初始化事件上面可以看到ngx_http_print_module_ctx是一个自定义结构体，如下123456789101112131415//ngx_http_print_module.cstatic ngx_http_module_t ngx_http_print_module_ctx = &#123; NULL,//解析配置前 NULL,//解析配置后 NULL,//解析http配置 NULL,//合并http配置 NULL,//解析server配置 NULL,//合并server配置 create_loc_conf, //解析location配置 NULL//合并location配置&#125;; 其实一个ngx_http_module结构体，包含了8个回调函数，分别是ngin.conf被解析时会调用的函数，需要我们自己实现 其实上面我们只实现了一个create_loc_conf方法，因为在解析配置前其实是需要提前分配好需要解析的配置保存的内存，所以这就是我们准备要做的工作 6.预分配自定义结构体内存12345678910111213//ngx_http_print_module.cstatic void * create_loc_conf(ngx_conf_t *cf)&#123; ngx_http_print_conf_t *conf; conf = ngx_pcalloc(cf-&gt;pool,sizeof(ngx_http_print_conf_t)); if(conf == NULL)&#123; return NGX_CONF_ERROR; &#125; conf-&gt;str.data = NULL; conf-&gt;str.len = 0; conf-&gt;num = 0; return conf;&#125; 三、模块请求入口函数这个便是本文的重点，充当了http 请求处理的角色，当有请求命中了我们定义的配置项，则如下函数会介入到请求处理生命周期中去123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//ngx_http_print_module.c//作为http生命周期阶段的一部分 处理该请求static ngx_int_t ngx_http_print_handler(ngx_http_request_t *r)&#123; if(!(r-&gt;method &amp; NGX_HTTP_GET))&#123; return NGX_HTTP_NOT_ALLOWED; &#125; //不处理包体，直接通知不在接受客户端传递数据 //这行看似可有可无，其实是当我们不处理缓存区数据，万一客户端继续发送可能会导致超时 ngx_int_t rc = ngx_http_discard_request_body(r); if(rc != NGX_OK)&#123; return rc; &#125; //返回响应 ngx_str_t type = ngx_string(\"application/json\"); ngx_str_t response = ngx_string(\" the print module\"); //设置状态码 r-&gt;headers_out.status = NGX_HTTP_OK; //设置响应包长度 r-&gt;headers_out.content_length_n = response.len; //设置content-type r-&gt;headers_out.content_type = type; //发送http头部 rc = ngx_http_send_header(r); if(rc == NGX_ERROR || rc &gt; NGX_OK || r-&gt;header_only)&#123; return rc; &#125; //构造ngx_buf_t 结构体准备发送包体 ngx_buf_t *b; b = ngx_create_temp_buf(r-&gt;pool,response.len) if(b == NULL)&#123; return NGX_HTTP_INTERNAL_SERVER_ERROR; &#125; ngx_memcpy(b-&gt;pos,response.data,response.len); b-&gt;last = b-&gt;post + response.len; //表明这是最后一块缓冲区 b-&gt;last_buf = 1; ngx_chain_t out; out.buf = b; out.next = NULL; //发送包体 return ngx_http_output_filter(r,&amp;out);&#125; 1.响应普通文本这个就是普通的字符串数据响应给客户端方式,本文的案例也是用的这种，返回一个普通字符数据给客户端1234567891011121314//构造ngx_buf_t 结构体准备发送包体ngx_buf_t *b;b = ngx_create_temp_buf(r-&gt;pool,response.len)if(b == NULL)&#123; return NGX_HTTP_INTERNAL_SERVER_ERROR;&#125;ngx_memcpy(b-&gt;pos,response.data,response.len);b-&gt;last = b-&gt;post + response.len;//表明这是最后一块缓冲区b-&gt;last_buf = 1;ngx_chain_t out;out.buf = b;out.next = NULL; 同时也可以将本地文件内容读取后返回给客户端，下面7.2的方法就可以做到 2.响应本地磁盘文件分别定义了发送文件响应的方法 设置文件回收的事件方法，防止内存泄漏或者文件占用123456789101112131415161718192021222324252627u_char* filename = (u_char*)\"/tmp/print.html\"; //告诉nginx 实际响应的内容从文件中获取 b-&gt;in_file = 1; b-&gt;file = ngx_pcalloc(r-&gt;pool,sizeof(ngx_file_t)); b-&gt;file-&gt;fd = ngx_open_file(filename,NGX_FILE_RDONLY|NGX_FILE_NONBLOCK,NGX_FILE_OPEN,0); b-&gt;file-&gt;log = r-&gt;connection-&gt;log; b-&gt;file-&gt;name.data = filename; b-&gt;file-&gt;name.len = sizeof(filename) -1; if(b-&gt;file-&gt;fd &lt;= 0 )&#123; return NGX_HTTP_NOT_FOUND; &#125; if(ngx_file_info(filename,&amp;b-&gt;file-&gt;info) == NGX_FILE_ERROR)&#123; return NGX_HTTP_INTERNAL_SERVER_ERROR; &#125; r-&gt;headers_out.content_length_n = b-&gt;file-&gt;info.st_size; b-&gt;file_pos = 0; b-&gt;file_last = b-&gt;file-&gt;info.st_size; ngx_pool_cleanup_t* cl = ngx_pool_cleanup_add(r-&gt;pool,sizeof(ngx_pool_cleanup_file_t)); if(cl == NULL)&#123; return NGX_ERROR; &#125; cl-&gt;handler = ngx_pool_cleanup_file; ngx_pool_cleanup_file_t *clnf = cl-&gt;data; clnf-&gt;fd = b-&gt;file-&gt;fd; clnf-&gt;name = b-&gt;file-&gt;name.data; clnf-&gt;log = r-&gt;pool-&gt;log; 四、code &amp; 总结总的来说，每个部分nginx都提供了非常多的功能和api，本文只是简单的实现了一个从配置定义、配置触发自定义函数、以及介入http请求，响应http等例子介绍了一个nginx扩展的开发 编译123./configure --add-moudle=/path/to/printmakemake install nginx.conf123456789http&#123; server&#123; listen 8081; location / &#123; print test 2; &#125; &#125;&#125; config123ngx_addon_name = ngx_http_print_moduleHTTP_MODULES=&quot;$HTTP_MODULES ngx_http_print_module&quot;NGX_ADDON_SRCS=&quot;$NGX_ADDON_SRCS $ngx_addon_dir/ngx_http_print_module.c&quot; code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208#include \"nginx.h\"#include \"ngx_config.h\"#include \"ngx_core.h\"#include \"ngx_http.h\"static char * ngx_http_print_register(ngx_conf_t *cf,ngx_command_t *cmd,void *conf);static ngx_int_t ngx_http_print_handler(ngx_http_request_t *r);static void * create_loc_conf(ngx_conf_t *cf);static void * create_serv_conf(ngx_conf_t *cf);typedef struct &#123; ngx_str_t str; ngx_int_t num;&#125;ngx_http_print_conf_t;//当解析nginx.conf 时 没发现一个如下的print配置，就会调用该set回调方法(ngx_http_print)static ngx_command_t ngx_http_print_commands[] = &#123; &#123; ngx_string(\"print\"), // The command name NGX_HTTP_LOC_CONF | NGX_HTTP_SRV_CONF| NGX_CONF_TAKE2, ngx_http_print_register, // The command handler NGX_HTTP_LOC_CONF_OFFSET, 0, // offsetof(ngx_http_print_conf_t, str), NULL &#125;, ngx_null_command&#125;;//nginx.conf解析阶段，没发现一个匹配项就会调用当前函数注册相关handler 也就是请求处理的真正函数static char * ngx_http_print_register(ngx_conf_t *cf,ngx_command_t *cmd,void *conf)&#123; printf(\"sfdsfs\"); ngx_http_core_loc_conf_t *clcf; clcf = ngx_http_conf_get_module_loc_conf(cf,ngx_http_core_module); //当http请求命中该配置后，会指行如下函数 clcf-&gt;handler = ngx_http_print_handler; //解析conf中的 配置 ngx_http_print_conf_t *cur_conf = conf; //是一个ngx_array_t 数组 保存着ngx解析nginx.conf中的配置参数 ngx_str_t *value = cf-&gt;args-&gt;elts; cur_conf-&gt;str = value[1]; if(cf-&gt;args-&gt;nelts &gt; 2)&#123; cur_conf-&gt;num = ngx_atoi(value[2].data,value[2].len); if(cur_conf-&gt;num == NGX_ERROR)&#123; return \"invalid number\"; &#125; &#125; return NGX_CONF_OK;&#125;// 在nginx启动，也就是框架初始化时会调用如下的自定义模块的回调函数//如果没有什么需要做的，就不需要实现相关函数static ngx_http_module_t ngx_http_print_module_ctx = &#123; NULL, NULL, NULL, NULL, NULL, NULL, create_loc_conf, NULL&#125;;ngx_module_t ngx_http_print_module = &#123; NGX_MODULE_V1, &amp;ngx_http_print_module_ctx, ngx_http_print_commands, NGX_HTTP_MODULE, NULL,NULL,NULL,NULL,NULL,NULL,NULL, NGX_MODULE_V1_PADDING&#125;;static void * create_loc_conf(ngx_conf_t *cf)&#123; ngx_http_print_conf_t *conf; conf = ngx_pcalloc(cf-&gt;pool,sizeof(ngx_http_print_conf_t)); if(conf == NULL)&#123; return NGX_CONF_ERROR; &#125; conf-&gt;str.data = NULL; conf-&gt;str.len = 0; conf-&gt;num = 0; return conf;&#125;static void * create_serv_conf(ngx_conf_t *cf)&#123; ngx_http_print_conf_t *conf; conf = ngx_pcalloc(cf-&gt;pool,sizeof(ngx_http_print_conf_t)); if(conf == NULL)&#123; return NGX_CONF_ERROR; &#125; conf-&gt;str.data = NULL; conf-&gt;str.len = 0; conf-&gt;num = 0; return conf;&#125;static ngx_int_t response_file(ngx_http_request_t *r)&#123; ngx_str_t type = ngx_string(\"application/json\"); u_char* filename = (u_char*)\"/tmp/print.html\"; ngx_buf_t *b = ngx_palloc(r-&gt;pool,sizeof(ngx_buf_t)); //设置状态码 r-&gt;headers_out.status = NGX_HTTP_OK; //设置content-type r-&gt;headers_out.content_type = type; //告诉nginx 实际响应的内容从文件中获取 b-&gt;in_file = 1; b-&gt;file = ngx_pcalloc(r-&gt;pool,sizeof(ngx_file_t)); b-&gt;file-&gt;fd = ngx_open_file(filename,NGX_FILE_RDONLY|NGX_FILE_NONBLOCK,NGX_FILE_OPEN,0); b-&gt;file-&gt;log = r-&gt;connection-&gt;log; b-&gt;file-&gt;name.data = filename; b-&gt;file-&gt;name.len = sizeof(filename) -1; if(b-&gt;file-&gt;fd &lt;= 0 )&#123; return NGX_HTTP_NOT_FOUND; &#125; if(ngx_file_info(filename,&amp;b-&gt;file-&gt;info) == NGX_FILE_ERROR)&#123; return NGX_HTTP_INTERNAL_SERVER_ERROR; &#125; r-&gt;headers_out.content_length_n = b-&gt;file-&gt;info.st_size; b-&gt;file_pos = 0; b-&gt;file_last = b-&gt;file-&gt;info.st_size; //发送http头部 ngx_int_t rc = ngx_http_send_header(r); if(rc == NGX_ERROR || rc &gt; NGX_OK || r-&gt;header_only)&#123; return rc; &#125; ngx_pool_cleanup_t* cl = ngx_pool_cleanup_add(r-&gt;pool,sizeof(ngx_pool_cleanup_file_t)); if(cl == NULL)&#123; return NGX_ERROR; &#125; cl-&gt;handler = ngx_pool_cleanup_file; ngx_pool_cleanup_file_t *clnf = cl-&gt;data; clnf-&gt;fd = b-&gt;file-&gt;fd; clnf-&gt;name = b-&gt;file-&gt;name.data; clnf-&gt;log = r-&gt;pool-&gt;log; ngx_http_print_conf_t *cf = (ngx_http_print_conf_t*)r-&gt;loc_conf[0]; ngx_chain_t out; out.buf = b; out.next = NULL; //发送包体 return ngx_http_output_filter(r,&amp;out);&#125;static ngx_int_t response_str(ngx_http_request_t *r)&#123; ngx_str_t type = ngx_string(\"application/json\"); ngx_str_t response = ngx_string(\" the print module\"); //设置状态码 r-&gt;headers_out.status = NGX_HTTP_OK; //设置content-type r-&gt;headers_out.content_type = type; //设置状态码 r-&gt;headers_out.status = NGX_HTTP_OK; //设置响应包长度 r-&gt;headers_out.content_length_n = response.len; //设置content-type r-&gt;headers_out.content_type = type; //构造ngx_buf_t 结构体准备发送包体 //发送http头部 ngx_int_t rc = ngx_http_send_header(r); if(rc == NGX_ERROR || rc &gt; NGX_OK || r-&gt;header_only)&#123; return rc; &#125; ngx_buf_t *b = ngx_create_temp_buf(r-&gt;pool,response.len); if(b == NULL)&#123; return NGX_HTTP_INTERNAL_SERVER_ERROR; &#125; ngx_memcpy(b-&gt;pos,response.data,response.len); b-&gt;last = b-&gt;pos + response.len; //表明这是最后一块缓冲区 b-&gt;last_buf = 1; ngx_chain_t out; out.buf = b; out.next = NULL; //发送包体 return ngx_http_output_filter(r,&amp;out);&#125;//作为http生命周期阶段的一部分 处理该请求static ngx_int_t ngx_http_print_handler(ngx_http_request_t *r)&#123; if(!(r-&gt;method &amp; NGX_HTTP_GET))&#123; return NGX_HTTP_NOT_ALLOWED; &#125; //不处理包体，直接通知不在接受客户端传递数据 //这行看似可有可无，其实是当我们不处理缓存区数据，万一客户端继续发送可能会导致超时 ngx_int_t rc = ngx_http_discard_request_body(r); if(rc != NGX_OK)&#123; return rc; &#125; return response_str(r); // return response_file(r);&#125;","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"nginx","slug":"nginx","permalink":"http://wiki.brewlin.com/tags/nginx/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"nginx","slug":"blog/nginx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/"}]},{"title":"core","date":"2020-02-05T13:28:59.000Z","path":"wiki/im-cloud/3.相关组件/core/core/","text":"@annotation注解扫描 @config配置读取 @container容器单利初始化 @eventswoole事件封装 @context携程上下文 @pool连接池封装 main框架启动、swoole启动","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"core","slug":"core","permalink":"http://wiki.brewlin.com/tags/core/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"3.相关组件","slug":"im-cloud/3-相关组件","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/"},{"name":"core","slug":"im-cloud/3-相关组件/core","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/core/"}]},{"title":"discovery","date":"2020-01-31T13:28:59.000Z","path":"wiki/im-cloud/3.相关组件/discovery/discovery/","text":"@env 配置文件discovery.php1234567891011121314151617181920212223242526272829303132&lt;?phpreturn [ 'consul' =&gt; [ 'address' =&gt; env(\"DISCOVERY_ADDRESS\",\"127.0.0.1\"), 'port' =&gt; env(\"DISCOVERY_PORT\",\"8500\"), 'register' =&gt; [ 'ID' =&gt; '', //只注册了grpc 服务，其他都是私有的 //tcp 和websocket 通过nginx负载均衡即可 'Name' =&gt; 'grpc-im-cloud-node', 'Tags' =&gt; [], 'enableTagOverride'=&gt; false, 'Address' =&gt; env(\"APP_HOST\",\"127.0.0.1\"), 'Port' =&gt; (int)env(\"GRPC_PORT\",9500), 'Check' =&gt; [ 'id' =&gt; '', 'name' =&gt; '', 'http' =&gt; \"http://127.0.0.1:\".env('DISCOVERY_CHECK_PORT',9500).\"/health\", 'interval' =&gt; \"10s\", 'timeout' =&gt; \"10s\", ], ], 'discovery' =&gt; [ 'name' =&gt; 'grpc-im-logic-node', 'dc' =&gt; 'dc1', 'near' =&gt; '', 'tag' =&gt;'', 'passing' =&gt; true ] ],]; @register 注册服务12345$registerStatus = provider()-&gt;select()-&gt;registerService();if(!$registerStatus)&#123; CLog::error(\"consul register false sleep 1 sec to reregiseter\"); Coroutine::sleep(1);&#125; @deregister 注销节点123//注销节点$discovery = config(\"discovery\");provider()-&gt;select()-&gt;deregisterService($discovery['consul'][\"register\"]['Name']);","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"discovery","slug":"discovery","permalink":"http://wiki.brewlin.com/tags/discovery/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"3.相关组件","slug":"im-cloud/3-相关组件","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/"},{"name":"discovery","slug":"im-cloud/3-相关组件/discovery","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/discovery/"}]},{"title":"db","date":"2020-01-29T13:28:59.000Z","path":"wiki/im-cloud/3.相关组件/database/db/","text":"@设置结果集为 array1234567891011121314151617181920use Core\\Event\\EventDispatcherInterface;use Core\\Event\\EventEnum;use Core\\Event\\Mapping\\Event;use Hyperf\\Database\\Events\\StatementPrepared;use PDO;/** * @Event(alias=EventEnum::DbFetchMode) */class FetchModeEvent implements EventDispatcherInterface&#123; /** * @param $event */ public function dispatch(...$param)&#123; $event = $param[0]; if ($event instanceof StatementPrepared) &#123; $event-&gt;statement-&gt;setFetchMode(PDO::FETCH_ASSOC); &#125; &#125;&#125; @db 操作https://hyperf.wiki/#/zh-cn/db/querybuilder","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"database","slug":"database","permalink":"http://wiki.brewlin.com/tags/database/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"3.相关组件","slug":"im-cloud/3-相关组件","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/"},{"name":"database","slug":"im-cloud/3-相关组件/database","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/database/"}]},{"title":"queue","date":"2020-01-28T13:28:59.000Z","path":"wiki/im-cloud/3.相关组件/queue/queue/","text":"@producer 生产数据12345use App\\Lib\\Producer;/** @var Producer $producers */$producers = \\bean(Producer::class);//发送到队列里producer()-&gt;produce($producers-&gt;producer($pushmsg)); @consumer 消费队列数据1234567891011121314151617181920212223242526272829303132333435use ImQueue\\Amqp\\Message\\ConsumerMessage;use ImQueue\\Amqp\\Result;/** * Class Consumer * @package App\\Lib */class Consumer extends ConsumerMessage&#123; public function __construct() &#123; $this-&gt;setExchange(env(\"EXCHANGE\")); $this-&gt;setQueue(env(\"QUEUE\")); $this-&gt;setRoutingKey(env(\"ROUTE_KEY\")); &#125; /** * 主流程消费数据入口 * @param PushMsg $data * @return string */ public function consume($data): string &#123; return Result::ACK; &#125; /** * 重新排队 * @return bool */ public function isRequeue(): bool &#123; return true; &#125;&#125;","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"queue","slug":"queue","permalink":"http://wiki.brewlin.com/tags/queue/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"3.相关组件","slug":"im-cloud/3-相关组件","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/"},{"name":"queue","slug":"im-cloud/3-相关组件/queue","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/queue/"}]},{"title":"grpc","date":"2020-01-27T13:28:59.000Z","path":"wiki/im-cloud/3.相关组件/grpc/grpc/","text":"@build123&gt; cd pkg/grpc/bin&gt; sh gen.sh....... @method grpc 调用组件封装有连接池机制，复用多个连接12345678910use Grpc\\Client\\GrpcLogicClient;use Im\\Cloud\\Operation;use Im\\Logic\\HeartbeatReq;$heartBeatReq = new HeartbeatReq();$host = env(\"APP_HOST\",\"127.0.0.1\").\":\".env(\"GRPC_PORT\",9500);$heartBeatReq-&gt;setServer($host);$heartBeatReq-&gt;setKey($key);$heartBeatReq-&gt;setMid($mid);GrpcLogicClient::Heartbeat($grpcServer,$heartBeatReq);","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"grpc","slug":"grpc","permalink":"http://wiki.brewlin.com/tags/grpc/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"3.相关组件","slug":"im-cloud/3-相关组件","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/"},{"name":"grpc","slug":"im-cloud/3-相关组件/grpc","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/grpc/"}]},{"title":"memory","date":"2020-01-26T13:28:59.000Z","path":"wiki/im-cloud/3.相关组件/memeory/memeory/","text":"@construct使用bean注解自动注入到container中，在swoole启动前就需要申请好内存并初始化，所以需要使用bean注解1234567891011121314151617181920212223use Core\\Container\\Mapping\\Bean;use Memory\\Table;use Memory\\Table\\Type;use Memory\\Table\\MemoryTable;/** * @Bean() */class CloudClient&#123; public static $table = null; /** * CloudClient constructor. */ public function __construct() &#123; $memorySize = (int)env(\"MEMORY_TABLE\",1000); $column = [ \"Address\" =&gt; [Type::String,20], \"Port\" =&gt; [Type::String,10], ]; self::$table = Table::create($memorySize,$column); &#125;&#125; @Table：：create 创建共享内存 size 内存大小 column 数据结构","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"memory","slug":"memory","permalink":"http://wiki.brewlin.com/tags/memory/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"3.相关组件","slug":"im-cloud/3-相关组件","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/"},{"name":"memeory","slug":"im-cloud/3-相关组件/memeory","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/memeory/"}]},{"title":"process","date":"2020-01-25T13:28:59.000Z","path":"wiki/im-cloud/3.相关组件/process/process/","text":"@construct1234567891011121314151617181920212223use Process\\Contract\\AbstractProcess;class DemoProcess extends AbstractProcess&#123; public function __construct() &#123; $this-&gt;name = \"process_name\"; &#125; public function check(): bool &#123; return true; &#125; /** * 自定义子进程 执行入口 * @param Process $process */ public function run(Process $process) &#123; &#125;&#125; @register 注册自定义进程1ProcessManager::register(\"demo-process\",new \bDemoProcess()); @start 启动主动伴随swoole进程模型启动，交由swoole mangager进程管理","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"process","slug":"process","permalink":"http://wiki.brewlin.com/tags/process/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"3.相关组件","slug":"im-cloud/3-相关组件","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/"},{"name":"process","slug":"im-cloud/3-相关组件/process","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/process/"}]},{"title":"redis","date":"2020-01-23T13:28:59.000Z","path":"wiki/im-cloud/3.相关组件/redis/redis/","text":"@class1Redis::hSet(\"hkey\",$key,$server); @api123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118* @method static int append(string $key, string $value)* @method static array blPop(array $keys, int $timeout)* @method static array brPop(array $keys, int $timeout)* @method static string brpoplpush(string $srcKey, string $dstKey, int $timeout)* @method static string decr(string $key)* @method static int decrBy(string $key, int $value)* @method static mixed eval(string $script, array $args = [], int $numKeys = 0)* @method static mixed evalSha(string $scriptSha, array $args = [], int $numKeys = 0)* @method static bool exists(string $key)* @method static int geoAdd(string $key, float $longitude, float $latitude, string $member)* @method static float geoDist(string $key, string $member1, string $member2, string $unit = 'm')* @method static array geohash(string $key, string $member1, string $member2 = null, string $memberN = null)* @method static array geopos(string $key, string $member1, string $member2 = null, string $memberN = null)* @method static mixed|bool get(string $key)* @method static int getBit(string $key, int $offset)* @method static int getOption(string $name)* @method static string getRange(string $key, int $start, int $end)* @method static string getSet(string $key, string $value)* @method static string hDel(string $key, string $hashKey1, string $hashKey2 = null, string $hashKeyN = null)* @method static bool hExists(string $key, string $hashKey)* @method static array hGet(string $key, array $hashKey)* @method static array hGetAll(string $key)* @method static int hIncrBy(string $key, string $hashKey, int $value)* @method static float hIncrByFloat(string $key, string $field, float $increment)* @method static array hKeys(string $key)* @method static int hLen(string $key)* @method static int hSet(string $key, string $hashKey, string $value)* @method static bool hSetNx(string $key, string $hashKey, string $value)* @method static array hVals(string $key)* @method static array hScan(string $key, int &amp;$iterator, string $pattern = null, int $count = 0)* @method static int incr(string $key)* @method static int incrBy(string $key, int $value)* @method static float incrByFloat(string $key, float $increment)* @method static array info(string $option = null)* @method static string|bool lGet(string $key, int $index)* @method static int lInsert(string $key, int $position, string $pivot, string $value)* @method static string|bool lPop(string $key)* @method static int|bool lPush(string $key, string $value1, string $value2 = null, string $valueN = null)* @method static int|bool lPushx(string $key, string $value)* @method static bool lSet(string $key, int $index, string $value)* @method static int msetnx(array $array)* @method static bool persist(string $key)* @method static bool pExpire(string $key, int $ttl)* @method static bool pExpireAt(string $key, int $timestamp)* @method static bool psetex(string $key, int $ttl, $value)* @method static int pttl(string $key)* @method static string rPop(string $key)* @method static int|bool rPush(string $key, string $value1, string $value2 = null, string $valueN = null)* @method static int|bool rPushx(string $key, string $value)* @method static mixed rawCommand(string|array $nodeParams, string $command, mixed $arguments)* @method static bool renameNx(string $srcKey, string $dstKey)* @method static bool restore(string $key, int $ttl, string $value)* @method static string rpoplpush(string $srcKey, string $dstKey)* @method static int sAdd(string $key, string $value1, string $value2 = null, string $valueN = null)* @method static int sAddArray(string $key, array $valueArray)* @method static array sDiff(string $key1, string $key2, string $keyN = null)* @method static int sDiffStore(string $dstKey, string $key1, string $key2, string $keyN = null)* @method static array sInter(string $key1, string $key2, string $keyN = null)* @method static int|bool sInterStore(string $dstKey, string $key1, string $key2, string $keyN = null)* @method static array sMembers(string $key)* @method static bool sMove(string $srcKey, string $dstKey, string $member)* @method static string|bool sPop(string $key)* @method static string|array|bool sRandMember(string $key, int $count = null)* @method static array sUnion(string $key1, string $key2, string $keyN = null)* @method static int sUnionStore(string $dstKey, string $key1, string $key2, string $keyN = null)* @method static array|bool scan(int &amp;$iterator, string $pattern = null, int $count = 0)* @method static mixed script(string|array $nodeParams, string $command, string $script)* @method static bool set(string $key, $value, int $timeout = null)* @method static int setBit(string $key, int $offset, int $value)* @method static string setRange(string $key, int $offset, $value)* @method static int setex(string $key, int $ttl, $value)* @method static bool setnx(string $key, $value)* @method static array sort(string $key, array $option = null)* @method static array sScan(string $key, int &amp;$iterator, string $pattern = null, int $count = 0)* @method static int strlen(string $key)* @method static int ttl(string $key)* @method static int type(string $key)* @method static void unwatch()* @method static void watch(string $key)* @method static int zCard(string $key)* @method static int zCount(string $key, int $start, int $end)* @method static float zIncrBy(string $key, float $value, string $member)* @method static int zLexCount(string $key, int $min, int $max)* @method static array zRange(string $key, int $start, int $end, bool $withscores = null)* @method static array zRangeByLex(string $key, int $min, int $max, int $offset = null, int $limit = null)* @method static array zRangeByScore(string $key, string $start, string $end, array $options = [])* @method static int zRank(string $key, string $member)* @method static array zRemRangeByLex(string $key, int $min, int $max)* @method static array zRevRange(string $key, int $start, int $end, bool $withscore = null)* @method static array zRevRangeByLex(string $key, int $min, int $max, int $offset = null, int $limit = null)* @method static array zRevRangeByScore(string $key, int $start, int $end, array $options = [])* @method static int zRevRank(string $key, string $member)* @method static float zScore(string $key, float $member)* @method static array zScan(string $key, int &amp;$iterator, string $pattern = null, int $count = 0)* @method static int del(string $key1, string $key2 = null, string $key3 = null)* @method static bool expire(string $key, int $ttl)* @method static array keys(string $pattern)* @method static int lLen(string $key)* @method static string|bool lIndex(string $key, int $index)* @method static array lRange(string $key, int $start, int $end)* @method static int|bool lRem(string $key, string $value, int $count)* @method static array|bool lTrim(string $key, int $start, int $stop)* @method static bool rename(string $srcKey, string $dstKey)* @method static int sCard(string $key)* @method static bool sIsMember(string $key, string $value)* @method static int sRem(string $key, string $member1, string $member2 = null, string $memberN = null)* @method static int zRem(string $key, string $member1, string $member2 = null, string $memberN = null)* @method static int zRemRangeByRank(string $key, int $start, int $end)* @method static int zRemRangeByScore(string $key, float|string $start, float|string $end)* @method static int zInterStore(string $Output, array $ZSetKeys, array $Weights = null, string $aggregateFunction = 'SUM')* @method static int zUnionStore(string $Output, array $ZSetKeys, array $Weights = null, string $aggregateFunction = 'SUM')* @method static array hMGet(string $key, array $keys)* @method static bool hMSet(string $key, array $keyValues)* @method static int zAdd(string $key, array $scoreValues)* @method static array mget(array $keys)* @method static bool mset(array $keyValues, int $ttl = 0)* @method static array pipeline(callable $callback)* @method static array transaction(callable $callback)","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"redis","slug":"redis","permalink":"http://wiki.brewlin.com/tags/redis/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"3.相关组件","slug":"im-cloud/3-相关组件","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/"},{"name":"redis","slug":"im-cloud/3-相关组件/redis","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/redis/"}]},{"title":"log","date":"2020-01-22T13:28:59.000Z","path":"wiki/im-cloud/3.相关组件/log/log/","text":"@Log 输出到日志文件 &amp;&amp; Clog 输出到终端@emergency level12Log::emergency(message,param);CLog::emergency(message,param); @info level12Log::info(message,param);CLog::info(message,param); @error level12Log::error(message,param);CLog::error(message,param); @debug level12Log::debug(message,param);CLog::debug(message,param); @alert level12Log::alert(message,param);CLog::alert(message,param); @warning level12Log::warning(message,param);CLog::warning(message,param);","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"log","slug":"log","permalink":"http://wiki.brewlin.com/tags/log/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"3.相关组件","slug":"im-cloud/3-相关组件","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/"},{"name":"log","slug":"im-cloud/3-相关组件/log","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/log/"}]},{"title":"task","date":"2020-01-21T13:28:59.000Z","path":"wiki/im-cloud/3.相关组件/task/task/","text":"@composer12345&#123; \"require\":&#123; \"brewlin/im-task\" &#125;&#125; @class12class Task &#123;&#125; @diliver 发送异步任务通过deliver方法可以直接在task进程中执行对应object的方法到达异步执行任务1234use namespace example;/** @var Task $task */\\bean(Task::class)-&gt;deliver(example::class,\"method\",[arg1,arg2,arg3.....]);","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"coroutine","slug":"coroutine","permalink":"http://wiki.brewlin.com/tags/coroutine/"},{"name":"task","slug":"task","permalink":"http://wiki.brewlin.com/tags/task/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"3.相关组件","slug":"im-cloud/3-相关组件","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/"},{"name":"task","slug":"im-cloud/3-相关组件/task","permalink":"http://wiki.brewlin.com/categories/im-cloud/3-相关组件/task/"}]},{"title":"read","date":"2020-01-13T13:28:59.000Z","path":"wiki/read/read/","text":"read…","tags":[{"name":"read","slug":"read","permalink":"http://wiki.brewlin.com/tags/read/"}],"categories":[{"name":"read","slug":"read","permalink":"http://wiki.brewlin.com/categories/read/"}]},{"title":"runtime","date":"2020-01-13T13:28:59.000Z","path":"wiki/c-ext/hook/runtime/","text":"Lib\\runtime::enableCorutine 启动hook机制123456&lt;?phpLib\\\bRuntime::enableCoroutine();cgo(function()&#123; sleep(1); // == Cco::sleep(1);&#125;);","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"hook","slug":"hook","permalink":"http://wiki.brewlin.com/tags/hook/"},{"name":"runtime","slug":"runtime","permalink":"http://wiki.brewlin.com/tags/runtime/"}],"categories":[{"name":"c-ext","slug":"c-ext","permalink":"http://wiki.brewlin.com/categories/c-ext/"},{"name":"hook","slug":"c-ext/hook","permalink":"http://wiki.brewlin.com/categories/c-ext/hook/"}]},{"title":"sleep","date":"2020-01-13T13:28:59.000Z","path":"wiki/c-ext/hook/sleep/","text":"在扩展内替换原生php内置sleep函数，使原有基于sleep的代码自动进行替换为协程\bCco::sleep()调用 @协程sleep123cgo(function()&#123; Cco::sleep(1);//协程切换&#125;); @原生sleep123cgo(function()&#123; sleep(1);//进程阻塞&#125;); @hook sleep1234Lib\\Runtime::enableCoroutine();cgo(function()&#123; sleep(1);//协程切换&#125;);","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"hook","slug":"hook","permalink":"http://wiki.brewlin.com/tags/hook/"},{"name":"sleep","slug":"sleep","permalink":"http://wiki.brewlin.com/tags/sleep/"}],"categories":[{"name":"c-ext","slug":"c-ext","permalink":"http://wiki.brewlin.com/categories/c-ext/"},{"name":"hook","slug":"c-ext/hook","permalink":"http://wiki.brewlin.com/categories/c-ext/hook/"}]},{"title":"协程socket","date":"2020-01-12T13:28:59.000Z","path":"wiki/c-ext/coroutine/协程socket/","text":"创建协程版socket，封装所有协程api，所有阻塞操作都会触发协程切换 @Lib\\Coroutine\\Socket12345678910111213141516171819202122232425262728&lt;?phplib_event_init();cgo(function ()&#123; $socket = new Lib\\Coroutine\\Socket(AF_INET, SOCK_STREAM, IPPROTO_IP); if($socket-&gt;fd &lt; 0)&#123; var_dump(\"err\");return; &#125; $socket-&gt;bind(\"127.0.0.1\", 9999); $socket-&gt;listen(); while (true) &#123; $conn = $socket-&gt;accept(); cgo(function () use($conn) &#123; $data = $conn-&gt;recv(); $responseStr = \"HTTP/1.1 200 OK\\r\\n Content-Type: text/html\\r\\n Connection: close\\r\\n Content-Length: 11\\r\\n\\r\\n hello world\\r\\n\"; $conn-&gt;send($responseStr); $conn-&gt;close(); &#125;); &#125;&#125;);lib_event_wait(); @Constant1AF_INET, SOCK_STREAM, IPPROTO_IP @__construct 初始化@bind 绑定端口@listen 启动监听@accept 接收新连接@recv 读取缓冲区数据@send 向对端连接写入数据@close 关闭连接","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"coroutine","slug":"coroutine","permalink":"http://wiki.brewlin.com/tags/coroutine/"},{"name":"epoll","slug":"epoll","permalink":"http://wiki.brewlin.com/tags/epoll/"},{"name":"socket","slug":"socket","permalink":"http://wiki.brewlin.com/tags/socket/"},{"name":"tcp","slug":"tcp","permalink":"http://wiki.brewlin.com/tags/tcp/"}],"categories":[{"name":"c-ext","slug":"c-ext","permalink":"http://wiki.brewlin.com/categories/c-ext/"},{"name":"coroutine","slug":"c-ext/coroutine","permalink":"http://wiki.brewlin.com/categories/c-ext/coroutine/"}]},{"title":"event","date":"2020-01-12T13:28:59.000Z","path":"wiki/c-ext/event/event/","text":"123456lib_event_init();dosthing...lib_event_wait(); @lib_event_init() 初始化全局变量和申请内存空间123LibG;LibG.pollLibG.poll.epollfd; @lib_event_wait() 轮训获取可读可写事件timer、socket、server、sleep等模块依赖于event，所以需要显示调用event123while(LibG.running)&#123; epoll_wait(....)&#125;","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"coroutine","slug":"coroutine","permalink":"http://wiki.brewlin.com/tags/coroutine/"},{"name":"epoll","slug":"epoll","permalink":"http://wiki.brewlin.com/tags/epoll/"}],"categories":[{"name":"c-ext","slug":"c-ext","permalink":"http://wiki.brewlin.com/categories/c-ext/"},{"name":"event","slug":"c-ext/event","permalink":"http://wiki.brewlin.com/categories/c-ext/event/"}]},{"title":"php_引用计数与gc","date":"2020-01-10T13:28:59.000Z","path":"wiki/blog/php/php_引用计数与GC/","text":"进行php扩展开发的时候会遇到一些问题，就是php用户态空间将变量传递到扩展层面c层调用的时候，会出现一些问题，下面的例子是一个timer定时器的例子。用户空间会传递一个回调函数给timer扩展接口，那么实际回调函数被调用的地方是c层。但是该回调函数变量本身是由用户空间申请并交由php内核gc管理的，如果扩展函数内不做任何操作，那么当切换到用户空间时php内核会判断该变量需要回收，然后扩展函数就会空指针异常等 当扩展函数内该php变量生命周期使用结束后，任然需要考虑垃圾回收的问题，并不是在扩展函数内简单free(data)就可以的，需要调用php内核引用计数接口等进行变量的回收以及gc等，最后交由php内核gc管理。当然扩展函数内由c自行申请管理的内存可以自己释放 扩展函数定义示例 12345678910111213PHP_METHOD(timer_obj,tick)&#123; php_lib_timer_callback *fci = (php_lib_timer_callback *)malloc(sizeof(php_lib_timer_callback)); //强制传入两个参数 ZEND_PARSE_PARAMETERS_START(2, 2) Z_PARAM_LONG(fci-&gt;seconds) Z_PARAM_FUNC(fci-&gt;fci,fci-&gt;fcc) ZEND_PARSE_PARAMETERS_END_EX(RETURN_FALSE); long id = create_time_event(fci-&gt;seconds,tick,fci,del); zend_fci_cache_persist(&amp;fci-&gt;fcc); RETURN_LONG(id);&#125; 扩展函数内执行php用户态回调函数示例 12345678910int tick(long long id,void *data)&#123; php_lib_timer_callback *fci = (php_lib_timer_callback *)data; zval result; fci-&gt;fci.retval = &amp;result; if(zend_call_function(&amp;fci-&gt;fci,&amp;fci-&gt;fcc) != SUCCESS)&#123; return NOMORE; &#125; return fci-&gt;seconds;&#125; timer 中对回调函数变量进行引用计数+1上面会发现timer::tick()函数在返回给用户空间时会做一个操作zend_fci_cache_persist(&amp;fci-&gt;fcc);，正是该调用对传入的回调函数进行饮用计数管理，告诉php内核该回调函数在c层会继续使用不用回收。代码如下1234567891011static void zend_fci_cache_persist(zend_fcall_info_cache *fci_cache)&#123; if (fci_cache-&gt;object) &#123; GC_ADDREF(fci_cache-&gt;object); &#125; if (fci_cache-&gt;function_handler-&gt;op_array.fn_flags &amp; ZEND_ACC_CLOSURE) &#123; GC_ADDREF(ZEND_CLOSURE_OBJECT(fci_cache-&gt;function_handler)); &#125;&#125; 其中GC_ADDREF（）函数很明显就是内核GC相关的api。fci_cache-&gt;function_handler 则为用户传递的回调函数真正的变量地址 如上前奏后就可以在c扩展中放心的对用户传递的变量进行操作了 timer 中结束后变量的Gc回收上面有看到php_lib_timer_callback变量实际是自己定义的结构体，包括内存也是有开发者自己分配的，可以放心的free。但是该结构体中指向的fci.fcc 则实际是php用户空间申请的变量，不能直接free,如果直接free，会引发php gc泄漏，如下警告所示:123&gt; php timer.php/php/src/Zend/zend_closures.c(459) : Freeing 0x00007fc084e6d480 (304 bytes), script=/timer.php=== Total 1 memory leaks detected === 所以依然需要根据php内核GC的管理方式来处理用户空间的变量，也就是模拟用户空间那样对变量的管理：12345678910111213141516171819202122static void zend_fci_cache_discard(zend_fcall_info_cache *fci_cache)&#123; if (fci_cache-&gt;object) &#123; OBJ_RELEASE(fci_cache-&gt;object); &#125; if (fci_cache-&gt;function_handler-&gt;op_array.fn_flags &amp; ZEND_ACC_CLOSURE) &#123; OBJ_RELEASE(ZEND_CLOSURE_OBJECT(fci_cache-&gt;function_handler)); &#125;&#125;static void zend_fci_params_discard(zend_fcall_info *fci)&#123; if (fci-&gt;param_count &gt; 0) &#123; uint32_t i; for (i = 0; i &lt; fci-&gt;param_count; i++) &#123; zval_ptr_dtor(&amp;fci-&gt;params[i]); &#125; efree(fci-&gt;params); &#125;&#125; 在不需要使用的时候，也需要对回调函数本身进行减引用，以及回调函数内的用户态的参数进行减引用以及变量的回收。只有做完上面这些基本的管理才能开发一个安全的扩展函数 总结总之用户空间申请的变量传递给扩展内函数使用，如果在返回给用户空间后依然会继续使用就要zval_copy或者引用计数+1,因为在返回给用户空间的时候本身用户空间gc会判断该变量是否有继续引用，否则就refcount -= 1，用户空间回收该变量，但是扩展函数内依然在访问该已经被销毁的变量。就会导致错误 只有将这些变量的引用与回收做好了才能开发出安全可靠的扩展函数","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"gc","slug":"gc","permalink":"http://wiki.brewlin.com/tags/gc/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"refrerence","slug":"refrerence","permalink":"http://wiki.brewlin.com/tags/refrerence/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"php","slug":"blog/php","permalink":"http://wiki.brewlin.com/categories/blog/php/"}]},{"title":"tap","date":"2020-01-10T13:28:59.000Z","path":"wiki/net-protocol/6.物理层/tap/","text":"1.创建一个tap模式的虚拟网卡tap01sudo ip tuntap add mode tap tap0 2.开启该网卡1sudo ip link set tap0 up 3.设置该网卡的ip及掩码 |添加路由123sudo ip route add 192.168.1.0/24 dev tap0//增加ip地址sudo ip addr add 192.168.1.1/24 dev tap0 4.添加网关1sudo ip route add default via 192.168.1.2 dev tap0 @删除网卡1.删除虚拟网卡1sudo ip tuntap del mode tap tap0","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"eth","slug":"eth","permalink":"http://wiki.brewlin.com/tags/eth/"},{"name":"tap","slug":"tap","permalink":"http://wiki.brewlin.com/tags/tap/"},{"name":"tool","slug":"tool","permalink":"http://wiki.brewlin.com/tags/tool/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"6.物理层","slug":"net-protocol/6-物理层","permalink":"http://wiki.brewlin.com/categories/net-protocol/6-物理层/"}]},{"title":"定时器","date":"2020-01-10T13:28:59.000Z","path":"wiki/c-ext/timer/定时器/","text":"demo123456789101112131415161718192021&lt;?phplib_event_init();//定时器 毫秒单位 循环触发$timerid = Lib\\Timer::tick(1000,function()&#123; echo \"定时器循环\";&#125;);//定时器 毫秒单位 触发单次Lib\\Timer::after(1000,function()use($timerid)&#123; echo \"只执行一次\"; //定时器 毫秒单位 触发单次 Lib\\Timer::after(2000,function()use($timerid)&#123; //定时器删除 Lib\\Timer::del($timerid); &#125;)&#125;);lib_event_wait(); @tick 无限触发定时任务long Lib\\Timer::tick(long long seconds,$callback);单位为毫秒 底层基于epoll_wait 阻塞触发定时 @after 单次任务执行long Lib\\Timer::after(long long seconds,$callback); @del 删除定时任务long Lib\\Timer::del(long timerid);","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"epoll","slug":"epoll","permalink":"http://wiki.brewlin.com/tags/epoll/"},{"name":"timer","slug":"timer","permalink":"http://wiki.brewlin.com/tags/timer/"}],"categories":[{"name":"c-ext","slug":"c-ext","permalink":"http://wiki.brewlin.com/categories/c-ext/"},{"name":"timer","slug":"c-ext/timer","permalink":"http://wiki.brewlin.com/categories/c-ext/timer/"}]},{"title":"协程","date":"2020-01-05T13:28:59.000Z","path":"wiki/c-ext/coroutine/协程/","text":"将协程任务保存到扩展事件中进行调度 @cgo12345678910//初始化全局对象 epoll等内存空间初始化lib_event_init();//协程运行cgo(function()&#123; echo \"go\"&#125;);//epoll event 轮循 检查事件lib_event_wait();","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"coroutine","slug":"coroutine","permalink":"http://wiki.brewlin.com/tags/coroutine/"},{"name":"epoll","slug":"epoll","permalink":"http://wiki.brewlin.com/tags/epoll/"}],"categories":[{"name":"c-ext","slug":"c-ext","permalink":"http://wiki.brewlin.com/categories/c-ext/"},{"name":"coroutine","slug":"c-ext/coroutine","permalink":"http://wiki.brewlin.com/categories/c-ext/coroutine/"}]},{"title":"协程tcp服务","date":"2020-01-05T13:28:59.000Z","path":"wiki/c-ext/coroutine/协程tcp服务/","text":"创建协程版server，封装所有协程api，所有阻塞操作都会触发协程切换 @Lib\\Coroutine\\Server123456789101112131415161718192021222324//初始化全局对象 epoll等内存空间初始化lib_event_init();//协程运行cgo(function ()&#123; $server = new Lib\\Coroutine\\Server(\"127.0.0.1\", 9991); $server-&gt;set_handler(function (Lib\\Coroutine\\Socket $conn) use($server) &#123; $data = $conn-&gt;recv(); $responseStr = \"HTTP/1.1 200 OK\\r\\n Content-Type: text/html\\r\\n Connection: close\\r\\n Content-Length: 11\\r\\n\\r\\n hello world\\r\\n\"; $conn-&gt;send($responseStr); $conn-&gt;close(); // Sco::sleep(0.01); &#125;); $server-&gt;start();&#125;);//epoll event 轮循 检查事件lib_event_wait(); @__construct 初始化@set_handler($callback) 回调触发事件start() 启动监听","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"coroutine","slug":"coroutine","permalink":"http://wiki.brewlin.com/tags/coroutine/"},{"name":"epoll","slug":"epoll","permalink":"http://wiki.brewlin.com/tags/epoll/"},{"name":"socket","slug":"socket","permalink":"http://wiki.brewlin.com/tags/socket/"},{"name":"tcp","slug":"tcp","permalink":"http://wiki.brewlin.com/tags/tcp/"}],"categories":[{"name":"c-ext","slug":"c-ext","permalink":"http://wiki.brewlin.com/categories/c-ext/"},{"name":"coroutine","slug":"c-ext/coroutine","permalink":"http://wiki.brewlin.com/categories/c-ext/coroutine/"}]},{"title":"dns-客户端","date":"2020-01-05T13:28:59.000Z","path":"wiki/net-protocol/7.客户端/dns-客户端/","text":"@客户端创建12345678910111213141516171819202122232425package mainimport ( \"fmt\" \"github.com/brewlin/net-protocol/protocol/application/dns\" \"github.com/brewlin/net-protocol/protocol/header\")func main() &#123; d := dns.NewEndpoint(\"www.baidu.com\") fmt.Println(\"DNS lookuphost : www.baidu.com\") defer d.Close() ir,err := d.Resolve(); if err != nil &#123; fmt.Println(err) return &#125; for _,v := range *ir &#123; switch v.Type &#123; case header.A: fmt.Println(\"A(host name) :\",v.Address) case header.CNAME: fmt.Println(\"CNAME (alias name):\",v.Address) &#125; &#125;&#125; 实现了基本的dns客户端,resolve()发起udp包查询域名解析 依赖tap虚拟网卡，所以需要启动网卡依赖 依赖ARP,UDP,IPV4等协议，所以默认注册了该协议 注意：外网请求需要使用tool/up 方式启动网卡配置数据包转发 @NewClient 创建客户端构造函数传入domain,默认返回一个指针123d := dns.NewEndpoint(\"www.baidu.com\")fmt.Println(\"DNS lookuphost : www.baidu.com\")defer d.Close() @解析域名发送udp包解析域名12345ir,err := d.Resolve();if err != nil &#123; fmt.Println(err) return&#125; @解析响应数据12345678for _,v := range *ir &#123; switch v.Type &#123; case header.A: fmt.Println(\"A(host name) :\",v.Address) case header.CNAME: fmt.Println(\"CNAME (alias name):\",v.Address) &#125;&#125;) demoDNS ClIENT123456&gt; cd net-protocol/tool;&gt; go build up.go&gt; sudo ./up&gt; cd net-protocol/cmd/application/dns&gt; sudo go run dns_client.go DNS SERVER启动 udp server,另起窗口发送dns查询并指定dnsserver12345678&gt; cd net-protocol/tool;&gt; go build up.go&gt; sudo ./up&gt; cd net-protocol/cmd/application/dns&gt; sudo go run dns_server.go//另起ssh窗口 发送dns查询并指定自定义的dns server 192.168.1.1:53&gt; nslookup www.baidu.com 192.168.1.1 @服务端创建123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116package mainimport ( \"fmt\" \"github.com/brewlin/net-protocol/config\" \"github.com/brewlin/net-protocol/internal/endpoint\" \"github.com/brewlin/net-protocol/pkg/buffer\" _ \"github.com/brewlin/net-protocol/pkg/logging\" _ \"github.com/brewlin/net-protocol/pkg/logging\" \"github.com/brewlin/net-protocol/pkg/waiter\" \"github.com/brewlin/net-protocol/protocol/header\" \"github.com/brewlin/net-protocol/protocol/network/ipv4\" \"github.com/brewlin/net-protocol/protocol/transport/udp\" \"github.com/brewlin/net-protocol/protocol/transport/udp/client\" \"github.com/brewlin/net-protocol/stack\" \"log\" \"strconv\" \"strings\" tcpip \"github.com/brewlin/net-protocol/protocol\")//当前demo作为一个dns代理，接受dns请求并转发后，解析响应做一些操作func main() &#123; s := endpoint.NewEndpoint() udploop(s)&#125;func udploop(s *stack.Stack) &#123; var wq waiter.Queue //新建一个UDP端 ep, err := s.NewEndpoint(udp.ProtocolNumber, ipv4.ProtocolNumber, &amp;wq) if err != nil &#123; log.Fatal(err) &#125; //绑定本地端口 53是dns默认端口 if err := ep.Bind(tcpip.FullAddress&#123;1, config.LocalAddres, 53&#125;, nil); err != nil &#123; log.Fatal(\"@main : bind failed :\", err) &#125; defer ep.Close() //创建队列 通知 channel waitEntry, notifych := waiter.NewChannelEntry(nil) wq.EventRegister(&amp;waitEntry, waiter.EventIn) defer wq.EventUnregister(&amp;waitEntry) var saddr tcpip.FullAddress for &#123; v, _, err := ep.Read(&amp;saddr) if err != nil &#123; if err == tcpip.ErrWouldBlock &#123; &lt;-notifych continue &#125; fmt.Println(err) return &#125; //接收到代理请求 h := header.DNS(v) fmt.Println(\"@main :接收到代理域名:\", string(h[header.DOMAIN:header.DOMAIN+h.GetDomainLen()-1])) go handle_proxy(v,ep,saddr) &#125;&#125;//转发代理请求，并解析响应数据func handle_proxy(v buffer.View,ep tcpip.Endpoint,saddr tcpip.FullAddress)&#123; cli := client.NewClient(\"8.8.8.8\",53) cli.Connect() cli.Write(v) defer cli.Close() rsp,err := cli.Read() if err != nil &#123; fmt.Println(err) return &#125; //返回给客户端 _, _, err = ep.Write(tcpip.SlicePayload(rsp), tcpip.WriteOptions&#123;To: &amp;saddr&#125;) if err != nil &#123; fmt.Println(err) &#125; p := header.DNS(rsp) answer := p.GetAnswer() for i := 0; i &lt; len(*answer) ; i++ &#123; switch (*answer)[i].Type &#123; case header.A: fmt.Println(\"dns 目标IP（A):\",parseAName((*answer)[i].RData)) case header.CNAME: fmt.Println(\"dns 目标IP（alias):\",parseCName((*answer)[i].RData)) &#125; &#125;&#125;func parseAName(rd []byte) string &#123; res := []string&#123;&#125; for _,v := range rd &#123; res = append(res,strconv.Itoa(int(v))) &#125; return strings.Join(res,\".\")&#125;func parseCName(rd []byte) (res string) &#123; for&#123; l := int(rd[0]) if l &gt;= len(rd)&#123; res += \".com\" return &#125; rd = rd[1:] res += string(rd[0:l]) rd = rd[l:] if len(rd) == 0 &#123; return &#125; &#125;&#125;","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"udp","slug":"udp","permalink":"http://wiki.brewlin.com/tags/udp/"},{"name":"client","slug":"client","permalink":"http://wiki.brewlin.com/tags/client/"},{"name":"dns","slug":"dns","permalink":"http://wiki.brewlin.com/tags/dns/"},{"name":"request","slug":"request","permalink":"http://wiki.brewlin.com/tags/request/"},{"name":"response","slug":"response","permalink":"http://wiki.brewlin.com/tags/response/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"7.客户端","slug":"net-protocol/7-客户端","permalink":"http://wiki.brewlin.com/categories/net-protocol/7-客户端/"}]},{"title":"进程管理","date":"2019-12-20T13:28:59.000Z","path":"wiki/c-ext/process/进程管理/","text":"@Lib/Process该扩展初始化传入回调函数并创建子进程执行，子进程间可以通过channel通讯1234567891011121314&lt;?php$process = new Lib\\Process(function(Lib\\Process $process)&#123; while(true)&#123; $data = $process-&gt;read(); echo \"child process :&gt; get parent msg: $data \\n\\n\"; &#125;&#125;);$process-&gt;start();for($i = 0;$i &lt; 10 ; $i ++ )&#123; echo \"parent process :&gt; send child msg: $i\\n\"; $process-&gt;write($i); sleep(1);&#125; @construct()初始化构造函数时必须传入回调函数，在子进程创建时会调用 @start()执行创建子进程操作 @$process-&gt;write($data)向子进程或者父进程写入数据 @$process-&gt;read()向子进程或父进程读取数据 @$process-&gt;getpid()获取当前进程id @$process-&gt;getppid()获取父进程id","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"syscall","slug":"syscall","permalink":"http://wiki.brewlin.com/tags/syscall/"},{"name":"process","slug":"process","permalink":"http://wiki.brewlin.com/tags/process/"},{"name":"channel","slug":"channel","permalink":"http://wiki.brewlin.com/tags/channel/"}],"categories":[{"name":"c-ext","slug":"c-ext","permalink":"http://wiki.brewlin.com/categories/c-ext/"},{"name":"process","slug":"c-ext/process","permalink":"http://wiki.brewlin.com/categories/c-ext/process/"}]},{"title":"共享内存","date":"2019-12-20T13:28:59.000Z","path":"wiki/c-ext/memory/共享内存/","text":"@Lib/SharMem该扩展申请一块共享内存地址，提供php调用，用于多进程间共享数据123456//初始化传入内存大小 单位字节 bytes$obj = new Lib\\SharMem(8)//模拟int 自增测试$obj-&gt;get();$obj-&gt;incr(); 多进程共享内存测试,采用lib_fork 调用 原生fork操作1234567891011121314151617$Obj = new Lib\\SharMem(8);if(lib_fork() == 0)&#123;//子进程 while(true) &#123; sleep(1); $obj-&gt;incr(); var_dump(\"this is clild process \\n\"); &#125;&#125;//父进程while(true)&#123; sleep(1); var_dump(\"this is parent process get value:\".$obj-&gt;get());&#125;","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"},{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"share","slug":"share","permalink":"http://wiki.brewlin.com/tags/share/"},{"name":"memory","slug":"memory","permalink":"http://wiki.brewlin.com/tags/memory/"},{"name":"syscall","slug":"syscall","permalink":"http://wiki.brewlin.com/tags/syscall/"}],"categories":[{"name":"c-ext","slug":"c-ext","permalink":"http://wiki.brewlin.com/categories/c-ext/"},{"name":"memory","slug":"c-ext/memory","permalink":"http://wiki.brewlin.com/categories/c-ext/memory/"}]},{"title":"shamem.h","date":"2019-12-11T13:28:59.000Z","path":"wiki/blog/nginx/sharmem/shamem.h/","text":"123456789101112131415161718192021222324#ifndef _SHMEM_H_INCLUDED_#define _SHMEM_H_INCLUDED_#define OK 0#define ERROR -1#include &lt;sys/mman.h&gt;#include \"server.h\"typedef server serv;typedef struct &#123; u_char *addr; size_t size; u_char name; serv *server;&#125; shm_t;int shm_alloc(shm_t *shm);void shm_free(shm_t *shm);#endif /* _SHMEM_H_INCLUDED_ */","tags":[{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"share","slug":"share","permalink":"http://wiki.brewlin.com/tags/share/"},{"name":"memory","slug":"memory","permalink":"http://wiki.brewlin.com/tags/memory/"},{"name":"syscall","slug":"syscall","permalink":"http://wiki.brewlin.com/tags/syscall/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"nginx","slug":"blog/nginx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/"},{"name":"sharmem","slug":"blog/nginx/sharmem","permalink":"http://wiki.brewlin.com/categories/blog/nginx/sharmem/"}]},{"title":"shamem.c","date":"2019-12-11T13:28:59.000Z","path":"wiki/blog/nginx/sharmem/shamem.c/","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#include \"shmem.h\"#include \"log.h\"//采用 mmap 方式申请共享内存#if (HAVE_MAP_ANON)int shm_alloc(shm_t *shm)&#123; shm-&gt;addr = (u_char *) mmap(NULL, shm-&gt;size, PROT_READ|PROT_WRITE, MAP_ANON|MAP_SHARED, -1, 0); if (shm-&gt;addr == MAP_FAILED) &#123; log_error(shm-&gt;server, \"mmap(MAP_ANON|MAP_SHARED, %d) failed\", shm-&gt;size); return ERROR; &#125; log_info(shm-&gt;server, \"mmap(MAP_ANON|MAP_SHARED, %d) success\", shm-&gt;size); return OK;&#125;void shm_free(shm_t *shm)&#123; if (munmap((void *) shm-&gt;addr, shm-&gt;size) == -1) &#123; log_error(shm-&gt;server, \"munmap(%s, %d) failed\", shm-&gt;addr, shm-&gt;size); &#125; log_info(shm-&gt;server, \"munmap( %d) success\", shm-&gt;size);&#125;//采用 文件映射方式申请共享内存#elif (HAVE_MAP_DEVZERO)int_t shm_alloc(shm_t *shm)&#123; fd_t fd; fd = open(\"/dev/zero\", O_RDWR); if (fd == -1) &#123; log_error(shm-&gt;server, \"open(\\\"/dev/zero\\\") failed\"); return ERROR; &#125; shm-&gt;addr = (u_char *) mmap(NULL, shm-&gt;size, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0); if (shm-&gt;addr == MAP_FAILED) &#123; log_error(shm-&gt;server, \"mmap(/dev/zero, MAP_SHARED, %d) failed\", shm-&gt;size); &#125; if (close(fd) == -1) &#123; log_error(shm-&gt;server,\"close(\\\"/dev/zero\\\") failed\"); &#125; return (shm-&gt;addr == MAP_FAILED) ? ERROR : OK;&#125;void shm_free(shm_t *shm)&#123; if (munmap((void *) shm-&gt;addr, shm-&gt;size) == -1) &#123; log_error(shm-&gt;server,\"munmap(%s, %d) failed\", shm-&gt;addr, shm-&gt;size); &#125;&#125;//采用 shmget 系统调用方式申请共享内存#elif (HAVE_SYSVSHM)#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;int_t shm_alloc(shm_t *shm)&#123; int id; id = shmget(IPC_PRIVATE, shm-&gt;size, (SHM_R|SHM_W|IPC_CREAT)); if (id == -1) &#123; log_error(shm-&gt;server,\"shmget(%d) failed\", shm-&gt;size); return ERROR; &#125; log_info(shm-&gt;server,, \"shmget id: %d\", id); shm-&gt;addr = shmat(id, NULL, 0); if (shm-&gt;addr == (void *) -1) &#123; log_error(shm-&gt;server, \"shmat() failed\"); &#125; if (shmctl(id, IPC_RMID, NULL) == -1) &#123; log_error(shm-&gt;server,\"shmctl(IPC_RMID) failed\"); &#125; return (shm-&gt;addr == (void *) -1) ? ERROR : OK;&#125;void shm_free(shm_t *shm)&#123; if (shmdt(shm-&gt;addr) == -1) &#123; log_error(shm-&gt;server,\"shmdt(%s) failed\", shm-&gt;addr); &#125;&#125;#endif","tags":[{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"share","slug":"share","permalink":"http://wiki.brewlin.com/tags/share/"},{"name":"memory","slug":"memory","permalink":"http://wiki.brewlin.com/tags/memory/"},{"name":"syscall","slug":"syscall","permalink":"http://wiki.brewlin.com/tags/syscall/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"nginx","slug":"blog/nginx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/"},{"name":"sharmem","slug":"blog/nginx/sharmem","permalink":"http://wiki.brewlin.com/categories/blog/nginx/sharmem/"}]},{"title":"共享内存的实现","date":"2019-12-11T13:28:59.000Z","path":"wiki/blog/nginx/sharmem/共享内存/","text":"共享内存本质为通过系统调用申请一块内存，由系统调用，该内存可以跨进程间使用，有是那种共享内存的申请方式 采用mmap 方式申请共享内存 采用文件映射方式申请共享内存 采用 shmget 系统调用方式申请共享内存 上面三种方式在本次实验中分别对应三种宏 HAVE_MAP_ANON HAVE_MAP_DEVZERO HAVE_SYSVSHM申请内存123456789 //申请共享内存shm_t shm;size_t size;size = 8 * 16;//分配128字节内存shm.size = size;shm.name = (u_char *)\"nginx_shared_zone\";shm.server = serv;shm_alloc(&amp;shm);int* count = (int *)(shm.addr + 8); 上面的例子中，shm_alloc方法分配了 128字节内存 申请成功后，shm.addr 即是共享的内存首地址，需要自己分配管理 int *count 截取了前8个字节分配使用。转换为8字节int指针使用，演示案例通过申请一块共享内存地址，分配一个int指针，模拟http多进程处理请求并统计请求总数.如下为请求样例123456789101112131415161718192021222324252627282930313233343536373839404142434445static void eventloop(server *serv) &#123; pid_t pid; struct sigaction sa; connection *con; //申请共享内存 shm_t shm; size_t size; size = 8 * 16;//分配128字节内存 shm.size = size; shm.name = (u_char *)&quot;nginx_shared_zone&quot;; shm.server = serv; shm_alloc(&amp;shm); int* count = (int *)(shm.addr + 8); sa.sa_handler = sigchld_handler; sigemptyset(&amp;sa.sa_mask); sa.sa_flags = SA_RESTART; if (sigaction(SIGCHLD, &amp;sa, NULL) == -1) &#123; perror(&quot;sigaction&quot;); exit(1); &#125; while (1) &#123; if ((con = connection_accept(serv)) == NULL) &#123; continue; &#125; if ((pid = fork()) == 0) &#123; // 子进程中处理HTTP请求 close(serv-&gt;sockfd); *count += 1; printf(&quot;request count is %d\\n&quot;,*count); connection_handler(serv, con); connection_close(con); exit(0); &#125; printf(&quot;child process: %d\\n&quot;, pid); connection_close(con); &#125; shm_free(&amp;shm);&#125; 统计结果：ab -c 10 -n 10 http://127.0.0.1:8080/123456request count is 7request count is 8socket: 5socket: 5request count is 9request count is 10","tags":[{"name":"linux","slug":"linux","permalink":"http://wiki.brewlin.com/tags/linux/"},{"name":"share","slug":"share","permalink":"http://wiki.brewlin.com/tags/share/"},{"name":"memory","slug":"memory","permalink":"http://wiki.brewlin.com/tags/memory/"},{"name":"syscall","slug":"syscall","permalink":"http://wiki.brewlin.com/tags/syscall/"}],"categories":[{"name":"blog","slug":"blog","permalink":"http://wiki.brewlin.com/categories/blog/"},{"name":"nginx","slug":"blog/nginx","permalink":"http://wiki.brewlin.com/categories/blog/nginx/"},{"name":"sharmem","slug":"blog/nginx/sharmem","permalink":"http://wiki.brewlin.com/categories/blog/nginx/sharmem/"}]},{"title":"websocket-客户端","date":"2019-12-06T13:28:59.000Z","path":"wiki/net-protocol/7.客户端/websocekt-客户端/","text":"@客户端创建12345678910111213141516171819202122232425262728package mainimport ( \"fmt\" \"github.com/brewlin/net-protocol/pkg/logging\" \"github.com/brewlin/net-protocol/protocol/application/websocket\")func init() &#123; logging.Setup()&#125;func main()&#123; wscli ,_ := websocket.NewClient(\"http://10.0.2.15:8080/ws\") defer wscli.Close() //升级 http协议为websocket if err := wscli.Upgrade();err != nil &#123; panic(err) &#125; //循环接受数据 for &#123; if err := wscli.Push(\"test\");err != nil &#123; break &#125; data,_ := wscli.Recv() fmt.Println(data) &#125;&#125; 实现了基本的websocket客户端,升级http协议，发送数据，接受数据等方法 依赖tap虚拟网卡，所以需要启动网卡依赖 依赖ARP,TCP,IPV4等协议，所以默认注册了该协议 注意： 1.外网请求需要使用tool/up 方式启动网卡配置数据包转发 2.未实现dns查询域名，必须使用ip测试 @NewClient 创建客户端构造函数传入url,默认返回一个*Client 指针1cli,err := http.NewClient(\"http://10.0.2.15:8080/ws\") @Close 关闭连接结束后，需要手动关闭连接，底层进行tcp四次挥手结束两端状态1defer wscli.Close() @Upgrade 升级协议该方法主要执行两个步骤 发起http情况，告诉服务端为websocket协议 对服务端返回的http响应，进行校验，校验通过后保持tcp连接，升级为websocket协议12//升级 http协议为websocketif err := wscli.Upgrade();err != nil &#123; @push 推送数据1wscli.Push(\"test\") 添加数据 @Recv 获取数据读取该websocket流 接受的数据，本质为tcp流数据，经过websocket协议解包后处理1data,_ := wscli.Recv()","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"tcp","slug":"tcp","permalink":"http://wiki.brewlin.com/tags/tcp/"},{"name":"http","slug":"http","permalink":"http://wiki.brewlin.com/tags/http/"},{"name":"client","slug":"client","permalink":"http://wiki.brewlin.com/tags/client/"},{"name":"request","slug":"request","permalink":"http://wiki.brewlin.com/tags/request/"},{"name":"response","slug":"response","permalink":"http://wiki.brewlin.com/tags/response/"},{"name":"websocket","slug":"websocket","permalink":"http://wiki.brewlin.com/tags/websocket/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"7.客户端","slug":"net-protocol/7-客户端","permalink":"http://wiki.brewlin.com/categories/net-protocol/7-客户端/"}]},{"title":"快速开始","date":"2019-12-05T13:28:59.000Z","path":"wiki/net-protocol/1.前言/1.快速开始/","text":"demo案例cmd:该目录下为各协议的实现demo，提供api调用实现以及测试 环境配置 需要配置相关的参数 config/net.go 如果应用层协议要与外网通讯，必须配置本地物理网卡作为网关使用 推荐使用too/up.go工具，创建tap网卡和配置环境 存在的问题1.外网通讯问题请看目录8问题反馈: 目前外网通讯采用的是，使用本地物理网卡开启ip_forward 和nat转发达到外网通讯，测试发现多次无法收到外网的回复包，导致client等调用超时， 具体可以通过抓包物理网卡观察","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"1.前言","slug":"net-protocol/1-前言","permalink":"http://wiki.brewlin.com/categories/net-protocol/1-前言/"}]},{"title":"http-客户端","date":"2019-12-05T13:28:59.000Z","path":"wiki/net-protocol/7.客户端/http-客户端/","text":"@客户端创建123456789101112131415161718192021package mainimport ( \"fmt\" \"github.com/brewlin/net-protocol/pkg/logging\" \"github.com/brewlin/net-protocol/protocol/application/http\")func init() &#123; logging.Setup()&#125;func main()&#123; cli,err := http.NewClient(\"http://10.0.2.15:8080/test\") if err != nil &#123; panic(err) return &#125; cli.SetMethod(\"GET\") cli.SetData(\"test\") res,err := cli.GetResult() fmt.Println(res)&#125; 实现了基本的http客户端,发起请求和接收响应等get post方法 依赖tap虚拟网卡，所以需要启动网卡依赖 依赖ARP,TCP,IPV4等协议，所以默认注册了该协议 注意： 1.外网请求需要使用tool/up 方式启动网卡配置数据包转发 2.未实现dns查询域名，必须使用ip测试 @NewClient 创建客户端构造函数传入url,默认返回一个*Client 指针1cli,err := http.NewClient(\"http://10.0.2.15:8080/test\") @设置请求方法设置请求的http方法 GET,POST等1cli.SetMethod(\"GET\") @添加请求数据1cli.SetData(\"test\") 添加数据 @获取响应结果该方法真正执行tcp连接，发送数据，和读取响应数据1res,err := cli.GetResult()","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"tcp","slug":"tcp","permalink":"http://wiki.brewlin.com/tags/tcp/"},{"name":"http","slug":"http","permalink":"http://wiki.brewlin.com/tags/http/"},{"name":"client","slug":"client","permalink":"http://wiki.brewlin.com/tags/client/"},{"name":"request","slug":"request","permalink":"http://wiki.brewlin.com/tags/request/"},{"name":"response","slug":"response","permalink":"http://wiki.brewlin.com/tags/response/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"7.客户端","slug":"net-protocol/7-客户端","permalink":"http://wiki.brewlin.com/categories/net-protocol/7-客户端/"}]},{"title":"Tun/Tap虚拟网卡外网通讯","date":"2019-12-04T13:28:59.000Z","path":"wiki/net-protocol/8.问题反馈/tun_tap/","text":"简介tap属于2层协议，也就是他能够像读取文件一样获取拥有完整的数据包，包括以太网封装的mac目的地址和源地址等。拥有自己的ip地址和网段、mac地址、等信息，可以当做完整独立的网卡 tun数据2层协议，也就是只能获取ip数据包结构，不能获得mac地址等等网络层以下的数据信息 默认tap网卡有自己的网段，和本地物理网卡不在同一个网段，那么收发的数据包需要路由配置，但是无法转发到网关路由器 有两种方法可以让tap网卡收发外网数据包， 新建一个网桥bridge,并把tap和物理网卡桥接到该网桥下 tap网卡的数据包所有的都转发到本地物理网卡上，让物理网卡替tap 收发数据包到网关 1234567891011121314151617+----------------------------------------------------------------+| || +------------------------------------------------+ || | Newwork Protocol Stack | || +------------------------------------------------+ || ↑ ↑ ||..............|................................|................|| ↓ ↓ || +----------+ +------------+ || | eth0 | | tap0 | || +----------+ +------------+ || 10.0.2.15 ↑ 192.168.1.1 || | || | |+--------------|-------------------------------------------------+ ↓ Physical Network 可以看到新建的tap虚拟网卡，可以自己定义协议栈和收发数据，但是却无法和物理网卡通讯 1. ip转发方式实现外网通讯本质来说，就是让tap和 本地网卡通讯，只是目的ip依然为外网ip,那么本地网卡收到数据包后，判断ip为外网后替你转发到网卡后，进行一下跳，直到收到对方的包，然后在回复给tap网卡1234567891011121314151617+----------------------------------------------------------------+| || +------------------------- | -----------------------+ || | Newwork Prot | ocol Stack | || +------------------------- | -----------------------+ || ↑ ↑ ||..............|................................|................|| ↓ ↓ || +----------+ +------------+ || | eth0 | &lt;-------&gt; | tap0 | || +----------+ +------------+ || 10.0.2.15 ↑ 192.168.1.1 || | || | |+--------------|-------------------------------------------------+ ↓ Physical Network 总的来说就是所有的数据包都发给eth0,mac目的地址填eth0的MAC地址，目的ip地址保持不变，传给eth0 让他去判断后转发给网关,最后转发到外网去。 @开启物理网卡的ip转发临时 1# echo &quot;1&quot;&gt; /proc/sys/net/ipv4/ip_forward 永久 123# nano /etc/sysctl.confnet.ipv4.ip_forward=1 //取消注释# sysctl -p //保存 第三种 1# sudo sysctl net.ipv4.ip_forward=1 @配置网卡防火墙规则配置物理网卡接受来自tap网段的数据包，并进行nat转发 1234# iptables -F //清除所有的iptables规则# iptables -P INPUT ACCEPT //允许接收# iptables -P FORWARD ACCEPT //允许发送数据包# iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -o eth0 -j MASQUERADE //MASQUERADE方式配置nat 2. 桥接网卡模式1234567891011121314151617181920+----------------------------------------------------------------+| || +------------------------------------------------+ || | Newwork Protocol Stack | || +------------------------------------------------+ || ↑ ↑ ||.........................|...........................|..........|| ↓ ↓ || +------+ +--------+ +-------+ || | | | .2.15 | |192.168.1.0 || +------+ +--------+ &lt;---------- +-------+ || | eth0 |&lt;---&gt;| br0 | | tap | || +------+ +--------+ +-------+ || ↑ || | || | || | |+------------|---------------------------------------------------+ ↓ Physical Network 可以看到，tap网卡所有的写入数据都会转发到网桥br0上，处理，也能发送到网关连通外网，但是我的tap网卡却收不到网桥发回的数据， 比如tap发送一个tcp sync 包到外网ip114.148.199.89(瞎编的)，那么他的流程实际是这样 tap -&gt; br0 br0收到目的ip不是本机，则发给网关，并带上源mac地址为br0地址 br0 -&gt; gateway 网关收到数据后进行下一跳，直到发送给114.148.199.89 114.148.199.89 -&gt; br0 114.148.199.89收到sync包，并发送ack给br0 br0 收到了该ack包，但是发现目的ip也就是tap的ip地址路由不到，就会发送icmp rst复位数据包告诉 114.148.199.89 连接错误 1现在没有解决为什么tap网卡收不到外网包的问题! 配置桥接 桥接物理网卡到网桥上 1234- `brctl addbr br0` #创建网桥- `brctl addif br0 eth0` #将eth0先加入网桥- `ifconfig br0 10.0.2.15 up` #启动网桥并分配IP- `ifconfig eth0 0.0.0.0` #eth0现在不需要IP地址了 创建tap网卡 123- sudo ip tuntap add mode tap tap0- sudo ip link set tap0 up- sudo ip addr add 192.168.1.1/24 dev tap0 桥接tap网 1- brctl addif br0 tap0 转移网关到网桥上 1- ip route add defalut via 10.0.2.2 dev br0 配置nat 防火墙转发 1- iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -o br0 -j MASQUERADE","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"tap","slug":"tap","permalink":"http://wiki.brewlin.com/tags/tap/"},{"name":"tun","slug":"tun","permalink":"http://wiki.brewlin.com/tags/tun/"},{"name":"bridge","slug":"bridge","permalink":"http://wiki.brewlin.com/tags/bridge/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"8.问题反馈","slug":"net-protocol/8-问题反馈","permalink":"http://wiki.brewlin.com/categories/net-protocol/8-问题反馈/"}]},{"title":"Logic 节点开放接口","date":"2019-11-24T13:28:59.000Z","path":"wiki/im-cloud/4.开放接口/logic开放接口/","text":"http api接口开放api推送接口,暴露http接口，提供用户业务推送功能1234HttpRouter::post(\"/im/push/keys\",\"/Api/PushKeyController/keys\");HttpRouter::post(\"/im/push/mids\",\"/Api/PushMidController/mids\");HttpRouter::post(\"/im/push/room\",\"/Api/PushRoomController/room\");HttpRouter::post(\"/im/push/all\",\"/Api/PushAllController/all\"); @push/keys根据keys 为id推送消息，key为client在注册cloud节点时分配的唯一值，每个端点（pc,android,ios）等注册等连接key值不同，所以会进行全部推送 [post] request:1234&#123; &quot;keys&quot;:[x,x,x,x,], &quot;msg&quot;:&quot;bytes&quot;&#125; @push/mids根据mids 为id推送对应client消息，mid为业务方自行管理，同一用户每个端点等mid唯一 [post] request:1234&#123; &quot;mids&quot;:[x,x,x,x,], &quot;msg&quot;:&quot;bytes&quot;&#125; @push/room进行房间广播，type + room 组合为房间唯一id[post] request:12345&#123; &quot;type&quot;:&quot;product1&quot;, &quot;room&quot;:&quot;room1&quot;, &quot;msg&quot;:&quot;bytes&quot;&#125; @push/all广播消息，推送所有端点所有连接 [post] request:123&#123; &quot;msg&quot;:&quot;bytes&quot;&#125; grpc 接口提供cloud节点用户连接注册grpc接口，多节点可以采用负载均衡123HttpRouter::post(&apos;/im.logic.Logic/Connect&apos;, &apos;/Grpc/Logic/connect&apos;);HttpRouter::post(&apos;/im.logic.Logic/Disconnect&apos;, &apos;/Grpc/Logic/disConnect&apos;);HttpRouter::post(&apos;/im.logic.Logic/Heartbeat&apos;, &apos;/Grpc/Logic/heartBeat&apos;);","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"coroutine","slug":"coroutine","permalink":"http://wiki.brewlin.com/tags/coroutine/"},{"name":"grpc","slug":"grpc","permalink":"http://wiki.brewlin.com/tags/grpc/"},{"name":"http","slug":"http","permalink":"http://wiki.brewlin.com/tags/http/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"4.开放接口","slug":"im-cloud/4-开放接口","permalink":"http://wiki.brewlin.com/categories/im-cloud/4-开放接口/"}]},{"title":"版本兼容","date":"2019-11-19T13:28:59.000Z","path":"wiki/im-cloud/2.版本/1.版本兼容/","text":"多进程与单线程协程版本都依赖与 pkg/Core 核心组件 单线程协程版 重写了App/Application -&gt; run()方法，并替换掉协程模式的server达到兼容整体架构的运行，更多细节请查看源码 多进程版本，根据需要在config/server.php 中配置进程数和task进程数","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"2.版本","slug":"im-cloud/2-版本","permalink":"http://wiki.brewlin.com/categories/im-cloud/2-版本/"}]},{"title":"单线程全协程化版","date":"2019-11-19T13:28:59.000Z","path":"wiki/im-cloud/2.版本/2.单进程全协程化版/","text":"im-cloud/apps 为单线程协程化版本，协程server、协程httpserver、协程websocekt协议等实现cloud-s,job-s,logic-s 协程化server暂且不清楚是否能够跨cpu调度，testing。。。。 @cloud-s 协程版cloud节点该节点根据SWOOLE 4.4.12+ 最新支持http2协议为基础构建，底层为单进程协程server：\\Swoole\\Coroutine\\Server构建协程tcp服务器，暴露tcp方式注册cloud中心 GRPC中心根据http_server:\\Swoole\\Coroutine\\Http\\Server构建基于http2协程的grpc中心，提供业务接口处理，并在该协程模式下实现websocket协议提供websocekt注册中心 @job-s 协程版job节点基于单进程版消费队列数据，并推送cloud节点处理，无特殊处理，可以采用多进程版本配合使用 @logic-s 协程版logic节点该节点采用\\Swoole\\Coroutine\\Http\\Server构建，并暴露接口提供client推送","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"2.版本","slug":"im-cloud/2-版本","permalink":"http://wiki.brewlin.com/categories/im-cloud/2-版本/"}]},{"title":"多进程worker版本","date":"2019-11-19T13:28:59.000Z","path":"wiki/im-cloud/2.版本/3.多进程worker版/","text":"im-cloud/appm 为多进程Worker-Task模型构建服务，基于Swoole\\Server,Swoole\\Http\\Server等实现cloud-m,job-m,logic-m节点 @cloud-m 多进程版cloud节点多进程采用 task进程-worker进程 等多进程处理请求方法，提升节点处理能力.cloud节点提供tcp、websocket等长连接注册到cloud中心，并提供grpc接口提供内部负载均衡推送 @job-m 多进程版job节点job为多进程消费队列数据，能更好的消费数据，提高并发处理能力 @logic-m 多进程版logic节点logic接口为用户业务接口节点，提供api接口推送数据，并缓存cloud用户连接数据到redis中","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"process","slug":"process","permalink":"http://wiki.brewlin.com/tags/process/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"2.版本","slug":"im-cloud/2-版本","permalink":"http://wiki.brewlin.com/categories/im-cloud/2-版本/"}]},{"title":"arp子网查询&跨子网查询","date":"2019-11-13T13:28:59.000Z","path":"wiki/net-protocol/4.网络层/跨子网arp查询&子网arp查询/","text":"1234当前网段为：192.168.1.0/24当前网络ip：192.168.1.1源mac地址 ：aa:00:01:01:01:01广播地址 ：ff:ff:ff:ff:ff:ff @子网查询1.广播下面为一个查询192.168.1.2 mac地址的arp请求6字节 | 6字节|2字节|2字节|2字节|1字节|1字节|2字节|6字节|4字节|6字节|4字节—|— |—- |—|—|—|—|—|—|—|—|–|—|—-|源Mac地址 | 目的Mac地址|以太网帧类型|硬件类型|协议类型|地址长度|协议地址长度|操作码|源mac地址|源ip地址|目的mac地址|目的ip地址aa:00:01:01:01:01|ff:ff:ff:ff:ff:ff|0x806|1|0x800|6|4|1|aa:00:01:01:01:01|192.168.1.1|?|192.168.1.2 可以看到在arp报文中，目的mac地址留空，期待arp回复的时候填满，这样就拿到了mac地址 @跨子网查询1.广播下面为一个查询115.159.254.64 mac地址的arp请求,跨子网通信区别在于目的mac地址为网关mac地址6字节 | 6字节|2字节|2字节|2字节|1字节|1字节|2字节|6字节|4字节|6字节|4字节—|— |—- |—|—|—|—|—|—|—|—|–|—|—-|源Mac地址 | 网关mac地址|以太网帧类型|硬件类型|协议类型|地址长度|协议地址长度|操作码|源mac地址|源ip地址|目的mac地址|目的ip地址aa:00:01:01:01:01|*|0x806|1|0x800|6|4|1|aa:00:01:01:01:01|192.168.1.1|?|192.168.1.2 直接将数据发往网关，网关在根据一下跳地址继续发往目的地","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"arp","slug":"arp","permalink":"http://wiki.brewlin.com/tags/arp/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"4.网络层","slug":"net-protocol/4-网络层","permalink":"http://wiki.brewlin.com/categories/net-protocol/4-网络层/"}]},{"title":"tcp-客户端","date":"2019-11-10T13:28:59.000Z","path":"wiki/net-protocol/7.客户端/tcp-客户端/","text":"@客户端创建12345678910111213141516171819202122import ( \"fmt\" \"github.com/brewlin/net-protocol/pkg/logging\" \"github.com/brewlin/net-protocol/protocol/transport/tcp/client\" _ \"github.com/brewlin/net-protocol/stack/stackinit\")func init() &#123; logging.Setup()&#125;func main() &#123; //注意不可以 目标IP为 127.0.0.1 导致无法发送 数据包 con := client.NewClient(\"10.0.2.15\", 8080) if err := con.Connect(); err != nil &#123; fmt.Println(err) return &#125; con.Write([]byte(\"send msg\")) //阻塞等待读 res, _ := con.Read() fmt.Println(string(res))&#125; 实现了基本的tcp客户端连接读写等函数 依赖tap虚拟网卡，所以需要启动网卡依赖 依赖ARP,TCP,IPV4等协议，所以默认注册了该协议 注意：默认本地地址为192.168.1.0/24 网段，如果目标ip为127.0.0.1 导致无法arp查询物理层地址,请填写局域网物理机器ip,或者外网ip @NewClient 创建客户端构造函数传入目的ip,端口等参数，默认返回一个*Client 指针1con := client.NewClient(\"10.0.2.15\", 8080) 注意:默认本地地址为192.168.1.0/24 网段，如果目标ip为127.0.0.1 导致无法arp查询物理层地址 @Connect tcp连接握手该函数主要处理两个任务 1.检查tap网卡是否启动，没有则默认初始化启动一个tap网卡拿到fd 2.进行tcp三次握手1234if err := con.Connect(); err != nil &#123; fmt.Println(err) return&#125; 连接失败的情况举例:1.err = no remote link address 这种情况一般表示该ip地址的arp查询失败，没有找到对应的mac地址2.err = connection was refused 这个和linux socket 错误码一致 表示 对端未监听该端口,连接拒绝 @Write 写入数据1con.Write([]byte(\"send msg\")) 直接向对端连接写入数据，错误返回err @Read 读取数据一次只读取一次数据，如果缓存没有读取完，则会返回 ErrWouldBlock错误，可以 在此监听该读方法12 //阻塞等待读res, _ := con.Read() @Readn 读取n字节数据123// var p [8]byte// res, _ := con.Readn(p[:1])// fmt.Println(p) 可以根据传入参数填充对应的字节数数据，如果不够则会阻塞等待数据填充满为止 golang 的slice底层是一个指针，所以虽然传值，但是实际会复制指针，那么该slice实际值会在Readn（）函数里被改变填充完后返回","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"tcp","slug":"tcp","permalink":"http://wiki.brewlin.com/tags/tcp/"},{"name":"client","slug":"client","permalink":"http://wiki.brewlin.com/tags/client/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"7.客户端","slug":"net-protocol/7-客户端","permalink":"http://wiki.brewlin.com/categories/net-protocol/7-客户端/"}]},{"title":"流量控制-滑动窗口","date":"2019-11-05T12:20:20.000Z","path":"wiki/net-protocol/3.传输层/tcp/5.流量控制的实现-滑动窗口/","text":"接收端在给发送端回 ACK 中会汇报自己的 AdvertisedWindow，而发送方会根据这个窗口来控制发送数据的大小，以保证接收方可以处理。要明确的是滑动窗口分为两个窗口，接收窗口和发送窗口 @接受窗口接收窗口不仅可以限制发送端发送的速率，还可以提高效率，因为接收窗口的机制，可以允许发送端一次多发送几个片段，而不必等候 ACK，而且可以允许等待一定情况下的乱序， 比如说先缓存提前到的数据，然后去等待需要的数据。 接收的窗口可以分为四段： 数据已经被 tcp 确认，但用户程序还未读取数据内容 中间还有些数据没有到达 数据已经接收到，但 tcp 未确认 通告窗口，也就是接收端在给发送端回 ACK 中会汇报自己的窗口大小 当接收端接收到数据包时，会判断该数据包的序列号是不是在接收窗口內，如果不在窗口內会立即回一个 ack 给发送端， 且丢弃该报文。滑动： 当用户程序读取接收窗口的内容后，窗口向右滑行 @发送窗口发送窗口的值是由接收窗口和拥塞窗口一起决定的，发送窗口的大小也决定了发送的速率。 发送窗口的上限值 = Min [rwnd, cwnd]，cwnd 拥塞窗口 f发送窗口可以分成四段: 已收到 ack 确认的数据 已经发送，但还没收到 ack 的数据 在窗口中还没有发出的（接收方还有空间） 窗口以外的数据（接收方没空间）滑动： 当发送端收到数据 ack 确认时，窗口向右滑 如果一个处理缓慢的 Server（接收端）是怎么把 Client（发送端）的TCP Sliding Window给降成 0 的。此时，你一定会问，如果 Window 变成 0 了，TCP 会怎么样？是不是发送端就不发数据了？是的，发送端就不发数据了，你可以想像成“Window Closed”，那你一定还会问，如果发送端不发数据了，接收方一会儿 Window size 可用了，怎么通知发送端呢？ 1.当接收方的应用程序读取了接收缓冲区中的数据以后，接收方会发送一个 ACK，通过通告窗口字段告诉发送方自己又可以接收数据了，发送方收到这个 ACK 之后，就知道自己可以继续发送数据了。 2.同时发送端使用了Zero Window Probe技术，缩写为 ZWP，当接收方的接收窗口为 0 时，每隔一段时间，发送方会主动发送探测包，迫使对端响应来得知其接收窗口有无打开。 既然接收端会主动通知发送端，为何还需要发送端定时探测？ @Silly Window SyndromeSilly Window Syndrome翻译成中文就是“糊涂窗口综合症”。正如你上面看到的一样，如果我们的接收方太忙了，来不及取走 Receive Windows 里的数据，那么，就会导致发送方越来越小。到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的 window，而我们的发送方会义无反顾地发送这几个字节。 要知道，我们的 TCP+IP 头有 40 个字节，为了几个字节，要达上这么大的开销，这太不经济了。 所以，Silly Windows Syndrome这个现像就像是你本来可以坐 200 人的飞机里只做了一两个人。要解决这个问题也不难，就是避免对小的 window size 做出响应，直到有足够大的 window size 再响应，这个思路可以同时实现在 sender 和 receiver 两端。 如果这个问题是由 Receiver 端引起的，那么就会使用David D Clark’s方案。在 receiver 端，如果收到的数据导致window size小于某个值，可以直接 ack(0)回 sender，这样就把 window 给关闭了，也阻止了 sender 再发数据过来，等到 receiver 端处理了一些数据后windows size大于等于了 MSS，或者，receiver buffer有一半为空，就可以把 window 打开让 sender 发送数据过来。 如果这个问题是由 Sender 端引起的，那么就会使用著名的Nagle’s algorithm。这个算法的思路也是延时处理，他有两个主要的条件： 要等到 Window Size &gt;= MSS 或是 Data Size &gt;= MSS收到之前发送数据的 ack 回包，他才会发数据，否则就是在攒数据 @发送窗口的维护12345678910 +-------&gt; sndWnd &lt;-------+ | |---------------------+-------------+----------+--------------------| acked | * * * * * * | # # # # #| unable send---------------------+-------------+----------+-------------------- ^ ^ | | sndUna sndNxt***** in flight data##### able send date 发送窗口主要维护这些变量，sndBufSize、sndBufUsed、sndUna、sndNxt 和 sndWnd。sndUna 表示是下一个未确认的序列号，sndNxt 是要发送的下一个段的序列号，sndWnd 是接受端通告的窗口大小。 首先是处理接收方的窗口通告，当收到报文时，一定会带接收窗口和确认号，此时先更新发送器的发送窗口大小为接收窗口大小。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123// Write writes data to the endpoint's peer.// 接收上层的数，通过tcp连接发送到对端func (e *endpoint) Write(p tcpip.Payload, opts tcpip.WriteOptions) (uintptr, &lt;-chan struct&#123;&#125;, *tcpip.Error) &#123; // Linux completely ignores any address passed to sendto(2) for TCP sockets // (without the MSG_FASTOPEN flag). Corking is unimplemented, so opts.More // and opts.EndOfRecord are also ignored. e.mu.RLock() defer e.mu.RUnlock() // The endpoint cannot be written to if it's not connected. // 判断tcp状态，必须已经建立了连接才能发送数据 if e.state != stateConnected &#123; switch e.state &#123; case stateError: return 0, nil, e.hardError default: return 0, nil, tcpip.ErrClosedForSend &#125; &#125; // Nothing to do if the buffer is empty. // 检查负载的长度，如果为0，直接返回 if p.Size() == 0 &#123; return 0, nil, nil &#125; e.sndBufMu.Lock() // Check if the connection has already been closed for sends. if e.sndClosed &#123; e.sndBufMu.Unlock() return 0, nil, tcpip.ErrClosedForSend &#125; // Check against the limit. // tcp流量控制：未被占用发送缓存还剩多少，如果发送缓存已经被用光了，返回 ErrWouldBlock avail := e.sndBufSize - e.sndBufUsed if avail &lt;= 0 &#123; e.sndBufMu.Unlock() return 0, nil, tcpip.ErrWouldBlock &#125; v, perr := p.Get(avail) if perr != nil &#123; e.sndBufMu.Unlock() return 0, nil, perr &#125; var err *tcpip.Error if p.Size() &gt; avail &#123; err = tcpip.ErrWouldBlock &#125; l := len(v) s := newSegmentFromView(&amp;e.route, e.id, v) // Add data to the send queue. // 插入发送队列 e.sndBufUsed += l e.sndBufInQueue += seqnum.Size(l) e.sndQueue.PushBack(s) e.sndBufMu.Unlock() // 发送数据，最终会调用 sender sendData 来发送数据。 if e.workMu.TryLock() &#123; // Do the work inline. e.handleWrite() e.workMu.Unlock() &#125; else &#123; // Let the protocol goroutine do the work. e.sndWaker.Assert() &#125; return uintptr(l), nil, err&#125;// 收到tcp段时调用 handleRcvdSegment; 它负责更新与发送相关的状态。func (s *sender) handleRcvdSegment(seg *segment) &#123; ... // 存放当前窗口大小。 s.sndWnd = seg.window // 获取确认号 ack := seg.ackNumber // 如果ack在最小未确认的seq和下一seg的seq之间 if (ack - 1).InRange(s.sndUna, s.sndNxt) &#123; ... // Remove all acknowledged data from the write list. acked := s.sndUna.Size(ack) s.sndUna = ack ackLeft := acked originalOutstanding := s.outstanding for ackLeft &gt; 0 &#123; // We use logicalLen here because we can have FIN // segments (which are always at the end of list) that // have no data, but do consume a sequence number. seg := s.writeList.Front() datalen := seg.logicalLen() if datalen &gt; ackLeft &#123; seg.data.TrimFront(int(ackLeft)) break &#125; if s.writeNext == seg &#123; s.writeNext = seg.Next() &#125; s.writeList.Remove(seg) s.outstanding-- seg.decRef() ackLeft -= datalen &#125; // Update the send buffer usage and notify potential waiters. s.ep.updateSndBufferUsage(int(acked)) ... &#125; ...&#125; @接受窗口的维护接收窗口主要维护这几个变量，rcvBufSize、rcvBufUsed、rcvNxt 和 rcvAcc， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687// tcp流量控制：计算未被占用的接收缓存大小func (e *endpoint) receiveBufferAvailable() int &#123; e.rcvListMu.Lock() size := e.rcvBufSize used := e.rcvBufUsed e.rcvListMu.Unlock() // We may use more bytes than the buffer size when the receive buffer // shrinks. if used &gt;= size &#123; return 0 &#125; return size - used&#125;func (e *endpoint) receiveBufferSize() int &#123; e.rcvListMu.Lock() size := e.rcvBufSize e.rcvListMu.Unlock() return size&#125;// zeroReceiveWindow 根据可用缓冲区的数量和接收窗口缩放，检查现在要宣布的接收窗口是否为零。func (e *endpoint) zeroReceiveWindow(scale uint8) bool &#123; if e.rcvBufUsed &gt;= e.rcvBufSize &#123; return true &#125; return ((e.rcvBufSize - e.rcvBufUsed) &gt;&gt; scale) == 0&#125;// tcp流量控制：判断 segSeq 在窗口內func (r *receiver) acceptable(segSeq seqnum.Value, segLen seqnum.Size) bool &#123; rcvWnd := r.rcvNxt.Size(r.rcvAcc) if rcvWnd == 0 &#123; return segLen == 0 &amp;&amp; segSeq == r.rcvNxt &#125; return segSeq.InWindow(r.rcvNxt, rcvWnd) || seqnum.Overlap(r.rcvNxt, rcvWnd, segSeq, segLen)&#125;// tcp流量控制：当接收窗口从零增长到非零时，调用 nonZeroWindow;在这种情况下，// 我们可能需要发送一个 ack，以便向对端表明它可以恢复发送数据。func (r *receiver) nonZeroWindow() &#123; if (r.rcvAcc-r.rcvNxt)&gt;&gt;r.rcvWndScale != 0 &#123; // We never got around to announcing a zero window size, so we // don't need to immediately announce a nonzero one. return &#125; // Immediately send an ack. r.ep.snd.sendAck()&#125;// 从tcp的接收队列中读取数据，并从接收队列中删除已读数据func (e *endpoint) readLocked() (buffer.View, *tcpip.Error) &#123; if e.rcvBufUsed == 0 &#123; if e.rcvClosed || e.state != stateConnected &#123; return buffer.View&#123;&#125;, tcpip.ErrClosedForReceive &#125; return buffer.View&#123;&#125;, tcpip.ErrWouldBlock &#125; s := e.rcvList.Front() views := s.data.Views() v := views[s.viewToDeliver] s.viewToDeliver++ if s.viewToDeliver &gt;= len(views) &#123; e.rcvList.Remove(s) s.decRef() &#125; scale := e.rcv.rcvWndScale // tcp流量控制：检测接收窗口是否为0 wasZero := e.zeroReceiveWindow(scale) e.rcvBufUsed -= len(v) // 检测糊涂窗口，主动发送窗口不为0的通告给对方 if wasZero &amp;&amp; !e.zeroReceiveWindow(scale) &#123; e.notifyProtocolGoroutine(notifyNonZeroReceiveWindow) &#125; return v, nil&#125;","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"tcp","slug":"tcp","permalink":"http://wiki.brewlin.com/tags/tcp/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"3.传输层","slug":"net-protocol/3-传输层","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/"},{"name":"tcp","slug":"net-protocol/3-传输层/tcp","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/tcp/"}]},{"title":"连接状态","date":"2019-11-04T13:28:59.000Z","path":"wiki/net-protocol/3.传输层/tcp/4.连接状态/","text":"@fin_wait1 状态四次挥手中，主动关闭方发送fin报文后，进入find_wait1状态 @close_wait四次挥手中，表示接受到对方fin报文，并发送对方ack回复，从此进入close_wait状态，等待发送对方fin报文 这中状态在开发中容易遇见，而且是灾难性的，因为这种状态会在网络中持续2*MSL（Max Segment Lifetime，最大分段生存期，指一个 TCP 报文在 Internet 上的最长生存时间。每个具体的 TCP 协议实现都必须选择一个确定的 MSL 值，RFC 1122 建议是 2 分钟，但 BSD 传统实现采用了 30 秒，Linux 可以 cat /proc/sys/net/ipv4/tcp_fin_timeout 看到本机的这个值）导致系统资源不会被释放 一般是由于服务端发生异常，导致未向客户端回复fin报文关闭连接进入time_wait状态 @fin_wait2 状态四次挥手中，表示发送对方fin报文，并接收到对方ack回复，进入到fin_wait2状态 @time_wait 状态四次挥手中，表示发送对方fin报文，并且受到ack报文和fin报文后进入time_wait状态 @last_ack 状态刚好和close_wait相反，四次挥手中，最后一次报文迟迟没有回复，客户端没有回复服务端ack确认 LAST_ACK 当被动关闭的一方在发送 FIN 报文后，等待对方的 ACK 报文的时候，就处于 LAST_ACK 状态。当收到对方的 ACK 报文后，也就可以进入到 CLOSED 可用状态了。 @closing 状态在四次挥手中，一般不会出现closing状态，因为主动关闭方发送Fin报文后，一般会先收到ack报文，随后在收到fin报文则进入time_wait状态 但是如果双方同时发送fin报文断开连接的话，就会出现fin报文先到，而ack报文在后面，也就是导致fin_wait2的状态直接进入closing状态","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"tcp","slug":"tcp","permalink":"http://wiki.brewlin.com/tags/tcp/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"3.传输层","slug":"net-protocol/3-传输层","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/"},{"name":"tcp","slug":"net-protocol/3-传输层/tcp","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/tcp/"}]},{"title":"协议分层模型","date":"2019-11-02T13:28:59.000Z","path":"wiki/net-protocol/1.前言/2.协议分层模型/","text":"协议运作其实就是将对应协议之间关联到协议都要先注册。在分流器中统一管理，数据包到达后一层一层解刨在转发到对应到业务层处理 例如监听tcp服务，需要注册 ipv4 arp tcp 等。 链路层 收到网卡原始数据后，通过分流器定位到ipv4协议，然后将数据包转发到ipv4协议处理 网络层ipv4层接受到数据后，在通过分流器找到传输层协议，将数据发往传输层 1e.dispatcher.DeliverTransportPacket(r, p, vv) 注册到分流器后，数据包到来，后一层一层转发到传输层tcp处理 分流器也就是每个协议层之间当协作转发关系。也就是分发网络协议到对应到协议栈处理1234567891011121314151617/ 网络层协议号和传输层协议号的组合，当作分流器的key值type protocolIDs struct &#123; network tcpip.NetworkProtocolNumber transport tcpip.TransportProtocolNumber&#125;// transportEndpoints 管理给定协议的所有端点。type transportEndpoints struct &#123; mu sync.RWMutex endpoints map[TransportEndpointID]TransportEndpoint&#125;// transportDemuxer 解复用针对传输端点的数据包（即，在它们被网络层解析之后）。// 它执行两级解复用：首先基于网络层协议和传输协议，然后基于端点ID。type transportDemuxer struct &#123; protocol map[protocolIDs]*transportEndpoints&#125; 可以看到分流器是个两级结构，第一级是protocolIDs，它是网络层协议号和传输层协议号的组合。第二级是个传输层 ID-TransportEndpointID，表示传输层端的四元组：源 IP、源端口、目的 IP、目的端口。分流器执行两级解复用，首先基于网络层协议和传输协议，然后基于端点 ID。","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"1.前言","slug":"net-protocol/1-前言","permalink":"http://wiki.brewlin.com/categories/net-protocol/1-前言/"}]},{"title":"校验和计算","date":"2019-11-02T13:28:59.000Z","path":"wiki/net-protocol/3.传输层/udp/2.检验和计算/","text":"UDP 计算校验和的方法和 IP 数据报首部校验和的方法相似。不同的是：IP 数据报校验和只校验 IP 数据报的首部，但 UDP 的校验和是把首部和数据部分一起都检验。 UDP 的校验和需要计算 UDP 首部加数据荷载部分，但也需要加上 UDP 伪首部。这个伪首部指，源地址、目的地址、UDP 数据长度、协议类型（0x11），协议类型就一个字节，但需要补一个字节的 0x0，构成 12 个字节。伪首部+UDP 首部+数据一起计算校验和。 UDP 检验和的计算方法是：按每 16 位求和得出一个 32 位的数；如果这个 32 位的数，高 16 位不为 0，则高 16 位加低 16 位再得到一个 32 位的数；重复第 2 步直到高 16 位为 0，将低 16 位取反，得到校验和。","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"udp","slug":"udp","permalink":"http://wiki.brewlin.com/tags/udp/"},{"name":"transport","slug":"transport","permalink":"http://wiki.brewlin.com/tags/transport/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"3.传输层","slug":"net-protocol/3-传输层","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/"},{"name":"udp","slug":"net-protocol/3-传输层/udp","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/udp/"}]},{"title":"tool","date":"2019-10-31T13:28:59.000Z","path":"wiki/net-protocol/6.物理层/tool/","text":"虚拟网卡tap启动关闭到工具 up123cd path/toolgo build up.gosudo ./up down123cd path/toolgo build down.gosudo ./down","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"eth","slug":"eth","permalink":"http://wiki.brewlin.com/tags/eth/"},{"name":"tap","slug":"tap","permalink":"http://wiki.brewlin.com/tags/tap/"},{"name":"tool","slug":"tool","permalink":"http://wiki.brewlin.com/tags/tool/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"6.物理层","slug":"net-protocol/6-物理层","permalink":"http://wiki.brewlin.com/categories/net-protocol/6-物理层/"}]},{"title":"以太网协议","date":"2019-10-31T13:28:59.000Z","path":"wiki/net-protocol/5.链路层/1.以太网协议/","text":"以太网头部1234567890 1 2 3 4 5 60 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| DESTINATION MAC 6字节目的mac地址 |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| ORIGINALSRC MAC 6字节源 mac地址 |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| 2 字节 网络层协议类型 | 46 - 1500 字节（ip包头 + 传输层包头 + 应用层数据） |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 目的mac地址:6 字节 物理地址 源 mac地址:6 字节 物理地址 数据包协议类型: 为0x8000时为 IPv4 协议包，为0x8060时，后面为 ARP 协议包。 数据包 :网卡输送能力上限 MTU(1500字节),对网络层 ip协议对封装，","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"eth","slug":"eth","permalink":"http://wiki.brewlin.com/tags/eth/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"5.链路层","slug":"net-protocol/5-链路层","permalink":"http://wiki.brewlin.com/categories/net-protocol/5-链路层/"}]},{"title":"业务说明","date":"2019-10-30T13:28:59.000Z","path":"wiki/swoole-im/前言/业务说明/","text":"流程架构","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"}],"categories":[{"name":"swoole-im","slug":"swoole-im","permalink":"http://wiki.brewlin.com/categories/swoole-im/"},{"name":"前言","slug":"swoole-im/前言","permalink":"http://wiki.brewlin.com/categories/swoole-im/前言/"}]},{"title":"微服务应用","date":"2019-10-28T13:28:59.000Z","path":"wiki/swoole-im/index/","text":"基于Swoft-cloud微服务架构-Im通讯平台@概述 对swoole-im进行服务拆分，进行微服务架构(https://www.github.com/brewlin/swoole-im.git) 基于Swoft-cloud 进行服务化治理服务治理、熔断器、服务降级、Rpc调用、服务网关、Cosul服务注册与发现、Mysql连接池、Redis连接池、异步任务、websocket推送 底层采用Swoole通讯引擎,多进程、异步任务，开发模式：Aop，依赖注入，Bean容器，全注解 服务间配置独立，使用composer进行依赖管理，进行composer组件化开发，公用的Rpc接口封装为独立composer包。 拆分有群组Rpc服务，聊天日志Rpc服务，用户基础Rpc服务，消息处理服务 Httpserver网关api服务，websocket服务 请使用swoole扩展2.1.3+ 以及php 7.1! 快速开始 针对每个服务使用composer更新依赖make install 开启所有服务 make start 关闭所有服务 make stop docker启动 docker-compose up 演示地址 http://chat.huido.site (可以注册) http://cloud.huido.site (soon..) @gateway-api-cloud (soon) 新增im-cloud版本，接入im-cloud分布式推送中间件作为推送中心。 新网关中心可替代原有的网关服务，接入im-cloud分布式推送服务 im-cloud 基于swoole原生开发的分布式中间件 done soon.. @架构图服务依赖 前端服务 服务处理 服务开发Rpc 接口依赖&quot;repositories&quot;: { &quot;0&quot;:{ &quot;type&quot;:&quot;vcs&quot;,//git源 &quot;url&quot;:&quot;http://www.github.com/brewlin/service-components&quot; //公用composer包 }, &quot;packagist&quot;: { &quot;type&quot;: &quot;composer&quot;, &quot;url&quot;: &quot;https://packagist.laravel-china.org&quot; } } Gateway-Api &amp;&amp; Websocket 中心网关服务接受web端webocket长连接通讯、api请求. 处理基础数据，对外中心api网关. 服务调用方(Rpc 调用),调用群组服务、用户基础服务等` 依赖: user-service、group-service、services-components、redis-service、group-service、msg-service 配置: worker:2，task_worker:2,port:8090,熔断器，服务降级,Rpc连接池，useProvider:false, 服务启动： cd gateway-api/ composer install更新依赖 php bin/swoft ws:start –d可选守护进程模式 Redis 缓存处理服务处理用用户的业务缓存，使用swoft redis连接池 独立服务处理用户群组缓存、好友聊天缓存 依赖:services-compoents、swoft-cloud* 服务启动： cd/redis-service composer install更新依赖 php bin/swoft rpc:start –d可选守护进程模式配置: worker:2，task_worker:2,port:8091,SyncRedis连接池，useProvider:false, Group 群组数据处理服务处理用群组基础信息，群组聊天等业务处理 依赖:services-compoents、swoft-cloud*、redis-service 服务启动： cd/group-service composer install更新依赖 php bin/swoft rpc:start –d可选守护进程模式配置: worker:2，task_worker:2,port:8092,SyncRedis连接池，useProvider:false,mysql连接池 Msg 消息处理服务处理系统消息，收发请求消息存储 依赖:services-compoents、swoft-cloud* 服务启动： cd ./msg-service composer install更新依赖 php bin/swoft rpc:start –d可选守护进程模式配置: worker:2，task_worker:2,port:8093,useProvider:false,mysql连接池 User 用户中心服务用户基础信息处理 用户好友聊天处理 用户业务功能封装 依赖:services-compoents、swoft-cloud*、redis-service,msg-service,group-service 服务启动： cd ./user-service composer install更新依赖 php bin/swoft rpc:start –d可选守护进程模式配置: worker:2，task_worker:2,port:8094,useProvider:false,mysql连接池 启动和服务进程预览 开发进度 &amp;&amp; 实现功能 好友单聊 添加好友 websocket token 机制 好友右键菜单操作功能 发送好友信息 查看好友资料 查看好友聊天记录 好友备注功能 移动好友分组 删除好友功能 发现中心 搜索好友 推荐好友 添加好友 创建群 消息中心 好友离线上线通知,好友上线离线消息推送 系统消息推送,好友申请处理操作 预览 消息处理中心，消息盒子 发现中心，推荐好友群，搜索好友群，创建群 单聊，群聊 聊天界面，聊天记录 主面板 右键功能（好友管理，分组管理，群管理） 整体预览图","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"im","slug":"im","permalink":"http://wiki.brewlin.com/tags/im/"}],"categories":[{"name":"swoole-im","slug":"swoole-im","permalink":"http://wiki.brewlin.com/categories/swoole-im/"}]},{"title":"服务发现","date":"2019-10-28T13:28:59.000Z","path":"wiki/im-cloud/5.相关实现/2.应用实现/2.服务发现/","text":"@注册服务file:app/Process/Discovery.php1234567891011121314151617181920212223242526272829 /** * 自定义子进程 执行入口 * @param Process $process */ public function run(Process $process) &#123; swoole_set_process_name(sprintf('php-im-cloud discovery process (%s)',ROOT)); $registerStatus = false; while(!$registerStatus)&#123; $registerStatus = provider()-&gt;select()-&gt;registerService(); if(!$registerStatus)&#123; CLog::error(\"consul register false sleep 1 sec to reregiseter\"); sleep(1); &#125; &#125; $config = config(\"discovery\"); $discovery = $config[\"consul\"][\"discovery\"][\"name\"]; while (true)&#123; $services = provider()-&gt;select()-&gt;getServiceList($discovery); if(empty($services))&#123; Log::error(\"not find any instance node:$discovery\"); LogicClient::updateService([]); goto SLEEP; &#125; LogicClient::updateService($services);SLEEP: sleep(5); &#125; &#125; 1.注册服务 注册失败后重试 2.发现服务 进行更新本地服务列表 @更新服务发现服务到频率越高表示同步到时间约精确，这里会有一个问题，php到array数组是非线程安全更新和读取都在进行，并发是会很大几率出现错误，单纯都加锁反而会降低性能 swoole table 应运而生，底层是原子操作，多进程共享变量，完整的解决来问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * Class LogicClient * @Bean() * @package App\\Lib */class LogicClient&#123; /** * servicelist * @var MemoryTable * [ * ip =&gt; [addr =&gt; ip] * \"127.0.0.1:9500\" =&gt; [\"Address\" =&gt; \"127.0.0.1\",\"Port\" =&gt; \"9500\"] * ] */ public static $table = null; /** * LogicClient constructor. */ public function __construct() &#123; $memorySize = (int)env(\"MEMORY_TABLE\",1000); $column = [ \"Address\" =&gt; [Type::String,20], \"Port\" =&gt; [Type::String,10], ]; self::$table = Table::create($memorySize,$column); &#125; /** * 返回一个可用的grpc 客户端 和logic 节点进行交互 * @return mixed|null */ public static function getLogicClient()&#123; if(self::$table-&gt;count() == 0)&#123; Log::error(\"not logic node find\"); return false; &#125; $node = \\bean(RandomBalancer::class)-&gt;select(self::$table-&gt;getKeys()); return $node; &#125; /** * automic operation insert|update|del * @param array $server */ public static function updateService(array $server) &#123; //insert if not exist | update if not equal $serverList = []; foreach ($server as $ser) &#123; $addr = $ser[\"Address\"].\":\".$ser[\"Port\"]; $serverList[] = $addr; if(!self::$table-&gt;exist($addr)) self::$table-&gt;set($addr,$ser); &#125; //del not exist foreach (self::$table as $k =&gt; $ser) &#123; if (!in_array($k, $serverList)) &#123; self::$table-&gt;del($k); &#125; &#125; &#125;&#125; table 内存表的创建使用原生封装的库core/table 需要加上@bean()注解，因为内存表需要在swoole启动之前创建，也就是注解扫描阶段就需要建立","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://wiki.brewlin.com/tags/rabbitmq/"},{"name":"consul","slug":"consul","permalink":"http://wiki.brewlin.com/tags/consul/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"5.相关实现","slug":"im-cloud/5-相关实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/"},{"name":"2.应用实现","slug":"im-cloud/5-相关实现/2-应用实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/2-应用实现/"}]},{"title":"连接池实现","date":"2019-10-28T13:28:59.000Z","path":"wiki/im-cloud/5.相关实现/3.组件实现/1.连接池实现/","text":"简介实现机制基于swoole channel实现，channel大小默认为10,每次获取连接时判断如果连接池为空，则新建连接，并在结束时放回channel中，放回时注意如果大于channel则销毁该连接，同理如果获取连接时小于5，也需要新建连接。只有 满足pool &gt;=5 才从channel中获取该连接。放回时 满足 pool &lt; 10&amp;。而且需要检查该连接是否断开 pkg/core/src/pool/poolfactory.php:123456789101112131415161718192021222324252627282930313233343536/** * @param string $name * @param string $option * @return mixed */public function getPool(string $name,$option = \"\")&#123; $channelName = $option.$name; //检查当前进程 全局静态池里 是否存在该连接池 if(!isset($this-&gt;pools[$channelName]) || $this-&gt;pools[$channelName] === null)&#123; $this-&gt;pools[$channelName] = new Channel($this-&gt;maxActive); &#125; //检查连接池里 可用连接是否小于最小连接，如果小于则走新建逻辑，最后在回归池里 if($this-&gt;pools[$channelName]-&gt;length() &lt; $this-&gt;minActive)&#123; return container()-&gt;get($name)-&gt;create($option); &#125; //获取连接，pop一个连接 $connection = null; if(!$this-&gt;pools[$channelName]-&gt;isEmpty())&#123; $connection = $this-&gt;pools[$channelName]-&gt;pop(); &#125; //直接返回 if($connection !== null)&#123; return $connection; &#125; //channel is empty or not reach maxActive return new create if($this-&gt;pools[$channelName]-&gt;length() &lt; $this-&gt;maxActive)&#123; return container()-&gt;get($name)-&gt;create($option); &#125; $connection = $this-&gt;pools[$channelName]-&gt;pop($this-&gt;maxWaitTime); if($connection === false)&#123; CLog::error(\"channel pop timeout name:$name\"); return container()-&gt;get($name)-&gt;create($option); &#125; return $connection;&#125;","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://wiki.brewlin.com/tags/rabbitmq/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"5.相关实现","slug":"im-cloud/5-相关实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/"},{"name":"3.组件实现","slug":"im-cloud/5-相关实现/3-组件实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/3-组件实现/"}]},{"title":"推送实现","date":"2019-10-28T13:28:59.000Z","path":"wiki/im-cloud/5.相关实现/2.应用实现/1.推送实现/","text":"推送流程总的来说logic暴露api接口服务，处理推送http请求，并通过队列的方式让job来消费该任务。最后通过grpc通知cloud节点推送实际的链接1logic -&gt; job -&gt; cloud @logicfile:app/Service/Dao/Queue.php 简短粗暴的直接丢到队列 rabbitmq即可123456789101112131415161718/** * pushMsg * @param int $op * @param string $server * @param array $keys * @param $msg * @throws \\Throwable */ public function pushMsg(int $operation,string $server,array $keys, $msg) &#123; $type = PushMsg\\Type::PUSH; $pushmsg = compact(\"type\",\"operation\",\"server\",\"keys\",\"msg\"); Log::info(\"push msg to job node data:\".json_encode($pushmsg)); /** @var Producer $producers */ $producers = \\bean(Producer::class); //发送到队列里 producer()-&gt;produce($producers-&gt;producer($pushmsg)); &#125; @jobfile:app/Task/pushKey.phpjob节点直接消费数据，去连接池获取链接，直接push到cloud节点12345678910111213141516171819202122232425/** * 进行grpc 和 cloud 节点通讯 * @param int $operation * @param string $server * @param array $subkey * @param $body */public function push(int $operation ,string $server , array $subkey , $body)&#123; $proto = new Proto(); $proto-&gt;setOp($operation); $proto-&gt;setVer(1); $proto-&gt;setBody($body); $pushMsg = new PushMsgReq(); $pushMsg-&gt;setKeys($subkey); $pushMsg-&gt;setProto($proto); $pushMsg-&gt;setProtoOp($operation); if(!CloudClient::$table-&gt;exist($server))&#123; Log::error(\"pushkey not exist grpc client server: $server \"); return; &#125; GrpcCloudClient::PushMsg($server,$pushMsg);&#125; @cloudfile:app/Grpc/Cloud.phpgrpc服务端获取到请求后，去swooletable 内存表拿到对应到链接信息，进行推送123456789101112131415161718192021222324252627/** * 接受 logic节点 job节点grpc请求，单点推送消息 * @return void */public function pushMsg()&#123; Log::debug(\"cloud node: pushmsg\"); $pushMsgRpy = Parser::serializeMessage(new PushMsgReply()); /** @var PushMsgReq $pushMsgReq */ $pushMsgReq = Parser::deserializeMessage([PushMsgReq::class,null],request()-&gt;getRawBody()); response()-&gt;withContent($pushMsgRpy)-&gt;end(); if(empty($pushMsgReq-&gt;getKeys()) || empty($pushMsgReq-&gt;getProto()))&#123; Log::error(\"cloud grpc pushmsg keys proto is empty raw data:\".json_encode($pushMsgReq)); return; &#125; /** @var array $keys */ $keys = $pushMsgReq-&gt;getKeys(); $op = $pushMsgReq-&gt;getProtoOp(); $body = $pushMsgReq-&gt;getProto()-&gt;getBody(); //coroutine do foreach ($keys as $key)&#123; /** @var Task $task */ \\bean(Task::class)-&gt;deliver(Push::class,\"push\",[$key,$op,$body]); &#125;&#125;","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://wiki.brewlin.com/tags/rabbitmq/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"5.相关实现","slug":"im-cloud/5-相关实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/"},{"name":"2.应用实现","slug":"im-cloud/5-相关实现/2-应用实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/2-应用实现/"}]},{"title":"im-cloud","date":"2019-10-25T13:28:59.000Z","path":"wiki/im-cloud/5.相关实现/1.底层实现/1.im-cloud/","text":"im-cloud 基于swoole 原生协程构建分布式推送中间件一、概述 基于swoole原生协程构建商业化即时推送im服务中间件,不进行业务处理，单独作为中间件使用，可弹性扩充节点增加性能处理.不依赖外部框架，核心代码为原生swoole构建的组件 借鉴goim(bilibili出品,生产级百万消息秒级推送)，使用swoole实现基于php的高性能分布式im中间件，提升高并发性能的推送 二、服务业务节点 cloud,job,logic 等节点都可以水平扩容 例如在消费能力不足时可以启动n个job节点提高并消费能力 启动多个cloud节点作为client客户端负载均衡，将多个websocket，tcp client分布到多个cloud节点中，提高cloud节点中心处理能力 logic 提供对外restapi 作为主要业务节点 高性能 协程化、水平扩容、分布式服务架构、接入服务治理 @cloudcloud 作为中心服务节点 grpc-server 节点，对外接收TCP、Websocket客户端进行长连接,可以水平扩容至多个节点 并注册到服务中心，例如consul。每个cloud节点维护自己的客户端 @jobjob 节点作为消费节点 消费队列数据 然后进行grpc 和cloud服务进行通讯 进行 push push room broadcast,作为节点中间件，消费kafaka，rockermq。。。之类，可以扩展多个节点提高并发消费能力 @logiclogic 节点 提供rest api接口，作为生产节点 和 grpc客户端,可写入队列作为生产者，也可以扩展自己的业务进行grpc直接调用cloud节点中心进行推送 三、组件依赖包 package 服务间配置独立，使用composer进行依赖管理，进行composer组件化开发 im-core 为核心基础组件，底层设计借鉴 swoft源码设计 im-grpc 定义grpc接口规范composer包,使用protobuf构建,封装有连接池 im-discovery 服务发现注册组件，注册grpc-server，发现服务等封装 im-process 进程管理模块，可以注册启动自定义进程，并交由swoole master进程管理声明周期 im-queue 消息队列管理模块，提供消息队列接口，底层实现了连接池接口，无需管理连接，根据类型可以切换不同的消息队列(done rabbitmq,soon kafak) im-redis 封装了连接池版本的redis client im-task 异步任务组件，封装投递task进程任务的接口，目前仅支持投递worker-&gt;task,不支持自定义进程投递以及投递到自定义进程 四、数据流程im-cloud 连接流程图 im-cloud 数据流程图 im-cloud 业务流程","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://wiki.brewlin.com/tags/rabbitmq/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"5.相关实现","slug":"im-cloud/5-相关实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/"},{"name":"1.底层实现","slug":"im-cloud/5-相关实现/1-底层实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/1-底层实现/"}]},{"title":"arp协议","date":"2019-10-24T13:28:59.000Z","path":"wiki/net-protocol/4.网络层/arp协议/","text":"ARP 协议基于arp协议，获取对应的物理mac地址，虽然同属于ip层到网络层协议，但是arp数据包没有被封装进ip数据包里,而是直接封装在以太网帧中 上层tcp/ip协议报文只包含目标服务器的ip地址，而下层链路层以太网协议需要知道目标服务器的mac地址，则arp的协议是指当前主机发送ARP查询（广播）查询该mac地址，如果目标地址不是在同一个局域网，则该mac地址则是局域网外的路由器mac地址，该所有帧都将发往该路由器地址 总之以太网协议中得到的上层数据中只有IP地址，需要使用arp协议去获得mac地址，arp协议会在链路层进行广播，只有目标地址会回应123ARP Paclket Format arp协议数据包格式6字节(以太网目的地址) + 6字节（以太网源地址） + 2 字节（帧类型） + 28字节（arp请求回应包） 28字节包格式 2字节硬件类型：1 =&gt; 以太网地址 2字节协议类型：0x800 表示ipv4协议 1字节地址长度：单位长度，一般为6 表示以太网地址的长度6字节 1字节协议地址长度：一般为4，ipv4地址长度 2字节操作码：1 =&gt; arp请求 2 =&gt; arp应答 3 =&gt; rarp请求 4 =&gt; rarp应答 6字节原mac地址：源mac地址 4字节源协议地址：源ip地址 如192.168.0.1 6字节目标mac地址：mac地址 不用担心每次请求都会触发arp查询广播，机器是有arp高速缓存的 arp -a @typetype:0x8060 表示arp协议","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"udp","slug":"udp","permalink":"http://wiki.brewlin.com/tags/udp/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"4.网络层","slug":"net-protocol/4-网络层","permalink":"http://wiki.brewlin.com/categories/net-protocol/4-网络层/"}]},{"title":"ip协议","date":"2019-10-24T13:28:59.000Z","path":"wiki/net-protocol/4.网络层/协议_ip/","text":"IP 报文协议首部协议格式 123456789101112131415161718190 1 2 3 40 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|Version| LHL | Type of Service | Total Length |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Identification(fragment Id) |Flags| Fragment Offset || 16 bits |R|D|M| 13 bits |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Time-To-Live | Protocol | Header Checksum || ttl(8 bits) | 8 bits | 16 bits |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Source IP Address (32 bits) |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Destination Ip Address (32 bits) |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Options (*** bits) | Padding |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| transport data... |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 版本（Version）: 1版本字段占 4bit，通信双方使用的版本必须一致。对于 IPv4，字段的值是 4。 首部长度（Internet Header Length， IHL）: 123占 4bit，首部长度说明首部有多少 32 位字（4字节）。由于 IPv4首部可能包含数目不定的选项，这个字段也用来确定数据的偏移量。这个字段的最小值是 5（二进制 0101），相当于 5*4=20 字节（RFC 791），最大十进制值是 15。 区分服务（Differentiated Services，DS): 12占 8bit，最初被定义为服务类型字段，实际上并未使用，但 1998 年被 IETF 重定义为区分服务 RFC 2474。只有在使用区分服务时，这个字段才起作用，在一般的情况 下都不使用这个字段。例如需要实时数据流的技术会应用这个字段，一个例子是 VoIP。 显式拥塞通告（ Explicit Congestion Notification，ECN）:12在 RFC 3168 中定义，允许在不丢弃报文的同时通知对方网络拥塞的发生。ECN 是一种可选的功能，仅当两端都支持并希望使用，且底层网络支持时才被使用。 全长（Total Length）:12345这个 16 位字段定义了报文总长，包含首部和数据，单位为字节。这个字段的最小值是 20（20 字节首部+0 字节数据），最大值是 216-1=65,535。IP 规定所有主机都必须支持最小 576 字节的报文，这是假定上层数据长度 512 字节，加上最长 IP 首部 60 字节，加上 4 字节富裕量，得出 576 字节，但大多数现代主机支持更大的报文。当下层的数据链路协议的最大传输单元（MTU）字段的值小于 IP 报文长度时间，报文就必须被分片，详细见下个标题。 标识符（Identification):12占 16 位，这个字段主要被用来唯一地标识一个报文的所有分片，因为分片不一定按序到达，所以在重组时需要知道分片所属的报文。每产生一个数据报，计数器加 1，并赋值给此字段。一些实验性的工作建议将此字段用于其它目的，例如增加报文跟踪信息以协助探测伪造的源地址。 标志 （Flags）:1234567这个 3 位字段用于控制和识别分片，它们是：位 0：保留，必须为 0； 位 1：禁止分片（Don’t Fragment，DF），当 DF=0 时才允许分片； 位 2：更多分片（More Fragment，MF），MF=1 代表后面还有分片，MF=0 代表已经是最后一个分片。 如果 DF 标志被设置为 1，但路由要求必须分片报文，此报文会被丢弃。这个标志可被用于发往没有能力组装分片的主机。当一个报文被分片，除了最后一片外的所有分片都设置 MF 为 1。最后一个片段具有非零片段偏移字段，将其与未分片数据包区分开，未分片的偏移字段为 0。 分片偏移 （Fragment Offset）:1这个 13 位字段指明了每个分片相对于原始报文开头的偏移量，以 8 字节作单位。 存活时间（Time To Live，TTL）:1234这个 8 位字段避免报文在互联网中永远存在（例如陷入路由环路）。存活时间以秒为单位，但小于一秒的时间均向上取整到一秒。在现实中，这实际上成了一个跳数计数器：报文经过的每个路由器都将此字段减 1，当此字段等于 0 时，报文不再向下一跳传送并被丢弃，最大值是 255。常规地，一份 ICMP 报文被发回报文发送端说明其发送的报文已被丢弃。这也是 traceroute 的核心原理。 协议 （Protocol）:1占 8bit，这个字段定义了该报文数据区使用的协议。IANA 维护着一份协议列表（最初由 RFC 790 定义），详细参见 IP 协议号列表。 首部检验和 （Header Checksum）:1234这个 16 位检验和字段只对首部查错，不包括数据部分。在每一跳，路由器都要重新计算出的首部检验和并与此字段进行比对，如果不一致，此报文将会被丢弃。重新计算的必要性是因为每一跳的一些首部字段（如 TTL、Flag、Offset 等）都有可能发生变化，不检查数据部分是为了减少工作量。数据区的错误留待上层协议处理——用户数据报协议（UDP）和传输控制协议（TCP）都有检验和字段。此处的检验计算方法不使用 CRC。 源地址 123一个 IPv4 地址由四个字节共 32 位构成，此字段的值是将每个字节转为二进制并拼在一起所得到的 32 位值。例如，10.9.8.7 是 00001010000010010000100000000111。但请注意，因为 NAT 的存在，这个地址并不总是报文的真实发送端，因此发往此地址的报文会被送往 NAT 设备，并由它被翻译为真实的地址。 目的地址1与源地址格式相同，但指出报文的接收端。 选项:123附加的首部字段可能跟在目的地址之后，但这并不被经常使用，从 1 到 40 个字节不等。请注意首部长度字段必须包括足够的 32 位字来放下所有的选项（包括任何必须的填充以使首部长度能够被 32 位整除）。当选项列表的结尾不是首部的结尾时，EOL（选项列表结束，0x00）选项被插入列表末尾。下表列出了可能。 字段 长度 描述 备份 1 当此选项需要被备份到所有分片中时，设为 1。 类 2 常规的选项类别，0 为“控制”，2 为“查错和措施”，1 和 3 保留。 数字 5 指明一个选项。 长度 8 指明整个选项的长度，对于简单的选项此字段可能不存在。 数据 可变 选项相关数据，对于简单的选项此字段可能不存在。 注：如果首部长度大于 5，那么选项字段必然存在并必须被考虑。注：备份、类和数字经常被一并称呼为“类型”。 数据 数据字段不是首部的一部分，因此并不被包含在首部检验和中。数据的格式在协议首部字段中被指明，并可以是任意的传输层协议。 一些常见协议的协议字段值被列在下面 协议字段值 协议名 缩写 1 互联网控制消息协议 ICMP 2 互联网组管理协议 IGMP 6 传输控制协议 TCP 17 用户数据报协议 UDP 41 IPv6 封装 ENCAP 89 开放式最短路径优先 OSPF 132 流控制传输协议 SCTP 总结IP 层最重要的目的是让两个主机之间通信，无论他们相隔多远。IP 协议理论上允许的最大 IP 数据报为 65535 字节（16 位来表示包总长）。但是因为协议栈网络层下面的数据链路层一般允许的帧长远远小于这个值，例如以太网的 MTU 通常在 1500 字节左右。所以较大的 IP 数据包会被分片传递给数据链路层发送，分片的 IP 数据报可能会以不同的路径传输到接收主机，接收主机通过一系列的重组，将其还原为一个完整的 IP 数据报，再提交给上层协议处理。IP 分片会带来一定的问题，分片和重组会消耗发送方、接收方一定的 CPU 等资源，如果存在大量的分片报文的话，可能会造成较为严重的资源消耗；分片丢包导致的重传问题；分片攻击；","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"udp","slug":"udp","permalink":"http://wiki.brewlin.com/tags/udp/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"4.网络层","slug":"net-protocol/4-网络层","permalink":"http://wiki.brewlin.com/categories/net-protocol/4-网络层/"}]},{"title":"端口机制","date":"2019-10-24T13:28:59.000Z","path":"wiki/net-protocol/4.网络层/协议_端口/","text":"端口端口在tcp协议中的体现端口一般在tcp首部前四个字节中，前2字节表示源端口 后两字节表示目标端口 1.周知端口（Well Known Ports）周知端口是众所周知的端口号，范围从 0 到 1023，其中 80 端口分配给 WWW 服务，21 端口分配给 FTP 服务等。我们在 IE 的地址栏里输入一个网址的时候是不必指定端口号的，因为在默认情况下 WWW 服务的端口是”80”。网络服务是可以使用其他端口号的，如果不是默认的端口号则应该在 地址栏上指定端口号，方法是在地址后面加上冒号”:”，再加上端口号。比如使用”8080”作为 WWW 服务的端口，则需要在地址栏里输入”网址:8080”。但是有些系统协议使用固定的端口号，它是不能被改变的，比如 139 端口专门用于 NetBIOS 与 TCP/IP 之间的通信，不能手动改变。 2.注册端口（Registered Ports）端口 1024 到 49151，分配给用户进程或应用程序。这些进程主要是用户选择安装的一些应用程序，而不是已经分配好了公认端口的常用程序。这些端口在没有被服务器资源占用的时候，可以用用户端动态选用为源端口。 3.动态端口（Dynamic Ports）动态端口的范围是从 49152 到 65535。之所以称为动态端口，是因为它 一般不固定分配某种服务，而是动态分配。比如本地想和远端建立 TCP 连接，如果没有指定本地源端口，系统就会给你自动分配一个未占用的源端口，这个端口值就是动态的，当你断开再次建立连接的时候，很有可能你的源端口和上次得到的端口不一样。 一些常见的端口号及其用途如下： TCP21 端口：FTP 文件传输服务 TCP22 端口：SSH 安全外壳协议 TCP23 端口：TELNET 终端仿真服务 TCP25 端口：SMTP 简单邮件传输服务 UDP53 端口：DNS 域名解析服务 UDP67 端口：DHCP 的服务端端口 UDP68 端口：DHCP 的客户端端口 TCP80 端口：HTTP 超文本传输服务 TCP110 端 口：POP3“邮局协议版本 3”使用的端口 TCP443 端口：HTTPS 加密的超文本传输服务 注意点端口是网络层协议地址+传输层协议号+端口号来区分的，比如： ipv4的tcp 80端口和ipv4的udp 80端口不会冲突。 如果你主机有两个 ip 地址 ip1 和 ip2，那么你同时监听ip1:80和ip2:80不会冲突。 ipv4的tcp 80端口和ipv6的tcp 80端口不会冲突。","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"udp","slug":"udp","permalink":"http://wiki.brewlin.com/tags/udp/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"4.网络层","slug":"net-protocol/4-网络层","permalink":"http://wiki.brewlin.com/categories/net-protocol/4-网络层/"}]},{"title":"icmp协议","date":"2019-10-24T13:28:59.000Z","path":"wiki/net-protocol/4.网络层/协议_icmp/","text":"ICMP 协议ICMP 的全称是 Internet Control Message Protocol 。与 IP 协议一样同属 TCP/IP 模型中的网络层，并且 ICMP 数据包是包裹在 IP 数据包中的。他的作用是报告一些网络传输过程中的错误与做一些同步工作。ICMP 数据包有许多类型。每一个数据包只有前 4 个字节是相同域的，剩余的字段有不同的数据包类型的不同而不同。ICMP 数据包的格式如下 1234567891011https://tools.ietf.org/html/rfc792 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Type | Code | Checksum |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| || 不同的Type和Code有不同的内容 | | |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 从技术角度来说，ICMP 就是一个“错误侦测与回报机制”， 其目的就是让我们能够检测网路的连线状况﹐也能确保连线的准确性﹐其功能主要有： 侦测远端主机是否存在。 建立及维护路由信息。 重导数据传送路径（ICMP 重定向）。 数据流量控制。ICMP 在沟通之中，主要是透过不同的类别(Type)与代码(Code) 让机器来识别不同的连线状况。 完整类型列表 TYPE CODE Description 0 0 Echo Reply——回显应答（Ping 应答） 3 0 Network Unreachable——网络不可达 3 1 Host Unreachable——主机不可达 3 2 Protocol Unreachable——协议不可达 3 3 Port Unreachable——端口不可达 3 4 Fragmentation needed but no frag. bit set——需要进行分片但设置不分片标志 3 5 Source routing failed——源站选路失败 3 6 Destination network unknown——目的网络未知 3 7 Destination host unknown——目的主机未知 3 8 Source host isolated (obsolete)——源主机被隔离（作废不用） 3 9 Destination network administratively prohibited——目的网络被强制禁止 3 10 Destination host administratively prohibited——目的主机被强制禁止 3 11 Network unreachable for TOS——由于服务类型 TOS，网络不可达 3 12 Host unreachable for TOS——由于服务类型 TOS，主机不可达 3 13 Communication administratively prohibited by filtering——由于过滤，通信被强制禁止 3 14 Host precedence violation——主机越权 3 15 Precedence cutoff in effect——优先中止生效 4 0 Source quench——源端被关闭（基本流控制） 5 0 Redirect for network——对网络重定向 5 1 Redirect for host——对主机重定向 5 2 Redirect for TOS and network——对服务类型和网络重定向 5 3 Redirect for TOS and host——对服务类型和主机重定向 8 0 Echo request——回显请求（Ping 请求） 9 0 Router advertisement——路由器通告 10 0 Route solicitation——路由器请求 11 0 TTL equals 0 during transit——传输期间生存时间为 0 11 1 TTL equals 0 during reassembly——在数据报组装期间生存时间为 0 12 0 IP header bad (catchall error)——坏的 IP 首部（包括各种差错） 12 1 Required options missing——缺少必需的选项 13 0 Timestamp request (obsolete)——时间戳请求（作废不用） 14 Timestamp reply (obsolete)——时间戳应答（作废不用） 15 0 Information request (obsolete)——信息请求（作废不用） 16 0 Information reply (obsolete)——信息应答（作废不用） 17 0 Address mask request——地址掩码请求 18 0 Address mask ICMP 是个非常有用的协议，尤其是当我们要对网路连接状况进行判断的时候。","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"udp","slug":"udp","permalink":"http://wiki.brewlin.com/tags/udp/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"4.网络层","slug":"net-protocol/4-网络层","permalink":"http://wiki.brewlin.com/categories/net-protocol/4-网络层/"}]},{"title":"tcp可靠性机制","date":"2019-10-22T13:28:59.000Z","path":"wiki/net-protocol/3.传输层/tcp/3.可靠性机制/","text":"tcp 可靠性机制可靠性指的是网络层能通信的前提下，保证数据包正确且按序到达对端。 比如发送端发送了“12345678”，那么接收端一定能收到“12345678”，不会乱序“12456783”，也不会少或多数据。 实现 TCP 的可靠传输有以下机制：1.校验和机制（检测和重传受到损伤的报文段） 2.确认应答机制（保存失序到达的报文段直至缺失的报文到期，以及检测和丢弃重复的报文段） 3.超时重传机制（重传丢失的报文段） 1.校验和每个 tcp 段都包含了一个检验和字段，用来检查报文段是否收到损伤。如果某个报文段因检验和无效而被检查出受到损伤，就由终点 TCP 将其丢弃，并被认为是丢失了。TCP 规定每个报文段都必须使用 16 位的检验和。12345678910111213141516// 校验和的计算func Checksum(buf []byte, initial uint16) uint16 &#123; v := uint32(initial) l := len(buf) if l&amp;1 != 0 &#123; l-- v += uint32(buf[l]) &lt;&lt; 8 &#125; for i := 0; i &lt; l; i += 2 &#123; v += (uint32(buf[i]) &lt;&lt; 8) + uint32(buf[i+1]) &#125; return ChecksumCombine(uint16(v), uint16(v&gt;&gt;16))&#125; 2.确认机制控制报文段不携带数据，但需要消耗一个序号，它也需要被确认，而 ACK 报文段永远不需要确认，ACK 报文段不消耗序号，也不需要被确认。在以前，TCP 只使用一种类型的确认，叫积累确认，目前 TCP 实现还实现了选择确认。 累积确认（ACK） 接收方通告它期望接收的下一个字节的序号，并忽略所有失序到达并被保存的报文段。有时这被称为肯定累积确认。在 TCP 首部的 32 位 ACK 字段用于积累确认，而它的值仅在 ACK 标志为 1 时才有效。举个例子来说，这里先不考虑 tcp 的序列号，如果发送方发了数据包 p1，p2，p3，p4；接受方成功收到 p1，p2，p4。那么接收方需要发回一个确认包，序号为 3(3 表示期望下一个收到的包的序号)，那么发送方就知道 p1 到 p2 都发送接收成功，必要时重发 p3。一个确认包确认了累积到某一序号的所有包，而不是对每个序号都发确认包。实际的 tcp 确认的都是序列号，而不是包的序号，但原理是一样的。 累积确认是快速重传的基础，这个后面讲拥塞控制的时候会详细说明。 累积确认是快速重传的基础，这个后面讲拥塞控制的时候会详细说明。 选择确认（SACK） 选择确认 SACK 要报告失序的数据块以及重复的报文段块，是为了更准确的告诉发送方需要重传哪些数据块。SACK 并没有取代 ACK，而是向发送方报告了更多的信息。SACK 是作为 TCP 首部末尾的选项来实现的。首先是否要启动 sack，应该在握手的时候告诉对方自己是否开启了 sack，这个是通过 kind=4 是选择性确认（Selective Acknowledgment，SACK）选项来实现的。实际传送 sack 信息的是 kind=5 的选项，其格式如下：123456789101112131415 +--------+--------+ | Kind=5 | Length | +--------+--------+--------+---------+ | Start of 1st Block | +--------+--------+--------+---------+ | End of 1st Block | +--------+--------+--------+---------+ | | / . . . . . . / | | +--------+--------+--------+---------+ | Start of nth Block | +--------+--------+--------+---------+ | End of nth Block | +--------+--------+--------+---------+ sack 的每个块是由两个参数构成的{ Start, End } Start 不连续块的第一个数据的序列号。End 不连续块的最后一个数据的序列号之后的序列号。 该选项参数告诉对方已经接收到并缓存的不连续的数据块，注意都是已经接收的，发送方可根据此信息检查究竟是哪个块丢失，从而发送相应的数据块。 比如下图：如图所示，tcp 接收方在接收到不连续的 tcp 段，可以看出，序号 1～1000，1501～3000，3501～4500 接收到了，但却少了序号 1001～1500，3001～3500 。 前面说了，sack 报告的是已接收的不连续的块，在这个例子中，sack 块的内容为{Start:1501, End:3001},{Start:3501, End:4501}， 注意：这里的 End 不是接收到数据段最后的序列号，而是最后的序列号加 1。 产生确认的情况 确认机制 当接收方收到了按序到达（序号是所期望的）的报文段，那么接收方就累积发送确认报文段。 当具有所期望的序号的报文段到达，而前一个按序到达的报文段还没有被确认，那么接收方就要立即发送 ACK 报文段。 当序号比期望的序号还大的失序报文段到达时，接收方立即发送 ACK 报文段，并宣布下一个期望的报文段序号。这将导致对丢失报文段的快重传。 当一个丢失的报文段到达时，接收方要发送 ACK 报文段，并宣布下一个所期望的序号。 如果到达一个重复的报文段，接收方丢弃该报文段，但是应当立即发送确认，指出下一个期望的报文段。 收到 fin 报文的时候，立即回复确认。 3.重传机制关于重传的基本概念RTO 即超时重传时间RTT 数据包往返时间平均偏差是指单项测定值与平均值的偏差（取绝对值）之和，除以测定次数。可靠性的核心就是报文段的重传。在一个报文段发送时，它会被保存到一个队列中，直至被确认为止。当重传计时器超时，或者发送方收到该队列中第一个报文段的三个重复的 ACK 时，该报文段被重传。 超时重传的概念很简单，就是一定时间内未收到确认，进行再次发送，但是如何计算重传的时间确实 tcp 最复杂的问题之一，毕竟要适应各种网络情况。TCP 一个连接期间只有一个 RTO 计时器，目前大部分实现都是采用Jacobaon/Karels 算法，详细可以看RFC6298，其计算公式如下， rto 的计算公式：1234567891011第一次rtt计算： SRTT = RRTTVAR = R/2RTO = SRTT + max (G, K*RTTVAR)K = 4之后：RTTVAR = (1 - beta) * RTTVAR + beta * |SRTT - R&apos;|SRTT = (1 - alpha) * SRTT + alpha * R&apos;RTO = SRTT + max (G, K*RTTVAR)K = 4 SRTT(smoothed round-trip time)平滑 RTT 时间RTTVAR(round-trip time variation)RTT 变量，其实就是 rtt 平均偏差G 表示系统时钟的粒度，一般很小，us 级别。 beta = 1/4, alpha = 1/8 发送方 TCP 的计时器时间到，TCP 发送队列中最前面的报文段（即序列号最小的报文段），并重启计时器。","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"tcp","slug":"tcp","permalink":"http://wiki.brewlin.com/tags/tcp/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"3.传输层","slug":"net-protocol/3-传输层","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/"},{"name":"tcp","slug":"net-protocol/3-传输层/tcp","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/tcp/"}]},{"title":"udp协议","date":"2019-10-22T13:28:59.000Z","path":"wiki/net-protocol/3.传输层/udp/1.协议/","text":"udp协议udp协议 包体 源端口 源端口号 目的端口 目的端口号 长度 UDP 数据报的长度，包含首部，最小为 8 检验和 UDP 数据报的校验和，如果接收到检验和不正确的情况下，直接丢弃该报文。 计算校验和算法UDP 计算校验和的方法和 IP 数据报首部校验和的方法相似。不同的是：IP 数据报校验和只校验 IP 数据报的首部，但 UDP 的校验和是把首部和数据部分一起都检验。 UDP 的校验和需要计算 UDP 首部加数据荷载部分，但也需要加上 UDP 伪首部。这个伪首部指，源地址、目的地址、UDP 数据长度、协议类型（0x11），协议类型就一个字节，但需要补一个字节的 0x0，构成 12 个字节。伪首部+UDP 首部+数据一起计算校验和。 UDP 检验和的计算方法是：按每 16 位求和得出一个 32 位的数；如果这个 32 位的数，高 16 位不为 0，则高 16 位加低 16 位再得到一个 32 位的数；重复第 2 步直到高 16 位为 0，将低 16 位取反，得到校验和。","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"udp","slug":"udp","permalink":"http://wiki.brewlin.com/tags/udp/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"3.传输层","slug":"net-protocol/3-传输层","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/"},{"name":"udp","slug":"net-protocol/3-传输层/udp","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/udp/"}]},{"title":"tcp头部","date":"2019-10-22T13:28:59.000Z","path":"wiki/net-protocol/3.传输层/tcp/1.头部/","text":"[toc] 传输层 tcp 协议 实现 首部协议格式12345678910111213141516171819 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Source Port | Destination Port |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Sequence Number |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Acknowledgment Number |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Data | |U|A|P|R|S|F| || Offset| Reserved |R|C|S|S|Y|I| Window || | |G|K|H|T|N|N| |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Checksum | Urgent Pointer |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Options | Padding |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| data |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 源端口和目的端口各占 2 个字节，分别 tcp 连接的源端口和目的端口。关于端口的概念之前已经介绍过了。 序号占 4 字节，序号范围是[0，2^32 - 1]，共 2^32（即 4294967296）个序号。序号增加到 2^32-1 后，下一个序号就又回到 0。TCP 是面向字节流的，在一个 TCP 连接中传送的字节流中的每一个字节都按顺序编号。整个要传送的字节流的起始序号（ISN）必须在连接建立时设置。首部中的序号字段值则是指的是本报文段所发送的数据的第一个字节的序号。例如，一报文段的序号是 301，而接待的数据共有 100 字节。这就表明：本报文段的数据的第一个字节的序号是 301，最后一个字节的序号是 400。显然，下一个报文段（如果还有的话）的数据序号应当从 401 开始，即下一个报文段的序号字段值应为 401。 确认号占 4 字节，是期望收到对方下一个报文段的第一个数据字节的序号。例如，B 正确收到了 A 发送过来的一个报文段，其序号字段值是 501，而数据长度是 200 字节（序号 501~700），这表明 B 正确收到了 A 发送的到序号 700 为止的数据。因此，B 期望收到 A 的下一个数据序号是 701，于是 B 在发送给 A 的确认报文段中把确认号置为 701。注意，现在确认号不是 501，也不是 700，而是 701。总之：若确认号为 N，则表明：到序号 N-1 为止的所有数据都已正确收到。TCP 除了第一个 SYN 报文之外，所有 TCP 报文都需要携带 ACK 状态位。 数据偏移占 4 位，它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。这个字段实际上是指出 TCP 报文段的首部长度。由于首部中还有长度不确定的选项字段，因此数据偏移字段是必要的，但应注意，“数据偏移”的单位是 4 个字节，由于 4 位二进制数能表示的最大十进制数字是 15，因此数据偏移的最大值是 60 字节。 保留占 6 位，保留为今后使用，但目前应置为 0。 控制报文标志紧急URG（URGent）当 URG=1 时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快发送（相当于高优先级的数据），而不要按原来的排队顺序来传送。例如，已经发送了很长的一个程序要在远地的主机上运行。但后来发现了一些问题，需要取消该程序的运行，因此用户从键盘发出中断命令。如果不使用紧急数据，那么这两个字符将存储在接收 TCP 的缓存末尾。只有在所有的数据被处理完毕后这两个字符才被交付接收方的应用进程。这样做就浪费了很多时间。当 URG 置为 1 时，发送应用进程就告诉发送方的 TCP 有紧急数据要传送。于是发送方 TCP 就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍然是普通数据。这时要与首部中紧急指针（Urgent Pointer）字段配合使用。 确认ACK（ACKnowledgment）仅当 ACK=1 时确认号字段才有效，当 ACK=0 时确认号无效。TCP 规定，在连接建立后所有的传送的报文段都必须把 ACK 置为 1。 推送 PSH（PuSH）当两个应用进程进行交互式的通信时，有时在一端的应用进程希望在键入一个命令后立即就能收到对方的响应。在这种情况下，TCP 就可以使用推送（push）操作。这时，发送方 TCP 把 PSH 置为 1，并立即创建一个报文段发送出去。接收方 TCP 收到 PSH=1 的报文段，就尽快地交付接收应用进程。复位RST（ReSeT）当 RST=1 时，表名 TCP 连接中出现了严重错误（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立传输连接。RST 置为 1 用来拒绝一个非法的报文段或拒绝打开一个连接。 同步SYN（SYNchronization）在连接建立时用来同步序号。当 SYN=1 而 ACK=0 时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使 SYN=1 和 ACK=1，因此 SYN 置为 1 就表示这是一个连接请求或连接接受报文。 终止FIN（FINis，意思是“完”“终”）用来释放一个连接。当 FIN=1 时，表明此报文段的发送发的数据已发送完毕，并要求释放运输连接。 窗口占 2 字节，窗口值是[0，2^16-1]之间的整数。窗口指的是发送本报文段的一方的接受窗口（而不是自己的发送窗口）。窗口值告诉对方：从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量（以字节为单位）。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。总之，窗口值作为接收方让发送方设置其发送窗口的依据，作为流量控制的依据，后面会详细介绍。总之：窗口字段明确指出了现在允许对方发送的数据量。窗口值经常在动态变化。 检验和占 2 字节，检验和字段检验的范围包括首部和数据这两部分。和 UDP 用户数据报一样，在计算检验和时，要在 TCP 报文段的前面加上 12 字节的伪首部。伪首部的格式和 UDP 用户数据报的伪首部一样。但应把伪首部第 4 个字段中的 17 改为 6（TCP 的协议号是 6）；把第 5 字段中的 UDP 中的长度改为 TCP 长度。接收方收到此报文段后，仍要加上这个伪首部来计算检验和。若使用 IPv6，则相应的伪首部也要改变。 紧急指针占 2 字节，紧急指针仅在 URG=1 时才有意义，它指出本报文段中的紧急数据的字节数（紧急数据结束后就是普通数据) 。因此，在紧急指针指出了紧急数据的末尾在报文段中的位置。当所有紧急数据都处理完时，TCP 就告诉应用程序恢复到正常操作。值得注意的是，即使窗口为 0 时也可以发送紧急数据。 选项选项长度可变，最长可达 40 字节。当没有使用“选项”时，TCP 的首部长度是 20 字节。TCP 首部总长度由 TCP 头中的“数据偏移”字段决定，前面说了，最长偏移为 60 字节。那么“tcp 选项”的长度最大为 60-20=40 字节。 选项的一般结构体1234 1byte 1byte nbytes+--------+--------+------------------+ | Kind | Length | Info |+--------+--------+------------------+ TCP 最初只规定了一种选项，即最大报文段长度 MSS（Maximum Segment Szie）。后来又增加了几个选项如窗口扩大选项、时间戳选项等，下面说明常用的选项。 kind=0 是选项表结束选项。 kind=1 是空操作（nop）选项没有特殊含义，一般用于将 TCP 选项的总长度填充为 4 字节的整数倍，为啥需要 4 字节整数倍？因为前面讲了数据偏移字段的单位是 4 个字节。 kind=2 是最大报文段长度选项TCP 连接初始化时，通信双方使用该选项来协商最大报文段长度（Max Segment Size，MSS）。TCP 模块通常将 MSS 设置为（MTU-40）字节（减掉的这 40 字节包括 20 字节的 TCP 头部和 20 字节的 IP 头部）。这样携带 TCP 报文段的 IP 数据报的长度就不会超过 MTU（假设 TCP 头部和 IP 头部都不包含选项字段，并且这也是一般情况），从而避免本机发生 IP 分片。对以太网而言，MSS 值是 1460（1500-40）字节。 kind=3 是窗口扩大因子选项TCP 连接初始化时，通信双方使用该选项来协商接收通告窗口的扩大因子。在 TCP 的头部中，接收通告窗口大小是用 16 位表示的，故最大为 65535 字节，但实际上 TCP 模块允许的接收通告窗口大小远不止这个数（为了提高 TCP 通信的吞吐量）。窗口扩大因子解决了这个问题。假设 TCP 头部中的接收通告窗口大小是 N，窗口扩大因子（移位数）是 M，那么 TCP 报文段的实际接收通告窗口大小是 N 乘 2M，或者说 N 左移 M 位。注意，M 的取值范围是 0～14。 和 MSS 选项一样，窗口扩大因子选项只能出现在同步报文段中，否则将被忽略。但同步报文段本身不执行窗口扩大操作，即同步报文段头部的接收通告窗口大小就是该 TCP 报文段的实际接收通告窗口大小。当连接建立好之后，每个数据传输方向的窗口扩大因子就固定不变了。关于窗口扩大因子选项的细节，可参考标准文档 RFC 1323。 kind=4 是选择性确认（Selective Acknowledgment，SACK）选项TCP 通信时，如果某个 TCP 报文段丢失，则 TCP 模块会重传最后被确认的 TCP 报文段后续的所有报文段，这样原先已经正确传输的 TCP 报文段也可能重复发送，从而降低了 TCP 性能。SACK 技术正是为改善这种情况而产生的，它使 TCP 模块只重新发送丢失的 TCP 报文段，不用发送所有未被确认的 TCP 报文段。选择性确认选项用在连接初始化时，表示是否支持 SACK 技术。 kind=5 是 SACK 实际工作的选项该选项的参数告诉发送方本端已经收到并缓存的不连续的数据块，从而让发送端可以据此检查并重发丢失的数据块。每个块边沿（edge of block）参数包含一个 4 字节的序号。其中块左边沿表示不连续块的第一个数据的序号，而块右边沿则表示不连续块的最后一个数据的序号的下一个序号。这样一对参数（块左边沿和块右边沿）之间的数据是没有收到的。因为一个块信息占用 8 字节，所以 TCP 头部选项中实际上最多可以包含 4 个这样的不连续数据块（考虑选项类型和长度占用的 2 字节）。 kind=8 是时间戳选项该选项提供了较为准确的计算通信双方之间的回路时间（Round Trip Time，RTT）的方法，从而为 TCP 流量控制提供重要信息。 多种状态的标志发起连接时的报文状态在连接建立时用来同步序号。当 SYN=1 而 ACK=0 时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使 SYN=1 和 ACK=1，因此 SYN 置为 1 就表示这是一个连接请求或连接接受报文。 终端连接的报文状态用来释放一个连接。当 FIN=1 时，表明此报文段的发送发的数据已发送完毕，并要求释放运输连接。","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"tcp","slug":"tcp","permalink":"http://wiki.brewlin.com/tags/tcp/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"3.传输层","slug":"net-protocol/3-传输层","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/"},{"name":"tcp","slug":"net-protocol/3-传输层/tcp","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/tcp/"}]},{"title":"tcp流量控制","date":"2019-10-22T13:28:59.000Z","path":"wiki/net-protocol/3.传输层/tcp/2.流量控制/","text":"tcp 流量控制tcp是由丢包重传的机制的 那么如果服务端因为负载导致不能接受发送端的数据从而丢弃数据 发送端接受到ack确认为丢包后导致重传 然后服务端导致负载更加严重，从而一个劲的重发数据，对网络造成更大的伤害。于是就提出了拥塞控制，当拥塞发生的时候，要做自我牺牲，降低发送速率。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"tcp","slug":"tcp","permalink":"http://wiki.brewlin.com/tags/tcp/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"3.传输层","slug":"net-protocol/3-传输层","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/"},{"name":"tcp","slug":"net-protocol/3-传输层/tcp","permalink":"http://wiki.brewlin.com/categories/net-protocol/3-传输层/tcp/"}]},{"title":"websocket协议解析","date":"2019-10-21T13:28:59.000Z","path":"wiki/net-protocol/2.应用层/websocket/1.websocket协议解析/","text":"websocket 协议报文websocket协议也是基于tcp协议，和http不同的是，tcp接受的数据包为二进制帧，而http为字符串数据包。并且websocket协议在连接阶段会触发一个http请求进行websocket协议校验。校验成功后才会接管tcp通讯流程不会断开该http连接 1234567891011121314151617181920websocket 数据帧报文 0 1 2 3 4 0 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 +-+-+-+-+-------+-+-------------+-------------------------------+ |F|R|R|R| opcode|M| Payload len | Extended payload length | |I|S|S|S| (4) |A| (7) | (16/64) | |N|V|V|V| |S| | (if payload len==126/127) | | |1|2|3| |K| | | +-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - + | Extended payload length continued, if payload len == 127 | + - - - - - - - - - - - - - - - +-------------------------------+ | |Masking-key, if MASK set to 1 | +-------------------------------+-------------------------------+ | Masking-key (continued) | Payload Data | +-------------------------------- - - - - - - - - - - - - - - - + : Payload Data continued ... : + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + | Payload Data continued ... | +---------------------------------------------------------------+ WebSocket协议详解WebSocket 协议解决了浏览器和服务器之间的全双工通信问题。在 WebSocket 出现之前，浏览器如果需要从服务器及时获得更新，则需要不停的对服务器主动发起请求，也就是 Web 中常用的poll技术。这样的操作非常低效，这是因为每发起一次新的 HTTP 请求，就需要单独开启一个新的 TCP 链接，同时 HTTP 协议本身也是一种开销非常大的协议。为了解决这些问题，所以出现了 WebSocket 协议。WebSocket 使得浏览器和服务器之间能通过一个持久的 TCP 链接就能完成数据的双向通信。关于 WebSocket 的 RFC 提案，可以参看RFC6455。 WebSocket 和 HTTP 协议一般情况下都工作在浏览器中，但 WebSocket 是一种完全不同于 HTTP 的协议。尽管，浏览器需要通过 HTTP 协议的GET请求，将 HTTP 协议升级为 WebSocket 协议。升级的过程被称为握手(handshake)。当浏览器和服务器成功握手后，则可以开始根据 WebSocket 定义的通信帧格式开始通信了。像其他各种协议一样，WebSocket 协议的通信帧也分为控制数据帧和普通数据帧，前者用于控制 WebSocket 链接状态，后者用于承载数据。下面我们将一一分析 WebSocket 协议的握手过程以及通信帧格式。 一、websocket握手握手的过程也就是将HTTP协议升级为WebSocket协议的过程，握手开始首先由浏览器端发送一个GET请求，该请求的HTTP头部信息如下:12345678GET /chat HTTP/1.1Host: server.example.comUpgrade: websocketConnection: UpgradeSec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==Origin: http://example.comSec-WebSocket-Protcol: chat, superchatSec-WebSocket-Version: 13 当服务器端，成功验证了以上信息后，则会返回一个形如以下的响应：12345HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: UpgradeSec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo=Sec-WebSocket-Protocol: chat 可以看到，浏览器发送端HTTP请求中，增加了一些新端字段，其作用如下所示： Upgrade: 规定必需的字段，其值必需为 websocket, 如果不是则握手失败； Connection: 规定必需的字段，值必需为 Upgrade, 如果不是则握手失败；Sec-WebSocket-Key: 必需字段，一个随机的字符串；Sec-WebSocket-Protocol: 可选字段，可以用于标识应用层的协议；Sec-WebSocket-Version: 必需字段，代表了 WebSocket 协议版本，值必需是 13, 否则握手失败；返回端响应中，如果握手成功会返回状态码101的HTTP响应，同时其他字段说明如下： Upgrade: 规定必需的字段，其值必需为 websocket, 如果不是则握手失败； Connection: 规定必需的字段，值必需为 Upgrade, 如果不是则握手失败； Sec-WebSocket-Accept: 规定必需的字段，该字段的值是通过固定字符串258EAFA5-E914-47DA-95CA-C5AB0DC85B11加上请求中Sec-WebSocket-Key字段的值，然后再对其结果通过 SHA1 哈希算法求出的结果。 Sec-WebSocket-Protocol: 对应于请求中的 Sec-WebSocket-Protocol 字段；当浏览器和服务端成功握手后，就可以传递数据了，传送数据是按照WebSocket的数据格式生成的二、WebSocket协议数据帧数据帧的定义类似与TCP/IP的格式定义，具体看下图：123456789101112131415161718 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-------+-+-------------+-------------------------------+|F|R|R|R| opcode|M| Payload len | Extended payload length ||I|S|S|S| (4) |A| (7) | (16/64) ||N|V|V|V| |S| | (if payload len==126/127) || |1|2|3| |K| | |+-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - +| Extended payload length continued, if payload len == 127 |+ - - - - - - - - - - - - - - - +-------------------------------+| |Masking-key, if MASK set to 1 |+-------------------------------+-------------------------------+| Masking-key (continued) | Payload Data |+-------------------------------- - - - - - - - - - - - - - - - +: Payload Data continued ... :+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +| Payload Data continued ... |+---------------------------------------------------------------+ 以上这张图，一行代表32bit（位），也就是4bytes（字节），总体上包含两份，帧头部和数据内容。每个从WebSocket链接中接受到的数据帧，都要按照以上格式进行解析，这样才能知道该数据帧是用于控制的还是用于传送数据的，关于以上数据帧的各个比特位的解释如下： FIN:1bit,当该比特位值为%x0时，表示后面还有更多的数据帧，%x1时表示这是最后一个数据帧； RSV1,RSV2,RSV3:各占1个比特位。一般情况下全为0，当客户端、服务端协商采用WebSocket扩展时，这三个标识位可以非0，且值当含义由扩展进行定义，如果出现非0当值，且没有采用WebSocket扩展，则链接出错 opcode:4 bit,用于表明数据帧当类型，一共可以表示16种帧类型，如下所示： %x0:表示这是一个分片当帧，它属于前面帧当后续帧； %x1:表示该数据帧携带的数据类型是文本类型，且编码utf-8 %x2 : 表示携带的是二进制数据； %x3-7 : 保留未使用； %x8 : 表示该帧用于关闭 WebSocket 链接； %x9 : 表示该帧代表了 ping 操作； %xA : 表示该帧代表了 pong 回应； %xB-F : 保留未使用； MASK:1 bit,%x0表示数据帧没有经过掩码计算，而%x1则表示数据帧已经经过掩码计算，得到真正当数据需要解码，一般情况下，只有浏览器发送给服务端当数据帧才需要进行掩码计算； Payload len:7 bit,表示了数据帧携带当数据长度，7 bit 的值根据三种情况，帧的解析有所不同： %x0 - 7D : 也就是从 0 到 125，表示数据长度, 数据总长度也就是 7 bit 代表的长度； %x7E : 7 bit 的值是 126 时，则后续的 2 个字节（16 bit)表示的一个 16 位无符号数，这个数用来表示数据的长度； %x7F : 7 bit 的值是 127 时，则后续的 8 个字节（64 bit)表示的一个 64 位无符号数，这个数用来表示数据的长度； Masking-key: 32 bit, 表示了用于解码的 key，只有当 MASK 比特位的值为 %x1 是，才有该数据； Payload Data: 余下的比特位用于存储具体的数据；通过以上分析可以看出，WebSocket 协议数据帧的最大头部为 2 + 8 + 4 = 14 bytes 也就是 14 个字节。同时我们要实现 WebSocket 协议，最主要的工作就是实现对数据帧的解析。","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"websocket","slug":"websocket","permalink":"http://wiki.brewlin.com/tags/websocket/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"2.应用层","slug":"net-protocol/2-应用层","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/"},{"name":"websocket","slug":"net-protocol/2-应用层/websocket","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/websocket/"}]},{"title":"websocket实现","date":"2019-10-21T13:28:59.000Z","path":"wiki/net-protocol/2.应用层/websocket/3.websocket实现/","text":"编写基本的httpserver启动一个基本的httpserver，提供两个接口，一个index返回主页，另一个是就是我们自定义的websocket协议接口@main.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( \"fmt\" \"log\" \"github.com/brewlin/net-protocol/pkg/logging\" \"github.com/brewlin/net-protocol/protocol/application/http\" \"github.com/brewlin/net-protocol/protocol/application/websocket\")func init() &#123; logging.Setup()&#125;func main() &#123; serv := http.NewHTTP(\"tap1\", \"192.168.1.0/24\", \"192.168.1.1\", \"9502\") serv.HandleFunc(\"/ws\", echo) serv.HandleFunc(\"/\", func(request *http.Request, response *http.Response) &#123; response.End(\"hello\") &#125;) fmt.Println(\"@main: server is start ip:192.168.1.1 port:9502 \") serv.ListenAndServ()&#125;//websocket处理器func echo(r *http.Request, w *http.Response) &#123; fmt.Println(\"got http request ; start to upgrade websocket protocol....\") //协议升级 c *websocket.Conn c, err := websocket.Upgrade(r, w) if err != nil &#123; //升级协议失败，直接return 交由http处理响应 fmt.Println(\"Upgrade error:\", err) return &#125; defer c.Close() //循环处理数据，接受数据，然后返回 for &#123; message, err := c.ReadData() if err != nil &#123; log.Println(\"read:\", err) break &#125; fmt.Println(\"recv client msg:\", string(message)) // c.SendData(message ) c.SendData([]byte(\"hello\")) &#125;&#125; echo 接口接受http请求并进行升级我们的websocket页面如下 自定义的webscoket upgrade进行升级根据之前的协议分析，我知道握手的过程其实就是检查 HTTP 请求头部字段的过程，值得注意的一点就是需要针对客户端发送的 Sec-WebSocket-Key 生成一个正确的 Sec-WebSocket-Accept 只。关于生成的 Sec-WebSocket-Accpet 的实现，可以参考之前的分析。握手过程的具体代码如下：@upgrade.go1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package websocketimport( \"net/http\" \"net\" \"errors\" \"log\" \"bufio\")func Upgrade(w http.ResponseWriter,r *http.Request)(c *Conn,err error)&#123; //是否是Get方法 if r.Method != \"GET\" &#123; http.Error(w,http.StatusText(http.StatusMethodNotAllowed),http.StatusMethodNotAllowed) return nil,errors.New(\"websocket:method not GET\") &#125; //检查 Sec-WebSocket-Version 版本 if values := r.Header[\"Sec-Websocket-Version\"];len(values) == 0 || values[0] != \"13\" &#123; http.Error(w,http.StatusText(http.StatusBadRequest),http.StatusBadRequest) return nil,errors.New(\"websocket:version != 13\") &#125; //检查Connection 和 Upgrade if !tokenListContainsValue(r.Header,\"Connection\",\"upgrade\") &#123; http.Error(w,http.StatusText(http.StatusBadRequest),http.StatusBadRequest) return nil,errors.New(\"websocket:could not find connection header with token 'upgrade'\") &#125; if !tokenListContainsValue(r.Header,\"Upgrade\",\"websocket\") &#123; http.Error(w,http.StatusText(http.StatusBadRequest),http.StatusBadRequest) return nil,errors.New(\"websocket:could not find connection header with token 'websocket'\") &#125; //计算Sec-Websocket-Accept的值 challengeKey := r.Header.Get(\"Sec-Websocket-Key\") if challengeKey == \"\" &#123; http.Error(w,http.StatusText(http.StatusBadRequest),http.StatusBadRequest) return nil,errors.New(\"websocket:key missing or blank\") &#125; var ( netConn net.Conn br *bufio.Reader ) h,ok := w.(http.Hijacker) if !ok &#123; http.Error(w,http.StatusText(http.StatusInternalServerError),http.StatusInternalServerError) return nil,errors.New(\"websocket:response dose not implement http.Hijacker\") &#125; var rw *bufio.ReadWriter //接管当前tcp连接，阻止内置http接管连接 netConn,rw,err = h.Hijack() if err != nil &#123; http.Error(w,http.StatusText(http.StatusInternalServerError),http.StatusInternalServerError) return nil,err &#125; br = rw.Reader if br.Buffered() &gt; 0 &#123; netConn.Close() return nil,errors.New(\"websocket:client send data before hanshake is complete\") &#125; // 构造握手成功后返回的 response p := []byte&#123;&#125; p = append(p, \"HTTP/1.1 101 Switching Protocols\\r\\nUpgrade: websocket\\r\\nConnection: Upgrade\\r\\nSec-WebSocket-Accept: \"...) p = append(p, computeAcceptKey(challengeKey)...) p = append(p, \"\\r\\n\\r\\n\"...) //返回repson 但不关闭连接 if _,err = netConn.Write(p);err != nil &#123; netConn.Close() return nil,err &#125; //升级为websocket log.Println(\"Upgrade http to websocket successfully\") conn := newConn(netConn) return conn,nil&#125; 握手过程的代码比较直观，就不多做解释了。到这里 WebSocket 的实现就基本完成了，可以看到有了之前的各种约定，我们实现 WebSocket 协议也是比较简单的。封装的websocket结构体和对应的方法@conn.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168package websocketimport ( \"fmt\" \"encoding/binary\" \"log\" \"errors\" \"net\")const ( /* * 是否是最后一个数据帧 * Fin Rsv1 Rsv2 Rsv3 Opcode * 1 0 0 0 0 0 0 0 =&gt; 128 */ finalBit = 1 &lt;&lt; 7 /* * 是否需要掩码处理 * Mask payload-len 第一位mask表示是否需要进行掩码处理 后面 * 7位表示数据包长度 1.0-125 表示长度 2.126 后面需要扩展2 字节 16bit * 3.127则扩展8bit * 1 0 0 0 0 0 0 0 =&gt; 128 */ maskBit = 1 &lt;&lt; 7 /* * 文本帧类型 * 0 0 0 0 0 0 0 1 */ TextMessage = 1 /* * 关闭数据帧类型 * 0 0 0 0 1 0 0 0 */ CloseMessage = 8)//websocket 连接type Conn struct &#123; writeBuf []byte maskKey [4]byte conn net.Conn&#125;func newConn(conn net.Conn)*Conn&#123; return &amp;Conn&#123;conn:conn&#125;&#125;func (c *Conn)Close()&#123; c.conn.Close()&#125;//发送数据func (c *Conn)SendData(data []byte)&#123; length := len(data) c.writeBuf = make([]byte,10 + length) //数据开始和结束位置 payloadStart := 2 /** *数据帧的第一个字节，不支持且只能发送文本类型数据 *finalBit 1 0 0 0 0 0 0 0 * | *Text 0 0 0 0 0 0 0 1 * =&gt; 1 0 0 0 0 0 0 1 */ c.writeBuf[0] = byte(TextMessage) | finalBit fmt.Printf(\"1 bit:%b\\n\",c.writeBuf[0]) //数据帧第二个字节，服务器发送的数据不需要进行掩码处理 switch&#123; //大于2字节的长度 case length &gt;= 1 &lt;&lt; 16 ://65536 //c.writeBuf[1] = byte(0x00) | 127 // 127 c.writeBuf[1] = byte(127) // 127 //大端写入64位 binary.BigEndian.PutUint64(c.writeBuf[payloadStart:],uint64(length)) //需要8byte来存储数据长度 payloadStart += 8 case length &gt; 125: //c.writeBuf[1] = byte(0x00) | 126 c.writeBuf[1] = byte(126) binary.BigEndian.PutUint16(c.writeBuf[payloadStart:],uint16(length)) payloadStart += 2 default: //c.writeBuf[1] = byte(0x00) | byte(length) c.writeBuf[1] = byte(length) &#125; fmt.Printf(\"2 bit:%b\\n\",c.writeBuf[1]) copy(c.writeBuf[payloadStart:],data[:]) c.conn.Write(c.writeBuf[:payloadStart+length])&#125;//读取数据func (c *Conn)ReadData()(data []byte,err error)&#123; var b [8]byte //读取数据帧的前两个字节 if _,err := c.conn.Read(b[:2]); err != nil &#123; return nil,err &#125; //开始解析第一个字节 是否还有后续数据帧 final := b[0] &amp; finalBit != 0 fmt.Printf(\"read data 1 bit :%b\\n\",b[0]) //不支持数据分片 if !final &#123; log.Println(\"Recived fragemented frame,not support\") return nil,errors.New(\"not suppeort fragmented message\") &#125; //数据帧类型 /* *1 0 0 0 0 0 0 1 * &amp; *0 0 0 0 1 1 1 1 *0 0 0 0 0 0 0 1 * =&gt; 1 这样就可以直接获取到类型了 */ frameType := int(b[0] &amp; 0xf) //如果 关闭类型，则关闭连接 if frameType == CloseMessage &#123; c.conn.Close() log.Println(\"Recived closed message,connection will be closed\") return nil,errors.New(\"recived closed message\") &#125; //只实现了文本格式的传输,编码utf-8 if frameType != TextMessage &#123; return nil,errors.New(\"only support text message\") &#125; //检查数据帧是否被掩码处理 //maskBit =&gt; 1 0 0 0 0 0 0 0 任何与他 要么为0 要么为 128 mask := b[1] &amp; maskBit != 0 //数据长度 payloadLen := int64(b[1] &amp; 0x7F)//0 1 1 1 1 1 1 1 1 127 dataLen := int64(payloadLen) //根据payload length 判断数据的真实长度 switch payloadLen &#123; case 126://扩展2字节 if _,err := c.conn.Read(b[:2]);err != nil &#123; return nil,err &#125; //获取扩展二字节的真实数据长度 dataLen = int64(binary.BigEndian.Uint16(b[:2])) case 127 : if _,err := c.conn.Read(b[:8]);err != nil &#123; return nil,err &#125; dataLen = int64(binary.BigEndian.Uint64(b[:8])) &#125; log.Printf(\"Read data length :%d,payload length %d\",payloadLen,dataLen) //读取mask key if mask &#123;//如果需要掩码处理的话 需要取出key //maskKey 是 4 字节 32位 if _,err := c.conn.Read(c.maskKey[:]);err != nil &#123; return nil ,err &#125; &#125; //读取数据内容 p := make([]byte,dataLen) if _,err := c.conn.Read(p);err != nil &#123; return nil,err &#125; if mask &#123; maskBytes(c.maskKey,p)//进行解码 &#125; return p,nil&#125; http 头部检查12345678910111213141516171819202122232425262728293031323334353637import ( \"crypto/sha1\" \"encoding/base64\" \"strings\" \"net/http\")var KeyGUID = []byte(\"258EAFA5-E914-47DA-95CA-C5AB0DC85B11\")//握手阶段使用 加密key返回 进行握手func computeAcceptKey(challengeKey string)string&#123; h := sha1.New() h.Write([]byte(challengeKey)) h.Write(KeyGUID) return base64.StdEncoding.EncodeToString(h.Sum(nil))&#125;//解码func maskBytes(key [4]byte,b []byte)&#123; pos := 0 for i := range b &#123; b[i] ^= key[pos &amp; 3] pos ++ &#125;&#125;// 检查http 头部字段中是否包含指定的值func tokenListContainsValue(header http.Header, name string, value string)bool&#123; for _,v := range header[name] &#123; for _, s := range strings.Split(v,\",\")&#123; if strings.EqualFold(value,strings.TrimSpace(s)) &#123; return true &#125; &#125; &#125; return false&#125;","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"websocket","slug":"websocket","permalink":"http://wiki.brewlin.com/tags/websocket/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"2.应用层","slug":"net-protocol/2-应用层","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/"},{"name":"websocket","slug":"net-protocol/2-应用层/websocket","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/websocket/"}]},{"title":"websocket算法","date":"2019-10-21T13:28:59.000Z","path":"wiki/net-protocol/2.应用层/websocket/2.websocket算法/","text":"websocket协议中的一些算法在分析 WebSocket 协议握手过程和数据帧格式过程中，我们讲到了一些算法，下面我们讲解下具体实现。 Sec-WebSocket-Accept的计算方法从上面的分析中，我们知道字段的值是通过固定字符串258EAFA5-E914-47DA-95CA-C5AB0DC85B11加上请求中Sec-WebSocket-Key字段的值，然后再对其结果通过 SHA1 哈希算法求出的结果。可以通过以下 golang 代码实现：1234567var keyGUID = []byte(\"258EAFA5-E914-47DA-95CA-C5AB0DC85B11\")func computeAcceptKey(challengeKey string) string &#123; h := sha1.New() h.Write([]byte(challengeKey)) h.Write(keyGUID) return base64.StdEncoding.EncodeToString(h.Sum(nil))&#125; 掩码处理浏览器发送给服务器的数据帧是经过掩码处理的，那怎么样对数据进行解码呢？以下是来自RFC6455文档的解释具体的流程是：将传输的数据按字节 byte 处理，同时将 Masking-key 代表的值也按字节处理。假如 data-byte-i 代表的是数据的第 i 个字节，那么 j = i MOD 4，然后从Maksing-key中(一共有 4 个字节）取出第 j 个字节 mask-key-byte-j，然后将 data-byte-i 和 mask-key-byte-j 代表的字节进行异或操作，取得结果就是最终的结果。该操作可以用如下 golang 代码实现：1234567func maskBytes(key [4]byte,pos int,b[]byte)int&#123; for i := range b&#123; b[i] ^= key[pos &amp; 3] pos++ &#125; return pos &amp; 3&#125; 注意以上的操作，pos &amp; 3这里代表的操作是pos%4,因为 a % (2 ^ n) 等价于 a &amp; (2^n -1),在这里使用按位与操作更加高效","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"websocket","slug":"websocket","permalink":"http://wiki.brewlin.com/tags/websocket/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"2.应用层","slug":"net-protocol/2-应用层","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/"},{"name":"websocket","slug":"net-protocol/2-应用层/websocket","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/websocket/"}]},{"title":"http协议解析","date":"2019-10-18T13:28:59.000Z","path":"wiki/net-protocol/2.应用层/http/1.http协议解析/","text":"http协议报文这是一个典型的http请求的报文样例，可以看出是一个websocket升级前的http请求。该字符报文完全基于tcp协议，协议报文内容为tcp数据包，也就是tcp进行recv调用获取的数据内容。如下报文表示已经接受完http报文数据。 解析http报文的源码为application/http/request.go中123456789http 协议报文GET /chat HTTP/1.1Host: server.example.comUpgrade: websocketConnection: UpgradeSec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==Origin: http://example.comSec-WebSocket-Protcol: chat, superchatSec-WebSocket-Version: 13 @请求方法解析tcp数据包第一行数据，遇到空格就拆分，则获取到请求方法 @uri解析tcp数据包第一行数据，遇到空格就拆分，则获取到uri路径 @header头部接下来都是一些头部信息的keyvalue，每次读取一行，然后根据:分隔符进行拆分，获取header头部请求键值对","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"},{"name":"http","slug":"http","permalink":"http://wiki.brewlin.com/tags/http/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"2.应用层","slug":"net-protocol/2-应用层","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/"},{"name":"http","slug":"net-protocol/2-应用层/http","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/http/"}]},{"title":"应用层前世今生","date":"2019-10-17T13:28:59.000Z","path":"wiki/net-protocol/2.应用层/应用层前世今生/","text":"应用层的作用对传输层协议对再次封装，例如对tcp进行封装对http、websocket协议等，以及http3协议基于udp协议的封装等 http协议报文123456789http 协议报文GET /chat HTTP/1.1Host: server.example.comUpgrade: websocketConnection: UpgradeSec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==Origin: http://example.comSec-WebSocket-Protcol: chat, superchatSec-WebSocket-Version: 13 websocket 协议报文1234567891011121314151617181920websocket 数据帧报文 0 1 2 3 4 0 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 +-+-+-+-+-------+-+-------------+-------------------------------+ |F|R|R|R| opcode|M| Payload len | Extended payload length | |I|S|S|S| (4) |A| (7) | (16/64) | |N|V|V|V| |S| | (if payload len==126/127) | | |1|2|3| |K| | | +-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - + | Extended payload length continued, if payload len == 127 | + - - - - - - - - - - - - - - - +-------------------------------+ | |Masking-key, if MASK set to 1 | +-------------------------------+-------------------------------+ | Masking-key (continued) | Payload Data | +-------------------------------- - - - - - - - - - - - - - - - + : Payload Data continued ... : + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + | Payload Data continued ... | +---------------------------------------------------------------+","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"},{"name":"2.应用层","slug":"net-protocol/2-应用层","permalink":"http://wiki.brewlin.com/categories/net-protocol/2-应用层/"}]},{"title":"c扩展","date":"2018-12-15T13:28:59.000Z","path":"wiki/c-ext/index/","text":"基于c ，c ++ 封装php对象扩展@Lib所有的扩展对象均以Lib 命名空间为开头1namespace Lib; @env123supoort:&gt; php7.3.5&gt; php7.3.10 项目中对于协程相关底层实现参考 https://github.com/php-extension-research/study.git 实现，并在此之上做了一些重构，详情请关注原协程实现 @cgo()创建一个协程运行 @Lib/SharMem该扩展申请一块共享内存地址，提供php调用，用于多进程间共享数据 @Lib/Process该扩展初始化传入回调函数并创建子进程执行，子进程间可以通过channel通讯 @Lib/Timer提供定时任务和对于timer操作，基于epoll阻塞实现定时器，采用链表保存时间任务，有待提高性能 @Lib/Coroutine/Server提供携程化socket服务，监听tcp协议 @Lib/Coroutine/Socket@event显示声明异步事件模式 @Hook对原生php底层函数进行hook替换 @Lib/Thread/Pool线程池，可以在任何地方创建并投递后台任务进行处理 @Lib/Thread/Pool/Future投递任务给线程池处理后，可以阻塞获取对应的返回值","tags":[{"name":"c","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"c++","slug":"c","permalink":"http://wiki.brewlin.com/tags/c/"},{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"ext","slug":"ext","permalink":"http://wiki.brewlin.com/tags/ext/"}],"categories":[{"name":"c-ext","slug":"c-ext","permalink":"http://wiki.brewlin.com/categories/c-ext/"}]},{"title":"红黑树","date":"2018-12-10T13:28:59.000Z","path":"wiki/go-stl/tree/reds-black-tree/","text":"REB-BLACK TREE 红黑树 struct 需要提供 Less() Mor() Equal()等可以比较的方法，在红黑树add, remove,get 和 set 的时候会进行判断123456789101112131415type Node struct &#123; key interface&#123;&#125; value interface&#123;&#125; left *Node right *Node //default RED color bool&#125;type RBTree struct &#123; root *Node size int less func(a, b interface&#123;&#125;) bool more func(a, b interface&#123;&#125;) bool equal func(a, b interface&#123;&#125;) bool&#125; 提供的方法@key 接口实现 自定义的key需要实现 接口的三个可比较方法 Less() More() Equal()初始化 new 一个 红黑树1234567891011func Less(a, b interface&#123;&#125;) bool &#123; return a.(int) &lt; b.(int)&#125;func More(a, b interface&#123;&#125;) bool &#123; return a.(int) &gt; b.(int)&#125;func Equal(a, b interface&#123;&#125;) bool &#123; return a.(int) == b.(int)&#125;//初始化rbtree := rb.NewRBTree(less,more,equal) @Add()1234//add 添加节点for i:= 0 ; i &lt; 10 ; i++&#123; rbtree.Add(i,i)&#125; @Remove()1234//删除节点for i:= 0 ; i &lt; 10 ; i++&#123; rbtree.Remove(i)&#125; @Contains 是否存在1rbtree.Contains(key)//bool @IsEmpty()bool@GetSize()int@Set(key,value)bool 更新value","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"tree","slug":"tree","permalink":"http://wiki.brewlin.com/tags/tree/"},{"name":"red-black-tree","slug":"red-black-tree","permalink":"http://wiki.brewlin.com/tags/red-black-tree/"}],"categories":[{"name":"go-stl","slug":"go-stl","permalink":"http://wiki.brewlin.com/categories/go-stl/"},{"name":"tree","slug":"go-stl/tree","permalink":"http://wiki.brewlin.com/categories/go-stl/tree/"}]},{"title":"二分搜索树","date":"2018-12-08T13:28:59.000Z","path":"wiki/go-stl/tree/binary-search/","text":"简介二分搜索树,基础版的实现，用于展示，因为在多种情况下效率比较差，没有自平衡，会退化成链表等,建议使用红黑树，或者hash表等， @New\bBSTree12//NewBSTree return BSTreefunc NewBSTree() *BSTree @Size 获取大小12//Size get sizefunc (b BSTree) Size() int @Add 添加节点12//Add addfunc (b *BSTree) Add(e int) @Contains 检查是否存在1func (b BSTree) Contains(e int) bool @PreOrder 前中后序遍历1func (b BSTree) PreOrder() @LevelOrder 层序遍历1func (b BSTree) LevelOrder() @Min 最小节点12//mini get mini valuefunc (c BSTree) Min() int @Max 最大节点1func (c BSTree) Max() int @RemoveMin 去除最小的1func (c *BSTree) RemoveMin() int @RemoveMax 去除最大节点1func (c *BSTree) RemoveMax() int @Remove 去除节点1func (c *BSTree) Remove(e int)","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"tree","slug":"tree","permalink":"http://wiki.brewlin.com/tags/tree/"},{"name":"binary-tree","slug":"binary-tree","permalink":"http://wiki.brewlin.com/tags/binary-tree/"}],"categories":[{"name":"go-stl","slug":"go-stl","permalink":"http://wiki.brewlin.com/categories/go-stl/"},{"name":"tree","slug":"go-stl/tree","permalink":"http://wiki.brewlin.com/categories/go-stl/tree/"}]},{"title":"哈希Code生成","date":"2018-12-07T13:28:59.000Z","path":"wiki/go-stl/hash/hash_code/","text":"简介hashcode 采用map底层的hashcode 方式,提前源码重新封装实现,最大实现hashcode生产效率 源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147package hash// Copyright 2014 The Go Authors. All rights reserved.// Use of this source code is governed by a BSD-style// license that can be found in the LICENSE file.// Hashing algorithm inspired by// xxhash: https://code.google.com/p/xxhash/// cityhash: https://code.google.com/p/cityhash/// +build amd64 amd64p32 arm64 mips64 mips64le ppc64 ppc64le s390x wasmimport ( \"strings\" \"unsafe\")const ( // Constants for multiplication: four random odd 64-bit numbers. m1 = 16877499708836156737 m2 = 2820277070424839065 m3 = 9497967016996688599 m4 = 15839092249703872147)func add(p unsafe.Pointer, x uintptr) unsafe.Pointer &#123; return unsafe.Pointer(uintptr(p) + x)&#125;func readUnaligned32(p unsafe.Pointer) uint32 &#123; q := (*[4]byte)(p) return uint32(q[0]) + uint32(q[1])&lt;&lt;8 + uint32(q[2])&lt;&lt;16 + uint32(q[3])&lt;&lt;24&#125;func readUnaligned64(p unsafe.Pointer) uint64 &#123; q := (*[8]byte)(p) return uint64(q[0]) + uint64(q[1])&lt;&lt;8 + uint64(q[2])&lt;&lt;16 + uint64(q[3])&lt;&lt;24 + uint64(q[4])&lt;&lt;32 + uint64(q[5])&lt;&lt;40 + uint64(q[6])&lt;&lt;48 + uint64(q[7])&lt;&lt;56&#125;var hashkey [4]uintptrtype stringStruct struct &#123; str unsafe.Pointer len int&#125;//Strhash (r string)// return uintptr64func Strhash(r string) uintptr &#123; return memhash(unsafe.Pointer(&amp;r), 3, uintptr(strings.Count(r, \"\")-1))&#125;func memhash(p unsafe.Pointer, seed, s uintptr) uintptr &#123; hashkey[0] |= 1 // make sure these numbers are odd hashkey[1] |= 1 hashkey[2] |= 1 hashkey[3] |= 1 h := uint64(seed + s*hashkey[0])tail: switch &#123; case s == 0: case s &lt; 4: h ^= uint64(*(*byte)(p)) h ^= uint64(*(*byte)(add(p, s&gt;&gt;1))) &lt;&lt; 8 h ^= uint64(*(*byte)(add(p, s-1))) &lt;&lt; 16 h = rotl_31(h*m1) * m2 case s &lt;= 8: h ^= uint64(readUnaligned32(p)) h ^= uint64(readUnaligned32(add(p, s-4))) &lt;&lt; 32 h = rotl_31(h*m1) * m2 case s &lt;= 16: h ^= readUnaligned64(p) h = rotl_31(h*m1) * m2 h ^= readUnaligned64(add(p, s-8)) h = rotl_31(h*m1) * m2 case s &lt;= 32: h ^= readUnaligned64(p) h = rotl_31(h*m1) * m2 h ^= readUnaligned64(add(p, 8)) h = rotl_31(h*m1) * m2 h ^= readUnaligned64(add(p, s-16)) h = rotl_31(h*m1) * m2 h ^= readUnaligned64(add(p, s-8)) h = rotl_31(h*m1) * m2 default: v1 := h v2 := uint64(seed * hashkey[1]) v3 := uint64(seed * hashkey[2]) v4 := uint64(seed * hashkey[3]) for s &gt;= 32 &#123; v1 ^= readUnaligned64(p) v1 = rotl_31(v1*m1) * m2 p = add(p, 8) v2 ^= readUnaligned64(p) v2 = rotl_31(v2*m2) * m3 p = add(p, 8) v3 ^= readUnaligned64(p) v3 = rotl_31(v3*m3) * m4 p = add(p, 8) v4 ^= readUnaligned64(p) v4 = rotl_31(v4*m4) * m1 p = add(p, 8) s -= 32 &#125; h = v1 ^ v2 ^ v3 ^ v4 goto tail &#125; h ^= h &gt;&gt; 29 h *= m3 h ^= h &gt;&gt; 32 return uintptr(h)&#125;func memhash32(p unsafe.Pointer, seed uintptr) uintptr &#123; hashkey[0] |= 1 // make sure these numbers are odd hashkey[1] |= 1 hashkey[2] |= 1 hashkey[3] |= 1 h := uint64(seed + 4*hashkey[0]) v := uint64(readUnaligned32(p)) h ^= v h ^= v &lt;&lt; 32 h = rotl_31(h*m1) * m2 h ^= h &gt;&gt; 29 h *= m3 h ^= h &gt;&gt; 32 return uintptr(h)&#125;func memhash64(p unsafe.Pointer, seed uintptr) uintptr &#123; hashkey[0] |= 1 // make sure these numbers are odd hashkey[1] |= 1 hashkey[2] |= 1 hashkey[3] |= 1 h := uint64(seed + 8*hashkey[0]) h ^= uint64(readUnaligned32(p)) | uint64(readUnaligned32(add(p, 4)))&lt;&lt;32 h = rotl_31(h*m1) * m2 h ^= h &gt;&gt; 29 h *= m3 h ^= h &gt;&gt; 32 return uintptr(h)&#125;// Note: in order to get the compiler to issue rotl instructions, we// need to constant fold the shift amount by hand.// TODO: convince the compiler to issue rotl instructions after inlining.func rotl_31(x uint64) uint64 &#123; return (x &lt;&lt; 31) | (x &gt;&gt; (64 - 31))&#125;","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"hash","slug":"hash","permalink":"http://wiki.brewlin.com/tags/hash/"},{"name":"list","slug":"list","permalink":"http://wiki.brewlin.com/tags/list/"},{"name":"hashcode","slug":"hashcode","permalink":"http://wiki.brewlin.com/tags/hashcode/"}],"categories":[{"name":"go-stl","slug":"go-stl","permalink":"http://wiki.brewlin.com/categories/go-stl/"},{"name":"hash","slug":"go-stl/hash","permalink":"http://wiki.brewlin.com/categories/go-stl/hash/"}]},{"title":"哈希链表","date":"2018-12-07T13:28:59.000Z","path":"wiki/go-stl/hash/hash_list/","text":"简介基于链表桶的hash算法，hashcode 采用 map底层的hashcode方式生成 @源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package hashimport ( \"github.com/brewlin/go-stl/list/list\")type HashList struct &#123; capacity int b uint8 //bit buckets []*list.List&#125;func NewHashList(capacity int) *HashList &#123; var hash HashList hash.b = uint8(capacity) hash.capacity = capacity &lt;&lt; (hash.b - 1) bs := make([]*list.List, hash.capacity) for i := 0; i &lt; hash.capacity; i++ &#123; bs[i] = list.NewList(equal) &#125; hash.buckets = bs return &amp;hash&#125;func equal(a, b interface&#123;&#125;) bool &#123; return a.(string) == b.(string)&#125;func (h HashList) hashCode(key string) int &#123; hashcode := Strhash(key) m := uintptr(1)&lt;&lt;h.b - 1 return int(hashcode &amp; m)&#125;func (h HashList) Get(key string) interface&#123;&#125; &#123; list := h.buckets[h.hashCode(key)] return list.Find(key)&#125;func (h HashList) Set(key string, value interface&#123;&#125;) &#123; list := h.buckets[h.hashCode(key)] list.Update(key, value)&#125;func (h *HashList) Insert(key string, value interface&#123;&#125;) &#123; list := h.buckets[h.hashCode(key)] list.Insert(key, value)&#125;func (h *HashList) Remove(key string) &#123; list := h.buckets[h.hashCode(key)] list.Delete(key)&#125;``## @NewHashList 新建一个哈希链表传入的容量为hash桶默认数量```gofunc NewHashList(capacity int) *HashList &#123; @Set 更新该key值@Get 获取该key值对应的value@Insert 新增一个key-value@Remove 移除该key@Equal 判断是否相等","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"hash","slug":"hash","permalink":"http://wiki.brewlin.com/tags/hash/"},{"name":"list","slug":"list","permalink":"http://wiki.brewlin.com/tags/list/"}],"categories":[{"name":"go-stl","slug":"go-stl","permalink":"http://wiki.brewlin.com/categories/go-stl/"},{"name":"hash","slug":"go-stl/hash","permalink":"http://wiki.brewlin.com/categories/go-stl/hash/"}]},{"title":"图论算法","date":"2018-10-27T13:28:59.000Z","path":"wiki/go-stl/graph/图论/","text":"领接矩阵 和 领接表领接表适合表示稀疏图 sparse graph 领接矩阵适合表示稠密图 dense graph 稠密图 和完全图领接矩阵 领接表领接矩阵","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"}],"categories":[{"name":"go-stl","slug":"go-stl","permalink":"http://wiki.brewlin.com/categories/go-stl/"},{"name":"graph","slug":"go-stl/graph","permalink":"http://wiki.brewlin.com/categories/go-stl/graph/"}]},{"title":"raft分布式一致性原理(二)","date":"2018-10-26T13:28:59.000Z","path":"wiki/go-stl/raft/raft分布式一致性原理(二)/","text":"@1 选举此阶段为集群初始化，所有的节点都是FOLLOWER身份 进行事件循环 @fllower 身份 接受主节点心跳 接受投票选举 如果在超时时间里还没有处触发上面两个事件 则转换为 CANDIDATE 候选身份，作为新的候选人进行选举 @candidate 身份 开始选举，增加当前任期 term 投票给自己 广播rpc向所有节点发起选举投票 当前任期小于其他节点则转换为fllower节点等待心跳到来或者超时 当前依然为candidate 且 收到的投票大于 总结点1/2 则准换为 leader节点结束选举 监听广播的投票结果 收到心跳 说明选举失败退化为follwer节点 选举成功为leader 结束选举@leader 身份 广播所有节点心跳 和日志复制 睡眠等待下一次心跳发送 原则 性质 描述 选举安全原则（Election Safety） 一个任期（term）内最多允许有一个领导人被选上 领导人只增加原则（Leader Append-Only） 领导人永远不会覆盖或者删除自己的日志，它只会增加条目 日志匹配原则（Log Matching） 如果两个日志在相同的索引位置上的日志条目的任期号相同，那么我们就认为这个日志从头到这个索引位置之间的条目完全相同 领导人完全原则（Leader Completeness) 如果一个日志条目在一个给定任期内被提交，那么这个条目一定会出现在所有任期号更大的领导人中 状态机安全原则（State Machine Safety） 如果一个服务器已经将给定索引位置的日志条目应用到状态机中，则所有其他服务器不会在该索引位置应用不同的条目 @2日志复制只有当该日志同步到所有node才可以进行提交commited 到状态机state machine @状态机其实就是实际进行操作的区域，如果该服务是数据库，那么状态机就是实际执行命令储存的地方 当收到所有的节点回复可以提交到状态机后，然后leader节点进行提交，提交后在广播到其他节点，通知其他节点可以提交日志到状态机执行命令 到这里就算是成功提交了一条命令","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"raft","slug":"raft","permalink":"http://wiki.brewlin.com/tags/raft/"}],"categories":[{"name":"go-stl","slug":"go-stl","permalink":"http://wiki.brewlin.com/categories/go-stl/"},{"name":"raft","slug":"go-stl/raft","permalink":"http://wiki.brewlin.com/categories/go-stl/raft/"}]},{"title":"raft分布式一致性原理(一)","date":"2018-10-26T13:28:59.000Z","path":"wiki/go-stl/raft/raft分布式一致性原理(一)/","text":"raft分布式一致性原理无限循环选leader异常当启动所有server时，默认都是follower 此时没有leader角色，然后follower会转换成candidate 身份进行选取leader @选取leader失败导致的重复选取当所有的follower 都转换为candidate身份进行leader选举时，可能导致选取leader失败，那么会更新选举时间，进行下一次重新选举 此时就可能导致无限次选举 @随机定时器其实就是采用 150ms - 300ms之间 随机产生一个定时时间，此时默认同一时刻基本只有一个server会转换为candidate身份，解决了单次无法选举出leader的问题 @选举leader 限制候选人进行选举leader时发起并行请求投票 RPC 实现了这样的限制： RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。 总的来说 就是过滤掉那些日志比较落后的候选人节点 Raft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"raft","slug":"raft","permalink":"http://wiki.brewlin.com/tags/raft/"}],"categories":[{"name":"go-stl","slug":"go-stl","permalink":"http://wiki.brewlin.com/categories/go-stl/"},{"name":"raft","slug":"go-stl/raft","permalink":"http://wiki.brewlin.com/categories/go-stl/raft/"}]},{"title":"相关资料","date":"2018-10-26T13:28:59.000Z","path":"wiki/go-stl/raft/相关资料/","text":"参考资料动画演示 raft 协议http://thesecretlivesofdata.com/raft/ raft 比较好的bloghttp://oserror.com/distributed/implement-raft-with-golang-first/ http://blog.luoyuanhang.com/2018/02/02/raft-paper-in-zh-CN/ 相关原版英语论文http://people.csail.mit.edu/cowling/vr/vr-revisited.pdf","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"raft","slug":"raft","permalink":"http://wiki.brewlin.com/tags/raft/"}],"categories":[{"name":"go-stl","slug":"go-stl","permalink":"http://wiki.brewlin.com/categories/go-stl/"},{"name":"raft","slug":"go-stl/raft","permalink":"http://wiki.brewlin.com/categories/go-stl/raft/"}]},{"title":"并发压测对比","date":"2018-10-25T13:28:59.000Z","path":"wiki/im-cloud/1.前言/2.并发压测对比/","text":"im-cloud &lt;&gt; goim 分布式中间件并发压测对比系统环境 此次测试环境为 window8.1 启动 virtualbox虚拟机部署的ubuntu14 goim无需担心进程配置，im-cloud测试时候需要根据机器配置做更改worker进程和task进程最好和cpu核心数保持一致，太大会使性能大大降低 测评对象 goim im-cloud goim (bilibili出品，经过B站生产验证 百万级消息秒级推送) im-cloud（借鉴goim 使用swoole原生实现 经过自己验证。。。）硬件环境123CPU: 4 核cpuMEM: 2G 内存 System: Ubunutu 14.04 (64bit) 软件环境123456789单节点启动im-cloud: cloud(2 个worker进程 2个子进程) job( 2 个worker进程 2个task进程 1个子进程) logic(2个worker进程 2个task进程 1个子进程)goim : comet(单进程) job(单进程) logic(单进程) 评测结果1234567891011c : concurrent 并发请求n : number 总请求数-----------------------------------c:500 | n:2000 | n:5000 | n:20000im-cloud: 6300 6082 3815goim : 5377 5540 5894 -----------------------------------c:1000 | n:20000im-cloud: 5014goim : 5950 ----------------------------------- @Concurrent:500 @Number:2000 im-cloud 整体高达6300qps goim 整体高达 5300qps im-cloud123456789101112131415161718192021222324Server Software: swoole-http-serverServer Hostname: 127.0.0.1Server Port: 9600Concurrency Level: 500Time taken for tests: 0.321 secondsComplete requests: 2000Failed requests: 0Total transferred: 354000 bytesTotal body sent: 374000HTML transferred: 58000 bytesRequests per second: 6239.74 [#/sec] (mean)Time per request: 80.131 [ms] (mean)Time per request: 0.160 [ms] (mean, across all concurrent requests)Transfer rate: 1078.55 [Kbytes/sec] received 1139.48 kb/s sent 2218.03 kb/s totalConnection Times (ms) min mean[+/-sd] median maxConnect: 10 22 5.0 21 35Processing: 6 33 11.3 30 74Waiting: 4 25 10.1 24 68Total: 31 54 11.1 54 98 goim123456789101112131415161718192021222324Document Path: /goim/push/mids?mids=123&amp;operation=1000Document Length: 23 bytesConcurrency Level: 500Time taken for tests: 0.372 secondsComplete requests: 2000Failed requests: 0Total transferred: 292000 bytesTotal body sent: 356000HTML transferred: 46000 bytesRequests per second: 5377.91 [#/sec] (mean)Time per request: 92.973 [ms] (mean)Time per request: 0.186 [ms] (mean, across all concurrent requests)Transfer rate: 766.77 [Kbytes/sec] received 934.83 kb/s sent 1701.60 kb/s totalConnection Times (ms) min mean[+/-sd] median maxConnect: 0 14 11.8 11 46Processing: 17 65 27.7 62 149Waiting: 16 59 24.1 57 136Total: 31 79 22.0 75 162 @Concurrent:500 @Number:5000 5000的请求下 im-cloud高达6100qps im-cloud12345678910111213141516171819Server Software: swoole-http-serverServer Hostname: 127.0.0.1Server Port: 9600Document Path: /im/push/mids?mids=123&amp;operation=9&amp;msg=push_midsDocument Length: 29 bytesConcurrency Level: 500Time taken for tests: 0.822 secondsComplete requests: 5000Failed requests: 0Total transferred: 885000 bytesTotal body sent: 935000HTML transferred: 145000 bytesRequests per second: 6082.98 [#/sec] (mean)Time per request: 82.196 [ms] (mean)Time per request: 0.164 [ms] (mean, across all concurrent requests)Transfer rate: 1051.45 [Kbytes/sec] received 1110.86 kb/s sent 2162.31 kb/s total goim1234567891011121314151617181920212223Document Path: /goim/push/mids?mids=123&amp;operation=1000Document Length: 23 bytesConcurrency Level: 500Time taken for tests: 0.907 secondsComplete requests: 5000Failed requests: 0Total transferred: 730000 bytesTotal body sent: 890000HTML transferred: 115000 bytesRequests per second: 5514.84 [#/sec] (mean)Time per request: 90.664 [ms] (mean)Time per request: 0.181 [ms] (mean, across all concurrent requests)Transfer rate: 786.30 [Kbytes/sec] received 958.63 kb/s sent 1744.93 kb/s totalConnection Times (ms) min mean[+/-sd] median maxConnect: 0 18 13.4 16 54Processing: 20 64 25.0 63 143Waiting: 17 55 20.5 54 117Total: 35 82 21.3 80 161 @Concurrent:500 @Number:20000 请求20000 并发500 goim1234567891011121314151617181920212223Document Path: /goim/push/mids?mids=123&amp;operation=1000Document Length: 23 bytesConcurrency Level: 500Time taken for tests: 3.393 secondsComplete requests: 20000Failed requests: 0Total transferred: 2920000 bytesTotal body sent: 3560000HTML transferred: 460000 bytesRequests per second: 5894.30 [#/sec] (mean)Time per request: 84.828 [ms] (mean)Time per request: 0.170 [ms] (mean, across all concurrent requests)Transfer rate: 840.40 [Kbytes/sec] received 1024.60 kb/s sent 1864.99 kb/s totalConnection Times (ms) min mean[+/-sd] median maxConnect: 0 30 129.4 10 1025Processing: 10 50 19.2 47 128Waiting: 6 42 16.1 40 125Total: 16 80 131.8 60 1100 im-cloud12345678910111213141516171819Server Software: swoole-http-serverServer Hostname: 127.0.0.1Server Port: 9600Document Path: /im/push/mids?mids=123&amp;operation=9&amp;msg=push_midsDocument Length: 29 bytesConcurrency Level: 500Time taken for tests: 5.242 secondsComplete requests: 20000Failed requests: 0Total transferred: 3540000 bytesTotal body sent: 3740000HTML transferred: 580000 bytesRequests per second: 3815.33 [#/sec] (mean)Time per request: 131.050 [ms] (mean)Time per request: 0.262 [ms] (mean, across all concurrent requests)Transfer rate: 659.49 [Kbytes/sec] received 696.75 kb/s sent 1356.23 kb/s total @Concurrent:1000 @Number:20000 请求20000 并发1000 goim12345678910111213141516Document Path: /goim/push/mids?mids=123&amp;operation=1000Document Length: 23 bytesConcurrency Level: 1000Time taken for tests: 3.361 secondsComplete requests: 20000Failed requests: 0Total transferred: 2920000 bytesTotal body sent: 3560000HTML transferred: 460000 bytesRequests per second: 5950.20 [#/sec] (mean)Time per request: 168.061 [ms] (mean)Time per request: 0.168 [ms] (mean, across all concurrent requests)Transfer rate: 848.37 [Kbytes/sec] received 1034.31 kb/s sent 1882.68 kb/s total im-cloud1234567891011121314151617181920Server Software: swoole-http-serverServer Hostname: 127.0.0.1Server Port: 9600Document Path: /im/push/mids?mids=123&amp;operation=9&amp;msg=push_midsDocument Length: 29 bytesConcurrency Level: 500Time taken for tests: 3.988 secondsComplete requests: 20000Failed requests: 0Total transferred: 3540000 bytesTotal body sent: 3740000HTML transferred: 580000 bytesRequests per second: 5014.66 [#/sec] (mean)Time per request: 99.708 [ms] (mean)Time per request: 0.199 [ms] (mean, across all concurrent requests)Transfer rate: 866.79 [Kbytes/sec] received 915.76 kb/s sent 1782.56 kb/s total","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://wiki.brewlin.com/tags/rabbitmq/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"1.前言","slug":"im-cloud/1-前言","permalink":"http://wiki.brewlin.com/categories/im-cloud/1-前言/"}]},{"title":"im-cloud 分布式推送中间件","date":"2018-10-25T13:28:59.000Z","path":"wiki/im-cloud/index/","text":"基于原生 swoole 全协程化构建 im-cloud中间件，多节点扩容 https://github.com/brewlin/im-cloud 概述 基于swoole原生构建即时推送im分布式服务,不进行业务处理，单独作为中间件使用，可弹性扩充节点增加性能处理,业务demo:(todo) 高性能 水平扩容 分布式服务架构 接入服务治理 cloud 作为中心服务节点 grpc-server 节点，对外可以进行tcp、websocket 客户端进行长连接注册,可水平扩容至多个节点 并注册到服务中心 例如consul，每个cloud节点维护自己的客户端 job 节点作为消费节点 消费队列数据 然后进行grpc 和cloud服务进行通讯 进行 push push room broadcast,作为节点中间件，消费kafaka，rabbitmq。。。之类,可以通过配置切换消息队列类型 logic 节点 提供rest api接口，作为生产节点 和 grpc客户端,可写入队列作为生产者，也可以扩展自己的业务进行rpc直接调用center中心进行推送,客户端数据缓存至redis中，多个logic节点访问redis数据同步 cloud,job,logic 等节点可水平扩容多个节点增加并发处理 appm &amp; apps appm多进程版本(multi process coroutine) 测试和单元测试中 test version apps单进程全协程化server版本(single process coroutine) 分支apps 待官方实现http2协议,暂取消合并到master notice api 流程图im-cloud 连接流程图 im-cloud 数据流程图 im-cloud 业务流程 组件依赖 相关组件为纯swoole实现 @core (done) 核心架构@grpc (done) grpc包依赖 grpc-client连接池@discovery (done) 服务发现注册@process(done) 自定义进程管理器@redis(done) redis连接池@queue(done amqp,soon kafak) 消息队列连接池@memory(done)swoole 相关内存操作封装@task(done) 异步任务投递组件@cloud (test verion)@job (test version)@logic (test version)","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://wiki.brewlin.com/tags/rabbitmq/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"}]},{"title":"安装部署","date":"2018-10-25T13:28:59.000Z","path":"wiki/im-cloud/1.前言/1.安装部署/","text":"im-cloud 分布式中间件的安装部署 github:http://github.com/brewlin/im-cloud im-cloud 基于swoole 原生协程构建分布式推送中间件 im-cloud 分布式中间件的安装部署 im-cloud &lt;&gt; goim 分布式中间件并发压测对比 im-cloud分布式中间件分析(一)-通讯协议 im-cloud分布式中间件分析(二)-cloud节点实现 im-cloud分布式中间件分析(三)-job节点实现 im-cloud分布式中间件分析(四)-logic节点实现 安装方式主要提供 docker单节点部署 docker-compose自动化编排部署 手动部署 三种方式部署环境 一、docker部署 基础镜像足够小 不用担心 base image+php7.2+swoole 4 才75M docker-compose networknamespace 为host模式，所以需要注意本地端口冲突的问题,也可以根据自己的环境更改compose.yml配置 1.docker 单独部署 镜像 consul redis 多进程版本镜像 brewlin/cloud-m brewlin/job-m brewlin/logic-m 单进程协程版镜像 brewlin/cloud-s brewlin/job-s brewlin/logic-s 启动consul 1docker run --network host consul 启动redis 1docker run --network host redis 启动cloud节点 123docker run --network host brewlin/cloud-mordocker run --network host brewlin/cloud-s 启动job节点 123docker run --network host brewlin/job-mordocker run --network host brewlin/job-s 启动logic节点 123docker run --network host brewlin/logic-mordocker run --network host brewlin/logic-s 2.docker-compose 编排服务1234git clone http://github.com/brewlin/im-cloudcd im-cloud//默认多进程版本docker-compose up 二、手动部署help process status 环境要求 swoole 4 + php 7.2 + console rabbitmq redis1.安装依赖make脚本使用composer自动install相关组件12cd path/im-cloudmake install 2.启动cloud节点12cd path/im-cloud/app/cloudphp bin/app --start --d --log=true --debug 3.启动logic节点12cd path/im-cloud/app/logic;php bin/app --start --d --log=true --debug 4.启动job节点12cd path/im-cloud/app/job;php bin/app --start --d --log=true --debug @makefile自动工具1234cd im-cloud;make startmake stopmake restart 5.安装启动consul1docker run --network -d consul 6.安装rabbitmq1docker run --network -d rabbitmq 三、测试 1.使用js sdk 提供的demo 注册到cloud 2.post http://host:9600/im/push/mids?mids=123&amp;operation=9&amp;msg=pushtest 进行单点推送","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://wiki.brewlin.com/tags/rabbitmq/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"1.前言","slug":"im-cloud/1-前言","permalink":"http://wiki.brewlin.com/categories/im-cloud/1-前言/"}]},{"title":"cloud节点实现","date":"2018-10-25T13:28:59.000Z","path":"wiki/im-cloud/5.相关实现/1.底层实现/3.cloud节点/","text":"im-cloud分布式中间件分析-cloud节点实现1.概述 cloud 节点对外提供websocket、tcp client 注册。并维护每个连接对应的客户端信息。作为Grpc server，接受grpc推送数据，并推送到client端 数据流程图 2.@Grpc server grpc server 基于swoole 的http2协议，然后通过config/router.php 配置项注册路由既可以使用如rest模式下的交互流程 grpc 路由注册 配置文件 config/router.php1234567&lt;?php//Grpc server routerHttpRouter::post('/im.cloud.Cloud/Ping', '/Grpc/Cloud/ping');HttpRouter::post('/im.cloud.Cloud/Close', '/Grpc/Cloud/close');HttpRouter::post('/im.cloud.Cloud/PushMsg', '/Grpc/Cloud/pushMsg');HttpRouter::post('/im.cloud.Cloud/Broadcast', '/Grpc/Cloud/broadcast');HttpRouter::post('/im.cloud.Cloud/Rooms', '/Grpc/Cloud/rooms'); 和rest 路由一样只需要注册路由到对应的方法即可，当使用grpc-client进行请求时，就能分发到最远的控制器去， grpc 参数解析 当接收到请求后，可以根据协程上下文获取当前连接的请求参数，grpc传输的协议是二进制，所以不能通过get，post方法直接获得对应的参数，需要采用grpc提供的方法进行解包1234567891011use Grpc\\Parser;use Core\\Context\\Context;public function pushMsg()&#123; $rawbody = Context::get()-&gt;getRequest()-&gt;getRawBody(); /** @var PushMsgReq $pushMsgReq */ $pushMsgReq = Parser::deserializeMessage( [PushMsgReq::class,null], $rawbody );&#125; 获取请求参数可以通过协程上下文获取 Context::get()-&gt;getRequest()-&gt;getRawBody(); request()-&gt;getRawBody(); Grpc\\Parser 方法使用的是 swoole\\grpc-client 组件包提供的方法，使用swoole对原生grpc 进行了封装3.@websocket server 基于websocket 协议注册到cloud节点，cloud 进行认证，通过grpc将注册信息传递到logic统一管理，认证成功后cloud节点将保存改连接的基础信息 握手阶段 命名空间：App/Websocket/HandshakeListener.class 该事件为swoole 监听事件，所以需要注册监听回调函数,配置文件为config/event.php1234567use \\Core\\Swoole\\SwooleEvent;use \\App\\Websocket\\HandshakeListener;return [ //websocket握手事件 SwooleEvent::HANDSHAKE =&gt; new HandshakeListener(),]; 接下来是握手流程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * token check &apos;&#123;&quot;mid&quot;:123, &quot;room_id&quot;:&quot;live://1000&quot;, &quot;platform&quot;:&quot;web&quot;, &quot;accepts&quot;:[1000,1001,1002]&#125;&apos; * @param Request $request * @param Response $response * @return bool */public function onHandshake(Request $request, Response $response): bool&#123; $httpRequest = HttpRequest::new($request); //握手失败 if($httpRequest-&gt;getUriPath() != self::upgradeUrl)&#123; $response-&gt;end(); return false; &#125; // websocket握手连接算法验证 $secWebSocketKey = $request-&gt;header[&apos;sec-websocket-key&apos;]; $patten = &apos;#^[+/0-9A-Za-z]&#123;21&#125;[AQgw]==$#&apos;; if (0 === preg_match($patten, $secWebSocketKey) || 16 !== strlen(base64_decode($secWebSocketKey))) &#123; $response-&gt;end(); return false; &#125; $key = base64_encode(sha1( $request-&gt;header[&apos;sec-websocket-key&apos;] . &apos;258EAFA5-E914-47DA-95CA-C5AB0DC85B11&apos;, true )); $headers = [ &apos;Upgrade&apos; =&gt; &apos;websocket&apos;, &apos;Connection&apos; =&gt; &apos;Upgrade&apos;, &apos;Sec-WebSocket-Accept&apos; =&gt; $key, &apos;Sec-WebSocket-Version&apos; =&gt; &apos;13&apos;, ]; // WebSocket connection to &apos;ws://127.0.0.1:9502/&apos; // failed: Error during WebSocket handshake: // Response must not include &apos;Sec-WebSocket-Protocol&apos; header if not present in request: websocket if (isset($request-&gt;header[&apos;sec-websocket-protocol&apos;])) &#123; $headers[&apos;Sec-WebSocket-Protocol&apos;] = $request-&gt;header[&apos;sec-websocket-protocol&apos;]; &#125; foreach ($headers as $key =&gt; $val) &#123; $response-&gt;header($key, $val); &#125; $response-&gt;status(101); $response-&gt;end(); return true;&#125; 该方法在握手阶段对于http请求进行校验，如果路径不为 ‘/sub’ 则认证失败关闭连接，成功后校验websocekt协议并升级为websocket， 主事件处理 同样需要注册websocket的onmessage事件 配置文件:config/envent.php @step1 解包 使用 App\\Packet\\Packet::class 进行解包，通讯协议为二进制传输，会有单独一章分析im-cloud通讯协议的设计 @step2 处理分发(注册) 根据协议，如果为注册请求，则进行注册流程，心跳则进行心跳流程im-cloud暂时不支持双向推送，也就是该连接不支持接受推送消息，推送请走logic节点push @step3 注册 1.进行auth参数校验 2.通过grpc 注册到logic节点 123456789101112$server = LogicClient::getLogicClient();if(empty($server)) throw new \\Exception(\"not find any logic node\");$connectReq = new ConnectReq();/** @var \\Im\\Logic\\LogicClient $rpcClient */$rpcClient = null;$serverId = env(\"APP_HOST\",\"127.0.0.1\").\":\".env(\"GRPC_PORT\",9500);$connectReq-&gt;setServer($serverId);$connectReq-&gt;setCookie(\"\");$connectReq-&gt;setToken(json_encode($data));/** @var ConnectReply $rpy */$rpy = GrpcLogicClient::Connect($server,$connectReq)[0]; 3.注册成功后将当前用户信息 写入bucket进程，独立维护所有的用户信息和连接 1234[$mid,$key,$roomId,$accepts,$heartbeat] = $this-&gt;registerLogic($body);/** @var Task $task */\\bean(Task::class)-&gt;deliver(Bucket::class,&quot;put&quot;,[$roomId,$key,$fd]); 4.@tcp server tcp 处理流程和websocket大致相似，走同样的流程,只是监听对应的api有些区别 5.自定义进程cloud节点 默认启动了两个自定义进程伴随swoole启动而启动 discoveryProcess 注册发现进程 该进程 在启动时注册到 注册中心(默认consul，可以扩展其他的注册中心),然后进行事件轮训，获取健康状态的实例节点 配置文件 config/process.php 注册进程到进程管理器 config/consul.php 配置发现中心的配置 获取到实例节点后 更新swoole所有的worker进程里的实例节点信息使用sendMessage()进行进程间通信123456789101112131415161718192021222324/*** 自定义子进程 执行入口* @param Process $process*/public function run(Process $process)&#123; provider()-&gt;select()-&gt;registerService(); $config = config(\"discovery\"); $discovery = $config[\"consul\"][\"discovery\"][\"name\"]; while (true)&#123; $services = provider()-&gt;select()-&gt;getServiceList($discovery); if(empty($services))&#123; CLog::error(\"not find any instance node:$discovery\"); goto SLEEP; &#125; for($i = 0; $i &lt; (int)env(\"WORKER_NUM\",4);$i++) &#123; //将可以用的服务同步到所有的worker进程 Cloud::server()-&gt;getSwooleServer()-&gt;sendMessage($services,$i); &#125;SLEEP: sleep(10); &#125;&#125; bucketProcess 用户缓存池 配置文件 config/process.php 注册该进程 该进程两个任务: 1 注册成功后缓存用户信息，管理用户连接 123456//step 1[$mid,$key,$roomId,$accepts,$heartbeat] = $this-&gt;registerLogic($body);//step 2/** @var Task $task */\\bean(Task::class)-&gt;deliver(Bucket::class,\"put\",[$roomId,$key,$fd]);使用deliver进程间通信，发送到bucketProcess进程处理 2.作为主要的推送进程 当cloud节点grpcserver 接收到推送请求，则创建一个协程写入bucketprocess进程，当前进程消费管道里的数据，每个数据创建一个协程，处理推送问题 3.使用自定义进程管理用户信息的选择 12出版采用的redis缓存用户信息，在实际压测的时候发现即使是redis缓存还是会影响并发处理。导致慢了4-5倍，而采用自定义进程处理的好处有如下两点，多进程下对数据不需要加锁。针对每个请求单独创建一个协程反而效率要高些 5.监听事件，生命周期管理 swoole 相关生命周期执行管理都依赖监听事件，例如 进程启动 请求事件 握手连接 关闭连接 等等。。123456789101112131415161718192021222324252627282930313233343536/** * set event to base swoole * 给swoole 设置基础的监听事件， */use \\Core\\Swoole\\SwooleEvent;use \\App\\Event\\PipeMessageListener;use \\App\\Event\\WorkerStopListener;use \\App\\Event\\ShutdownListener;use \\App\\Websocket\\MessageListener;use \\App\\Websocket\\HandshakeListener;use App\\Tcp\\ReceiveListener;use App\\Event\\OnCloseListener;use App\\Event\\WorkerStartListener;return [ //监听onpipmessage事件 SwooleEvent::PIPE_MESSAGE =&gt; new PipeMessageListener(), //监听进程启动事件 SwooleEvent::WORKER_START =&gt; new WorkerStartListener(), //监听进程关闭事件 SwooleEvent::WORKER_STOP =&gt; new WorkerStopListener(), SwooleEvent::SHUTDOWN =&gt; new ShutdownListener(), //监听tcp事件 SwooleEvent::RECEIVE =&gt; new ReceiveListener(), //监听websocket 事件 SwooleEvent::MESSAGE =&gt; new MessageListener(), //websocket握手事件 SwooleEvent::HANDSHAKE =&gt; new HandshakeListener(), //server监听关闭连接事件然后grpc通知logic销毁连接信息 SwooleEvent::CLOSE =&gt; new OnCloseListener(),];","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://wiki.brewlin.com/tags/rabbitmq/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"5.相关实现","slug":"im-cloud/5-相关实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/"},{"name":"1.底层实现","slug":"im-cloud/5-相关实现/1-底层实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/1-底层实现/"}]},{"title":"logic节点实现","date":"2018-10-25T13:28:59.000Z","path":"wiki/im-cloud/5.相关实现/1.底层实现/5.logic节点/","text":"im-cloud分布式中间件分析-logic节点实现1.概述 logic 节点 作为生产者和client端，作为业务节点，提供push推送resetapi接口，可以扩容多个节点做nginx负载均衡 2.@Producer 默认启动10个消息队列连接池，在task进程为每个人物创建协程异步生产任务 异步task任务直接调用组件task接口进行投递到task进程执行，task投递为非阻塞操作，执行完毕会直接返回，大大的提升了worker处理并发请求的能力，唯一的影响是，如果多个task进程的消费能力更不上worker的投递速度也会影响worker的处理能力，所以需要做取舍 具体的消息队列生成在task进程中执行 task进程启用了协程模式，投递的每个任务都默认创建一个协程 12345use Task\\Task;/*** @var LogicPush*/Task::deliver(LogicPush::class,&quot;pushMids&quot;,[(int)$arg[&quot;op&quot;],$arg[&quot;mids&quot;],$arg[&quot;msg&quot;]]); 相关异步任务 存放在命名空间App\\Task下 相关优化容器化单个请求流程执行的生命周期会调用生成多个对象，多达10多个。并发大的情况下GC 几乎会首先挂掉，而且会耗时等待，所以new对象也有优化的空间 项目在初始化也就是主进程启动期间就扫描相关代码，有注解的就进行收集，然后实例化到容器container中，以后再多次使用的时候直接复用代码，而无需多次new对象，大大节省空间和时间，如下图为创建一个协程去执行任务，相关的对象都从容器中获取1234567891011121314Co::create(function ()use($op,$mids,$msg)&#123; /** @var RedisDao $servers */ $servers = \\container()-&gt;get(RedisDao::class)-&gt;getKeysByMids($mids); $keys = []; foreach($servers as $key =&gt; $server)&#123; $keys[$server][] = $key; &#125; foreach($keys as $server =&gt; $key)&#123; //丢到队列里去操做，让job去处理 \\container()-&gt;get(QueueDao::class)-&gt;pushMsg($op,$server,$key,$msg); &#125;&#125;,true);//第二个参数为true 表示使用Context::waitGroup() 等待任务执行完成 如上图所示可以调用组件提供的多个方法获取容器对象 container()-&gt;get(class) bean(class) 两种都可以获取容器对象， 提高并发性能即使将主要的耗时任务放到task进程中执行，worker进程中依然会有少量的等待时间，现在采取的方式，是请求到来时获取数据后，直接回复结束当前连接，然后在继续执行任务，这样就不用等到投递task任务后再结束当前连接，大大提高并发能力，虽然可能耗时性能没有发生太大的改变，但是并发能力大大的提升。如下所示： 123456789101112131415161718192021/** * @return \\Core\\Http\\Response\\Response|static */public function mids()&#123; Context::get()-&gt;getResponse()-&gt;end(); $post = Context::get()-&gt;getRequest()-&gt;input(); if(empty($post[&quot;operation&quot;]) || empty($post[&quot;mids&quot;]) ||empty($post[&quot;msg&quot;]))&#123; return $this-&gt;error(&quot;缺少参数&quot;); &#125; $arg = [ &quot;op&quot; =&gt; $post[&quot;operation&quot;], &quot;mids&quot; =&gt; is_array($post[&quot;mids&quot;])?$post[&quot;mids&quot;]:[$post[&quot;mids&quot;]], &quot;msg&quot; =&gt; $post[&quot;msg&quot;] ]; Log::debug(&quot;push mids post data:&quot;.json_encode($arg)); /** * @var LogicPush */ Task::deliver(LogicPush::class,&quot;pushMids&quot;,[(int)$arg[&quot;op&quot;],$arg[&quot;mids&quot;],$arg[&quot;msg&quot;]]);&#125; 如上图直接使用Context::get()-&gt;getResponse()-&gt;end();通过协程上下文获取reponse对象直接结束当前连接，然后在继续执行当前任务，并释放内存","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://wiki.brewlin.com/tags/rabbitmq/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"5.相关实现","slug":"im-cloud/5-相关实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/"},{"name":"1.底层实现","slug":"im-cloud/5-相关实现/1-底层实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/1-底层实现/"}]},{"title":"job节点实现","date":"2018-10-25T13:28:59.000Z","path":"wiki/im-cloud/5.相关实现/1.底层实现/4.job节点/","text":"im-cloud分布式中间件分析-job节点实现1.概述 job 节点 作为消费端，消费logic生产的数据，然后通过grpc推送至cloud节点，cloud点真正处理客户端数据，job节点默认多进程消费启动4个worker进程，以及默认10个grpc连接池 数据流程图 2.@Consumer 消费中心 默认启动4个worker进程消费logic请求，耗时处理投放至task进程处理，并转发至cloud节点 监听worker启动事件需要在config/queue.php ,config/event.php 注册相应的事件和相关配置123456789101112131415161718use App\\Consumer\\Consumer;use Core\\App;use Core\\Swoole\\WorkerStartInterface;use Swoole\\Server as SwooleServer;class WorkerStartListener implements WorkerStartInterface&#123; const INIT_LOGIC = 1; public function onWorkerStart(SwooleServer $server, int $workerId): void &#123; if(App::isWorkerStatus())&#123; //启动的n个 worker进程 分别作为消费者进程消费，每个进程会直接阻塞直到消费到数据 consumer()-&gt;consume(new Consumer()); &#125; &#125;&#125; 消费主流程 1.为每个消费数据请求建立一个协程，处理相关数据 2.将每个数据投递至worker进程进行真正的grpc与cloud推送请求 12345678Co::create(function()use($data)&#123; if(empty(CloudClient::$table-&gt;getAllInstance()))&#123; Log::error(&quot;cancle task deliver discovery cloud node is empty&quot;); return; &#125; Task::deliver(Job::class,&quot;push&quot;,[$data]);&#125;,false);return Result::ACK; 3.通过以上做法能加快并发是消费速度，task进程也进行协程处理，增加并行处理能力，如果task进程阻塞也会造成task任务投递阻塞，所以在worker进程也需要加一个协程处理","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://wiki.brewlin.com/tags/rabbitmq/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"5.相关实现","slug":"im-cloud/5-相关实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/"},{"name":"1.底层实现","slug":"im-cloud/5-相关实现/1-底层实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/1-底层实现/"}]},{"title":"通讯协议","date":"2018-10-25T13:28:59.000Z","path":"wiki/im-cloud/5.相关实现/1.底层实现/2.通讯协议/","text":"通讯协议@heartbeat 心跳注意心跳是10s间隔，如果20s还未收到心跳则断开连接","tags":[{"name":"php","slug":"php","permalink":"http://wiki.brewlin.com/tags/php/"},{"name":"swoole","slug":"swoole","permalink":"http://wiki.brewlin.com/tags/swoole/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://wiki.brewlin.com/tags/rabbitmq/"}],"categories":[{"name":"im-cloud","slug":"im-cloud","permalink":"http://wiki.brewlin.com/categories/im-cloud/"},{"name":"5.相关实现","slug":"im-cloud/5-相关实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/"},{"name":"1.底层实现","slug":"im-cloud/5-相关实现/1-底层实现","permalink":"http://wiki.brewlin.com/categories/im-cloud/5-相关实现/1-底层实现/"}]},{"title":"字典树","date":"2018-10-24T13:28:59.000Z","path":"wiki/go-stl/trie/trie/","text":"简介字典树是一种对字符串统计效率非常高的一种算法，当前字典树基于红黑树实现 @NewTrie12345import ( \"github.com/brewlin/go-stl/trie\")trie := trie.NewTrie() @Add 加入字典树12//func (t *Trie) Add(word string) trie.Add(\"test\") @Contains 查询字符串是否存在12//func (t Trie) Contains(word string) boolflag := trie.Contains(\"test\")//true @IsPrefix 查询是否是前缀12// func (t Trie) IsPrefix(pre string) booltrie.Isprefix(\"te\")//test =&gt; true","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"tree","slug":"tree","permalink":"http://wiki.brewlin.com/tags/tree/"},{"name":"trie","slug":"trie","permalink":"http://wiki.brewlin.com/tags/trie/"}],"categories":[{"name":"go-stl","slug":"go-stl","permalink":"http://wiki.brewlin.com/categories/go-stl/"},{"name":"trie","slug":"go-stl/trie","permalink":"http://wiki.brewlin.com/categories/go-stl/trie/"}]},{"title":"index","date":"2018-10-24T13:28:59.000Z","path":"wiki/net-protocol/index/","text":"net-protocolhttps://github.com/brewlin/net-protocol基于go 实现链路层、网络层、传输层、应用层 网络协议栈 ，使用虚拟网卡实现 @demo1相关demo以及协议测试在cmd目录下 cd ./cmd/* @application 应用层 http websocket dns @transport 传输层 tcp udp port 端口机制 @network 网络层 icmp ipv4 ipv6 @link 链路层 arp ethernet @物理层 tun tap 虚拟网卡的实现 @客户端发起客户端请求 http client websocket client tcp client udp client dns client协议相关构体 1.应用层相关协议应用层暂时只实现了http、websocket、dns等协议。都基于tcp、对tcp等进行二次封装 http protocol:123456789http 协议报文GET /chat HTTP/1.1Host: server.example.comUpgrade: websocketConnection: UpgradeSec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==Origin: http://example.comSec-WebSocket-Protcol: chat, superchatSec-WebSocket-Version: 13 websocket protocol:1234567891011121314151617181920websocket 数据帧报文 0 1 2 3 4 0 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 +-+-+-+-+-------+-+-------------+-------------------------------+ |F|R|R|R| opcode|M| Payload len | Extended payload length | |I|S|S|S| (4) |A| (7) | (16/64) | |N|V|V|V| |S| | (if payload len==126/127) | | |1|2|3| |K| | | +-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - + | Extended payload length continued, if payload len == 127 | + - - - - - - - - - - - - - - - +-------------------------------+ | |Masking-key, if MASK set to 1 | +-------------------------------+-------------------------------+ | Masking-key (continued) | Payload Data | +-------------------------------- - - - - - - - - - - - - - - - + : Payload Data continued ... : + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + | Payload Data continued ... | +---------------------------------------------------------------+ 2.传输层相关协议传输层实现了upd、tcp、灯协议，并实现了主要接口 tcp protocol: 1234567891011121314151617181920 tcp 首部协议报文0 1 2 3 40 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Source Port | Destination Port |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Sequence Number |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Acknowledgment Number |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Data | |U|A|P|R|S|F| || Offset| Reserved |R|C|S|S|Y|I| Window || | |G|K|H|T|N|N| |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Checksum | Urgent Pointer |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Options | Padding |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| data |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ udp-protocol:1udp 协议报文 端口机制 3.网络层相关协议ip protocol:123456789101112131415161718 ip头部协议报文0 1 2 3 40 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|Version| LHL | Type of Service | Total Length |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Identification(fragment Id) |Flags| Fragment Offset || 16 bits |R|D|M| 13 bits |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Time-To-Live | Protocol | Header Checksum || ttl(8 bits) | 8 bits | 16 bits |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Source IP Address (32 bits) |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Destination Ip Address (32 bits) |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Options (*** bits) | Padding |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"protocol","slug":"protocol","permalink":"http://wiki.brewlin.com/tags/protocol/"}],"categories":[{"name":"net-protocol","slug":"net-protocol","permalink":"http://wiki.brewlin.com/categories/net-protocol/"}]},{"title":"GO标准库和算法应用","date":"2018-10-24T13:28:59.000Z","path":"wiki/go-stl/index/","text":"github:https://github.com/brewlin/go-stl @containers 算法库 lru缓存算法 @hash 基于双向链表等hash表 @list 双向链表 单向链表 skip跳跃表 @queue 基于双向链表的实现 @tree tree struct 二分搜索树 红黑树 3.线段树@graph 图论相关算法 @test 单元测试 压力测试 @raft raft分布式一致性协议 raft 节点 @mr =&gt; mapreduce mr 计算框架","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"}],"categories":[{"name":"go-stl","slug":"go-stl","permalink":"http://wiki.brewlin.com/categories/go-stl/"}]},{"title":"LIST","date":"2018-10-24T13:28:59.000Z","path":"wiki/go-stl/queue/list/","text":"简介基于链表的队列 push:O(1) Pop:O(1) 入队和出队都可以达到O（1） 的时间复杂度。因为链表维护了头结点和尾节点从而使入队和出队都是O（1） api@push12queue := NewQueue()queue.Push(interface) @Pop1queue.Pop() @IsEmptyqueue.IsEmpty()","tags":[{"name":"go","slug":"go","permalink":"http://wiki.brewlin.com/tags/go/"},{"name":"algorithm","slug":"algorithm","permalink":"http://wiki.brewlin.com/tags/algorithm/"},{"name":"list","slug":"list","permalink":"http://wiki.brewlin.com/tags/list/"},{"name":"queue","slug":"queue","permalink":"http://wiki.brewlin.com/tags/queue/"}],"categories":[{"name":"go-stl","slug":"go-stl","permalink":"http://wiki.brewlin.com/categories/go-stl/"},{"name":"queue","slug":"go-stl/queue","permalink":"http://wiki.brewlin.com/categories/go-stl/queue/"}]},{"title":"Welcome Brewlin's Wiki Site","date":"2018-01-21T17:55:57.000Z","path":"wiki/index/","text":"@blog相关文章笔记、源码分析、模拟实现等BLOG @net-protocol基于go模拟内核协议栈 实现链路层、网络层、传输层、应用层 网络协议栈 ，使用虚拟网卡实现 @goosGPM 多线程协程调度器 for PHP Extension，multi-core concurrency library @im-cloud原生swoole4 全协程化分布式中间件、多节点扩容、多节点服务 @c-ext基于c,c++ 开发php对象扩展，充分利用c的无损性能 @read相关读书笔记 @swoole-im swoft-version swoft聊天室 swoole-version swoole聊天室 @go-stlGolang Standard Template Library","tags":[],"categories":[]}]}